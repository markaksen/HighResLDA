{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "import preprocessing # import Jupyter notebook\n",
    "#from preprocessing import clean_pdf\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "with open('./Dataset/merged/textdata_all.pkl', 'rb') as f:\n",
    "    text_df = pickle.load(f)\n",
    "text_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>key_words</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[Distributional robustness,  Markov decision p...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>Throughout the technical note, we use capital ...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Distributionally robust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56031008</td>\n",
       "      <td>Abstract-The present study attempted to find o...</td>\n",
       "      <td>[listening comprehension,  pre-task activities...</td>\n",
       "      <td>[{'section': 'A. Listening Materials and Activ...</td>\n",
       "      <td>Morley (1991) has explained that in developing...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Listening', 'authors': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88484504</td>\n",
       "      <td>In this paper, we address robust design of sym...</td>\n",
       "      <td>[Downlink MU-MISO,  imperfect CSI,  symbolleve...</td>\n",
       "      <td>[{'section': 'II. SYSTEM AND UNCERTAINTY MODEL...</td>\n",
       "      <td>We consider an MU-MISO wireless broadcast chan...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Convex optimization-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88485902</td>\n",
       "      <td>ABSTRACT A kinematic equation of profiling flo...</td>\n",
       "      <td>[Profiling float,  depth control,  low power c...</td>\n",
       "      <td>[{'section': 'I. INTRODUCTION', 'text': 'With ...</td>\n",
       "      <td>With the increase in the cognition of marine a...</td>\n",
       "      <td>{'BIBREF0': {'title': 'AUV buoyancy regulating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204197524</td>\n",
       "      <td>We characterize practical optical signal recei...</td>\n",
       "      <td>[Optical wireless communications,  multi-stage...</td>\n",
       "      <td>[{'section': 'A. PMT Principle Review', 'text'...</td>\n",
       "      <td>The typical structure of a PMT is shown in Fig...</td>\n",
       "      <td>{'BIBREF0': {'title': 'A statistical non-linea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id                                           abstract  \\\n",
       "0   18980380  This technical note studies Markov decision pr...   \n",
       "1   56031008  Abstract-The present study attempted to find o...   \n",
       "2   88484504  In this paper, we address robust design of sym...   \n",
       "3   88485902  ABSTRACT A kinematic equation of profiling flo...   \n",
       "4  204197524  We characterize practical optical signal recei...   \n",
       "\n",
       "                                           key_words  \\\n",
       "0  [Distributional robustness,  Markov decision p...   \n",
       "1  [listening comprehension,  pre-task activities...   \n",
       "2  [Downlink MU-MISO,  imperfect CSI,  symbolleve...   \n",
       "3  [Profiling float,  depth control,  low power c...   \n",
       "4  [Optical wireless communications,  multi-stage...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "1  [{'section': 'A. Listening Materials and Activ...   \n",
       "2  [{'section': 'II. SYSTEM AND UNCERTAINTY MODEL...   \n",
       "3  [{'section': 'I. INTRODUCTION', 'text': 'With ...   \n",
       "4  [{'section': 'A. PMT Principle Review', 'text'...   \n",
       "\n",
       "                                          whole_text  \\\n",
       "0  Throughout the technical note, we use capital ...   \n",
       "1  Morley (1991) has explained that in developing...   \n",
       "2  We consider an MU-MISO wireless broadcast chan...   \n",
       "3  With the increase in the cognition of marine a...   \n",
       "4  The typical structure of a PMT is shown in Fig...   \n",
       "\n",
       "                                           citations  \n",
       "0  {'BIBREF0': {'title': 'Distributionally robust...  \n",
       "1  {'BIBREF0': {'title': 'Listening', 'authors': ...  \n",
       "2  {'BIBREF0': {'title': 'Convex optimization-bas...  \n",
       "3  {'BIBREF0': {'title': 'AUV buoyancy regulating...  \n",
       "4  {'BIBREF0': {'title': 'A statistical non-linea...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing index to paper_id\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "Tokenizing\n",
      "53.112943172454834\n",
      "53.112943172454834\n",
      "53.112943172454834\n",
      "Lemmatizing\n",
      "53.112943172454834\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  158730\n",
      "length of dct after filter_extreme:  25185\n",
      "159.25587630271912\n"
     ]
    }
   ],
   "source": [
    "docs_cleaned = clean_pdf(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4443 4443\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_cleaned['ids']), len(docs_cleaned['corpus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_df = process_sections(text_df)\n",
    "sections_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing index to paper_id\n",
      "0.002969980239868164\n",
      "0.002969980239868164\n",
      "0.002969980239868164\n",
      "0.002969980239868164\n",
      "0.002969980239868164\n",
      "0.002969980239868164\n",
      "Tokenizing\n",
      "5.570342540740967\n",
      "5.570342540740967\n",
      "5.570342540740967\n",
      "Lemmatizing\n",
      "5.570342540740967\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  31656\n",
      "length of dct after filter_extreme:  7942\n",
      "13.497344732284546\n"
     ]
    }
   ],
   "source": [
    "sections_cleaned = clean_section(sections_df, file_name='section_level_kw', output_dir='./Dataset/cleaned/cs-med/',section_lvl = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights\n",
    "\n",
    "def ts_doc(dct, corpus, paper_ids):\n",
    "    paper_ids_unique = np.unique(paper_ids)\n",
    "    nwords = len(sections_cleaned['dct'].token2id)\n",
    "    weights = np.zeros((nwords, len(sections_cleaned['corpus'])))\n",
    "    for paper_id in paper_ids_unique:\n",
    "        inds = np.where(paper_ids==paper_id)\n",
    "        nonzero_words = []\n",
    "        for ind in inds:\n",
    "            nonzero_words_add = [corpus[ind][x][0] for x in range(len(corpus[ind]))]\n",
    "            nonzero_words = nonzero_words + nonzero_words_add\n",
    "        nonzero_words = np.unique(nonzero_words)\n",
    "        for \n",
    "        \n",
    "def ts_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2360"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = sections_cleaned['dct']\n",
    "dct.cfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[1] for x in corpus[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sections_cleaned['corpus']\n",
    "dct = sections_cleaned['dct']\n",
    "paper_ids = sections_cleaned['ids']\n",
    "\n",
    "corpus_doc = docs_cleaned['corpus']\n",
    "dct_doc = docs_cleaned['dct']\n",
    "paper_ids_doc = docs_cleaned['ids']\n",
    "\n",
    "weights = np.zeros((len(corpus), len(dct.cfs)))\n",
    "for d_idx,d in enumerate(corpus):\n",
    "    for w_idx, c in enumerate(d):\n",
    "        \n",
    "        # section length\n",
    "        section_length = sum([x[1] for x in d])\n",
    "        \n",
    "        # Calculate section-level weight\n",
    "        weight_section = (c[1] + 1) / (dct.cfs[w_idx] + section_length)\n",
    "        \n",
    "        # Calculate document-level weight\n",
    "        paper_id = paper_ids.iloc[d_idx]\n",
    "        ind = paper_ids_doc.index(paper_id)\n",
    "        \n",
    "        # document length\n",
    "        document_length = sum([x[1] for x in corpus_doc[ind]])\n",
    "        \n",
    "        w_idx_doc = dct_doc.token2id[dct[w_idx]]\n",
    "        \n",
    "        if w_idx_doc in \n",
    "        dict(corpus_doc[ind])[w_idx_doc]\n",
    "        \n",
    "        weight_document = ( + 1) / (dct_doc.cfs[w_idx_doc] + document length_length)\n",
    "        \n",
    "        # Combined weight\n",
    "        weight_combined = weight_selection*weight_document\n",
    "    \n",
    "        weights[d_idx][w_idx] = weight_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_doc = docs_cleaned['corpus']\n",
    "dct_doc = docs_cleaned['dct']\n",
    "paper_ids_doc = docs_cleaned['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25186"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_doc.token2id['addition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25186 in dict(corpus_doc[0]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(corpus_doc[0])[25186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account': 0,\n",
       " 'achieves': 1,\n",
       " 'action': 2,\n",
       " 'adapt': 3,\n",
       " 'addressed': 4,\n",
       " 'admissible': 5,\n",
       " 'advantageous': 6,\n",
       " 'adversarial': 7,\n",
       " 'affine': 8,\n",
       " 'agent': 9,\n",
       " 'allows': 10,\n",
       " 'ambiguity': 11,\n",
       " 'ambiguous': 12,\n",
       " 'andm': 13,\n",
       " 'applicability': 14,\n",
       " 'applies': 15,\n",
       " 'apply': 16,\n",
       " 'applying': 17,\n",
       " 'apriori': 18,\n",
       " 'around': 19,\n",
       " 'arranged': 20,\n",
       " 'aspect': 21,\n",
       " 'asserts': 22,\n",
       " 'associated': 23,\n",
       " 'assumed': 24,\n",
       " 'assumes': 25,\n",
       " 'assumption': 26,\n",
       " 'asz': 27,\n",
       " 'auxiliary': 28,\n",
       " 'avoid': 29,\n",
       " 'backward': 30,\n",
       " 'bad': 31,\n",
       " 'bar': 32,\n",
       " 'beat': 33,\n",
       " 'believe': 34,\n",
       " 'bellman': 35,\n",
       " 'belong': 36,\n",
       " 'belonging': 37,\n",
       " 'belongs': 38,\n",
       " 'beneficial': 39,\n",
       " 'bernoulli': 40,\n",
       " 'bin': 41,\n",
       " 'blind': 42,\n",
       " 'block': 43,\n",
       " 'bold': 44,\n",
       " 'bound': 45,\n",
       " 'bounded': 46,\n",
       " 'box': 47,\n",
       " 'call': 48,\n",
       " 'called': 49,\n",
       " 'capable': 50,\n",
       " 'capital': 51,\n",
       " 'capturing': 52,\n",
       " 'cartesian': 53,\n",
       " 'centered': 54,\n",
       " 'challenging': 55,\n",
       " 'chance': 56,\n",
       " 'characterize': 57,\n",
       " 'check': 58,\n",
       " 'chosen': 59,\n",
       " 'class': 60,\n",
       " 'classical': 61,\n",
       " 'clearly': 62,\n",
       " 'clock': 63,\n",
       " 'closed': 64,\n",
       " 'clustering': 65,\n",
       " 'coincide': 66,\n",
       " 'column': 67,\n",
       " 'community': 68,\n",
       " 'compact': 69,\n",
       " 'compactness': 70,\n",
       " 'compensation': 71,\n",
       " 'complete': 72,\n",
       " 'computational': 73,\n",
       " 'computationally': 74,\n",
       " 'compute': 75,\n",
       " 'computing': 76,\n",
       " 'concentrate': 77,\n",
       " 'concept': 78,\n",
       " 'conditioned': 79,\n",
       " 'cone': 80,\n",
       " 'confidence': 81,\n",
       " 'conic': 82,\n",
       " 'conservative': 83,\n",
       " 'considerably': 84,\n",
       " 'considers': 85,\n",
       " 'constraint': 86,\n",
       " 'construct': 87,\n",
       " 'contain': 88,\n",
       " 'contains': 89,\n",
       " 'continuous': 90,\n",
       " 'contrast': 91,\n",
       " 'convex': 92,\n",
       " 'convexity': 93,\n",
       " 'coordinate': 94,\n",
       " 'core': 95,\n",
       " 'corner': 96,\n",
       " 'cost': 97,\n",
       " 'costtogo': 98,\n",
       " 'coupled': 99,\n",
       " 'cpu': 100,\n",
       " 'cvx': 101,\n",
       " 'datadriven': 102,\n",
       " 'decision': 103,\n",
       " 'definition': 104,\n",
       " 'denote': 105,\n",
       " 'denotes': 106,\n",
       " 'depends': 107,\n",
       " 'derive': 108,\n",
       " 'deriving': 109,\n",
       " 'designed': 110,\n",
       " 'desirable': 111,\n",
       " 'desktop': 112,\n",
       " 'detailed': 113,\n",
       " 'deterministic': 114,\n",
       " 'discount': 115,\n",
       " 'discounted': 116,\n",
       " 'discus': 117,\n",
       " 'disjoint': 118,\n",
       " 'distinct': 119,\n",
       " 'distributional': 120,\n",
       " 'duality': 121,\n",
       " 'dummy': 122,\n",
       " 'easily': 123,\n",
       " 'easy': 124,\n",
       " 'efficiently': 125,\n",
       " 'element': 126,\n",
       " 'elementary': 127,\n",
       " 'emerged': 128,\n",
       " 'enables': 129,\n",
       " 'encompass': 130,\n",
       " 'end': 131,\n",
       " 'enough': 132,\n",
       " 'environment': 133,\n",
       " 'essential': 134,\n",
       " 'essentially': 135,\n",
       " 'estimate': 136,\n",
       " 'estimated': 137,\n",
       " 'estimation': 138,\n",
       " 'evaluated': 139,\n",
       " 'ever': 140,\n",
       " 'exact': 141,\n",
       " 'except': 142,\n",
       " 'exists': 143,\n",
       " 'exit': 144,\n",
       " 'expect': 145,\n",
       " 'expectation': 146,\n",
       " 'expected': 147,\n",
       " 'experiment': 148,\n",
       " 'exposition': 149,\n",
       " 'extend': 150,\n",
       " 'extended': 151,\n",
       " 'extends': 152,\n",
       " 'extension': 153,\n",
       " 'extra': 154,\n",
       " 'face': 155,\n",
       " 'factory': 156,\n",
       " 'feasible': 157,\n",
       " 'finding': 158,\n",
       " 'finite': 159,\n",
       " 'fix': 160,\n",
       " 'flexible': 161,\n",
       " 'follow': 162,\n",
       " 'followed': 163,\n",
       " 'formulation': 164,\n",
       " 'framework': 165,\n",
       " 'gaussian': 166,\n",
       " 'generality': 167,\n",
       " 'generalize': 168,\n",
       " 'generalized': 169,\n",
       " 'generalizes': 170,\n",
       " 'generally': 171,\n",
       " 'generic': 172,\n",
       " 'ghz': 173,\n",
       " 'grid': 174,\n",
       " 'handle': 175,\n",
       " 'happening': 176,\n",
       " 'hard': 177,\n",
       " 'harder': 178,\n",
       " 'hereafter': 179,\n",
       " 'highest': 180,\n",
       " 'highlight': 181,\n",
       " 'highly': 182,\n",
       " 'histogram': 183,\n",
       " 'historical': 184,\n",
       " 'history': 185,\n",
       " 'historydependent': 186,\n",
       " 'hold': 187,\n",
       " 'horizon': 188,\n",
       " 'httpwwwieeeorgpublicationsstandardspublicationsrightsindexhtml': 189,\n",
       " 'huber': 190,\n",
       " 'ieee': 191,\n",
       " 'illustrated': 192,\n",
       " 'illustrates': 193,\n",
       " 'illustration': 194,\n",
       " 'image': 195,\n",
       " 'immediately': 196,\n",
       " 'implementation': 197,\n",
       " 'implemented': 198,\n",
       " 'implies': 199,\n",
       " 'impossible': 200,\n",
       " 'incorporate': 201,\n",
       " 'incorporated': 202,\n",
       " 'incorporates': 203,\n",
       " 'incorporating': 204,\n",
       " 'incurred': 205,\n",
       " 'incurs': 206,\n",
       " 'indeed': 207,\n",
       " 'independently': 208,\n",
       " 'induction': 209,\n",
       " 'industrial': 210,\n",
       " 'inf': 211,\n",
       " 'infinite': 212,\n",
       " 'ini': 213,\n",
       " 'initial': 214,\n",
       " 'inside': 215,\n",
       " 'instance': 216,\n",
       " 'intel': 217,\n",
       " 'interest': 218,\n",
       " 'interior': 219,\n",
       " 'intersection': 220,\n",
       " 'interval': 221,\n",
       " 'intractable': 222,\n",
       " 'introduce': 223,\n",
       " 'introducing': 224,\n",
       " 'investigate': 225,\n",
       " 'ith': 226,\n",
       " 'joint': 227,\n",
       " 'jump': 228,\n",
       " 'jumping': 229,\n",
       " 'justified': 230,\n",
       " 'last': 231,\n",
       " 'left': 232,\n",
       " 'lemma': 233,\n",
       " 'length': 234,\n",
       " 'letter': 235,\n",
       " 'life': 236,\n",
       " 'lifting': 237,\n",
       " 'linearly': 238,\n",
       " 'listed': 239,\n",
       " 'literature': 240,\n",
       " 'longer': 241,\n",
       " 'lowerbound': 242,\n",
       " 'lowerright': 243,\n",
       " 'machine': 244,\n",
       " 'mainly': 245,\n",
       " 'maker': 246,\n",
       " 'manifold': 247,\n",
       " 'manner': 248,\n",
       " 'marginal': 249,\n",
       " 'markov': 250,\n",
       " 'matlab': 251,\n",
       " 'maximizes': 252,\n",
       " 'maze': 253,\n",
       " 'mdp': 254,\n",
       " 'mdps': 255,\n",
       " 'metric': 256,\n",
       " 'mild': 257,\n",
       " 'minimax': 258,\n",
       " 'mixed': 259,\n",
       " 'mixture': 260,\n",
       " 'modality': 261,\n",
       " 'modeled': 262,\n",
       " 'modeling': 263,\n",
       " 'modern': 264,\n",
       " 'moreover': 265,\n",
       " 'move': 266,\n",
       " 'multimodel': 267,\n",
       " 'name': 268,\n",
       " 'naturally': 269,\n",
       " 'nc': 270,\n",
       " 'neglect': 271,\n",
       " 'nested': 272,\n",
       " 'nesting': 273,\n",
       " 'networkbased': 274,\n",
       " 'networked': 275,\n",
       " 'nominal': 276,\n",
       " 'nonempty': 277,\n",
       " 'nonlinear': 278,\n",
       " 'nonnegative': 279,\n",
       " 'nonrectangular': 280,\n",
       " 'nonstationary': 281,\n",
       " 'normal': 282,\n",
       " 'notice': 283,\n",
       " 'notion': 284,\n",
       " 'novel': 285,\n",
       " 'numerical': 286,\n",
       " 'obey': 287,\n",
       " 'objective': 288,\n",
       " 'observation': 289,\n",
       " 'ofc': 290,\n",
       " 'omit': 291,\n",
       " 'omitted': 292,\n",
       " 'onto': 293,\n",
       " 'optimization': 294,\n",
       " 'option': 295,\n",
       " 'orthant': 296,\n",
       " 'otherwise': 297,\n",
       " 'outperforms': 298,\n",
       " 'package': 299,\n",
       " 'pair': 300,\n",
       " 'partition': 301,\n",
       " 'pas': 302,\n",
       " 'path': 303,\n",
       " 'peak': 304,\n",
       " 'permission': 305,\n",
       " 'permitted': 306,\n",
       " 'personal': 307,\n",
       " 'place': 308,\n",
       " 'planning': 309,\n",
       " 'pointed': 310,\n",
       " 'policy': 311,\n",
       " 'polynomial': 312,\n",
       " 'portion': 313,\n",
       " 'possibly': 314,\n",
       " 'practice': 315,\n",
       " 'prescribed': 316,\n",
       " 'prevent': 317,\n",
       " 'primitive': 318,\n",
       " 'probabilistic': 319,\n",
       " 'procedure': 320,\n",
       " 'product': 321,\n",
       " 'projection': 322,\n",
       " 'proof': 323,\n",
       " 'proper': 324,\n",
       " 'quadratic': 325,\n",
       " 'ram': 326,\n",
       " 'randomized': 327,\n",
       " 'reach': 328,\n",
       " 'realization': 329,\n",
       " 'reboot': 330,\n",
       " 'recent': 331,\n",
       " 'recently': 332,\n",
       " 'reducing': 333,\n",
       " 'regularity': 334,\n",
       " 'relationship': 335,\n",
       " 'remark': 336,\n",
       " 'repair': 337,\n",
       " 'repairing': 338,\n",
       " 'replacement': 339,\n",
       " 'represent': 340,\n",
       " 'representable': 341,\n",
       " 'republicationredistribution': 342,\n",
       " 'require': 343,\n",
       " 'requirement': 344,\n",
       " 'residing': 345,\n",
       " 'resolved': 346,\n",
       " 'respect': 347,\n",
       " 'respective': 348,\n",
       " 'revisited': 349,\n",
       " 'reward': 350,\n",
       " 'rich': 351,\n",
       " 'right': 352,\n",
       " 'risk': 353,\n",
       " 'risky': 354,\n",
       " 'robust': 355,\n",
       " 'rsc': 356,\n",
       " 'run': 357,\n",
       " 'saddle': 358,\n",
       " 'sample': 359,\n",
       " 'satisfies': 360,\n",
       " 'secure': 361,\n",
       " 'seek': 362,\n",
       " 'select': 363,\n",
       " 'semidefinite': 364,\n",
       " 'setpoints': 365,\n",
       " 'setup': 366,\n",
       " 'shaded': 367,\n",
       " 'showed': 368,\n",
       " 'simplex': 369,\n",
       " 'simplify': 370,\n",
       " 'solvable': 371,\n",
       " 'solve': 372,\n",
       " 'solved': 373,\n",
       " 'solving': 374,\n",
       " 'special': 375,\n",
       " 'specifically': 376,\n",
       " 'spectrum': 377,\n",
       " 'speed': 378,\n",
       " 'spot': 379,\n",
       " 'stage': 380,\n",
       " 'stand': 381,\n",
       " 'starting': 382,\n",
       " 'stationary': 383,\n",
       " 'strategy': 384,\n",
       " 'strike': 385,\n",
       " 'structural': 386,\n",
       " 'subject': 387,\n",
       " 'subproblem': 388,\n",
       " 'subscript': 389,\n",
       " 'support': 390,\n",
       " 'synthetic': 391,\n",
       " 'technical': 392,\n",
       " 'termed': 393,\n",
       " 'terminal': 394,\n",
       " 'thatc': 395,\n",
       " 'theorem': 396,\n",
       " 'throughout': 397,\n",
       " 'topic': 398,\n",
       " 'topology': 399,\n",
       " 'tradeoff': 400,\n",
       " 'transition': 401,\n",
       " 'treated': 402,\n",
       " 'trial': 403,\n",
       " 'true': 404,\n",
       " 'tth': 405,\n",
       " 'tuple': 406,\n",
       " 'turn': 407,\n",
       " 'twolayer': 408,\n",
       " 'typical': 409,\n",
       " 'typically': 410,\n",
       " 'uncertain': 411,\n",
       " 'uncertainty': 412,\n",
       " 'underlying': 413,\n",
       " 'undesirable': 414,\n",
       " 'unified': 415,\n",
       " 'unifying': 416,\n",
       " 'unit': 417,\n",
       " 'unknown': 418,\n",
       " 'upper': 419,\n",
       " 'upperleft': 420,\n",
       " 'usin': 421,\n",
       " 'usually': 422,\n",
       " 'utility': 423,\n",
       " 'variance': 424,\n",
       " 'variety': 425,\n",
       " 'version': 426,\n",
       " 'via': 427,\n",
       " 'virtually': 428,\n",
       " 'virtue': 429,\n",
       " 'visit': 430,\n",
       " 'visited': 431,\n",
       " 'visiting': 432,\n",
       " 'waiting': 433,\n",
       " 'want': 434,\n",
       " 'weak': 435,\n",
       " 'weakly': 436,\n",
       " 'whereas': 437,\n",
       " 'wherem': 438,\n",
       " 'white': 439,\n",
       " 'whole': 440,\n",
       " 'widely': 441,\n",
       " 'word': 442,\n",
       " 'worst': 443,\n",
       " 'worstcase': 444,\n",
       " 'wrt': 445,\n",
       " 'accepted': 446,\n",
       " 'across': 447,\n",
       " 'act': 448,\n",
       " 'acted': 449,\n",
       " 'activate': 450,\n",
       " 'activating': 451,\n",
       " 'activation': 452,\n",
       " 'activity': 453,\n",
       " 'actual': 454,\n",
       " 'additionally': 455,\n",
       " 'administered': 456,\n",
       " 'administering': 457,\n",
       " 'advanced': 458,\n",
       " 'affecting': 459,\n",
       " 'age': 460,\n",
       " 'aim': 461,\n",
       " 'aimed': 462,\n",
       " 'allow': 463,\n",
       " 'almost': 464,\n",
       " 'along': 465,\n",
       " 'alpha': 466,\n",
       " 'alternative': 467,\n",
       " 'anova': 468,\n",
       " 'answer': 469,\n",
       " 'answering': 470,\n",
       " 'anticipating': 471,\n",
       " 'appropriate': 472,\n",
       " 'argued': 473,\n",
       " 'asked': 474,\n",
       " 'assigned': 475,\n",
       " 'assisted': 476,\n",
       " 'association': 477,\n",
       " 'attempted': 478,\n",
       " 'attention': 479,\n",
       " 'attribute': 480,\n",
       " 'author': 481,\n",
       " 'aware': 482,\n",
       " 'background': 483,\n",
       " 'basis': 484,\n",
       " 'beginning': 485,\n",
       " 'belief': 486,\n",
       " 'benefit': 487,\n",
       " 'benefited': 488,\n",
       " 'benefiting': 489,\n",
       " 'betweengroup': 490,\n",
       " 'blank': 491,\n",
       " 'bottomup': 492,\n",
       " 'boyle': 493,\n",
       " 'broadly': 494,\n",
       " 'brought': 495,\n",
       " 'building': 496,\n",
       " 'care': 497,\n",
       " 'carried': 498,\n",
       " 'casting': 499,\n",
       " 'cause': 500,\n",
       " 'centre': 501,\n",
       " 'chang': 502,\n",
       " 'chiang': 503,\n",
       " 'chinese': 504,\n",
       " 'classified': 505,\n",
       " 'classroom': 506,\n",
       " 'clear': 507,\n",
       " 'cognitive': 508,\n",
       " 'combined': 509,\n",
       " 'communication': 510,\n",
       " 'communicative': 511,\n",
       " 'comparing': 512,\n",
       " 'compensate': 513,\n",
       " 'comprehension': 514,\n",
       " 'comprehensive': 515,\n",
       " 'computed': 516,\n",
       " 'con': 517,\n",
       " 'concerned': 518,\n",
       " 'concluded': 519,\n",
       " 'conclusion': 520,\n",
       " 'conducted': 521,\n",
       " 'conducting': 522,\n",
       " 'confirm': 523,\n",
       " 'confirmed': 524,\n",
       " 'confirms': 525,\n",
       " 'connection': 526,\n",
       " 'consequently': 527,\n",
       " 'consisted': 528,\n",
       " 'consists': 529,\n",
       " 'constituted': 530,\n",
       " 'contained': 531,\n",
       " 'content': 532,\n",
       " 'contentbased': 533,\n",
       " 'context': 534,\n",
       " 'contextual': 535,\n",
       " 'contributed': 536,\n",
       " 'contribution': 537,\n",
       " 'conventional': 538,\n",
       " 'crucial': 539,\n",
       " 'degree': 540,\n",
       " 'delimit': 541,\n",
       " 'delivered': 542,\n",
       " 'depend': 543,\n",
       " 'despite': 544,\n",
       " 'develop': 545,\n",
       " 'developing': 546,\n",
       " 'deviation': 547,\n",
       " 'dialogue': 548,\n",
       " 'difficulty': 549,\n",
       " 'direct': 550,\n",
       " 'directing': 551,\n",
       " 'discovering': 552,\n",
       " 'discussed': 553,\n",
       " 'discussion': 554,\n",
       " 'divide': 555,\n",
       " 'divided': 556,\n",
       " 'domain': 557,\n",
       " 'done': 558,\n",
       " 'economic': 559,\n",
       " 'edward': 560,\n",
       " 'effective': 561,\n",
       " 'effectively': 562,\n",
       " 'effectiveness': 563,\n",
       " 'efficacy': 564,\n",
       " 'embedded': 565,\n",
       " 'emphasized': 566,\n",
       " 'employed': 567,\n",
       " 'enhance': 568,\n",
       " 'enhanced': 569,\n",
       " 'enhancement': 570,\n",
       " 'entail': 571,\n",
       " 'especially': 572,\n",
       " 'ets': 573,\n",
       " 'exacerbated': 574,\n",
       " 'exactly': 575,\n",
       " 'examining': 576,\n",
       " 'exclusively': 577,\n",
       " 'exist': 578,\n",
       " 'existence': 579,\n",
       " 'experimental': 580,\n",
       " 'explained': 581,\n",
       " 'explicit': 582,\n",
       " 'exposure': 583,\n",
       " 'extent': 584,\n",
       " 'facilitates': 585,\n",
       " 'factual': 586,\n",
       " 'failure': 587,\n",
       " 'familiar': 588,\n",
       " 'familiarity': 589,\n",
       " 'female': 590,\n",
       " 'fill': 591,\n",
       " 'focal': 592,\n",
       " 'formation': 593,\n",
       " 'forthcoming': 594,\n",
       " 'glossary': 595,\n",
       " 'goal': 596,\n",
       " 'goh': 597,\n",
       " 'group': 598,\n",
       " 'guarantee': 599,\n",
       " 'guess': 600,\n",
       " 'guiding': 601,\n",
       " 'hansen': 602,\n",
       " 'heard': 603,\n",
       " 'help': 604,\n",
       " 'helped': 605,\n",
       " 'helping': 606,\n",
       " 'highlighted': 607,\n",
       " 'hoc': 608,\n",
       " 'homogeneity': 609,\n",
       " 'hypothesis': 610,\n",
       " 'idea': 611,\n",
       " 'identifies': 612,\n",
       " 'identifying': 613,\n",
       " 'illuminate': 614,\n",
       " 'implication': 615,\n",
       " 'improved': 616,\n",
       " 'improvement': 617,\n",
       " 'include': 618,\n",
       " 'increased': 619,\n",
       " 'indicated': 620,\n",
       " 'infer': 621,\n",
       " 'influential': 622,\n",
       " 'intended': 623,\n",
       " 'interaction': 624,\n",
       " 'intermediate': 625,\n",
       " 'internalize': 626,\n",
       " 'investigated': 627,\n",
       " 'involve': 628,\n",
       " 'involves': 629,\n",
       " 'issue': 630,\n",
       " 'item': 631,\n",
       " 'jensen': 632,\n",
       " 'justifies': 633,\n",
       " 'kelly': 634,\n",
       " 'key': 635,\n",
       " 'kind': 636,\n",
       " 'knowledge': 637,\n",
       " 'lack': 638,\n",
       " 'language': 639,\n",
       " 'learner': 640,\n",
       " 'learning': 641,\n",
       " 'lecture': 642,\n",
       " 'led': 643,\n",
       " 'lesson': 644,\n",
       " 'lexical': 645,\n",
       " 'light': 646,\n",
       " 'lin': 647,\n",
       " 'line': 648,\n",
       " 'linguistic': 649,\n",
       " 'list': 650,\n",
       " 'listen': 651,\n",
       " 'listener': 652,\n",
       " 'listening': 653,\n",
       " 'literal': 654,\n",
       " 'little': 655,\n",
       " 'long': 656,\n",
       " 'looked': 657,\n",
       " 'looking': 658,\n",
       " 'macrolevel': 659,\n",
       " 'maintain': 660,\n",
       " 'maintained': 661,\n",
       " 'making': 662,\n",
       " 'male': 663,\n",
       " 'material': 664,\n",
       " 'mcdonald': 665,\n",
       " 'meaning': 666,\n",
       " 'meaningful': 667,\n",
       " 'measured': 668,\n",
       " 'memory': 669,\n",
       " 'mentioned': 670,\n",
       " 'message': 671,\n",
       " 'microlevel': 672,\n",
       " 'might': 673,\n",
       " 'mind': 674,\n",
       " 'minute': 675,\n",
       " 'mode': 676,\n",
       " 'modification': 677,\n",
       " 'multiplechoice': 678,\n",
       " 'native': 679,\n",
       " 'necessary': 680,\n",
       " 'news': 681,\n",
       " 'nonnative': 682,\n",
       " 'noted': 683,\n",
       " 'null': 684,\n",
       " 'offer': 685,\n",
       " 'offered': 686,\n",
       " 'offering': 687,\n",
       " 'oneway': 688,\n",
       " 'onset': 689,\n",
       " 'organizational': 690,\n",
       " 'outperformed': 691,\n",
       " 'participant': 692,\n",
       " 'participated': 693,\n",
       " 'past': 694,\n",
       " 'paying': 695,\n",
       " 'people': 696,\n",
       " 'performing': 697,\n",
       " 'period': 698,\n",
       " 'phase': 699,\n",
       " 'picture': 700,\n",
       " 'piece': 701,\n",
       " 'population': 702,\n",
       " 'possibility': 703,\n",
       " 'post': 704,\n",
       " 'posttest': 705,\n",
       " 'predicting': 706,\n",
       " 'preexisting': 707,\n",
       " 'preferred': 708,\n",
       " 'preparation': 709,\n",
       " 'pretest': 710,\n",
       " 'primary': 711,\n",
       " 'prior': 712,\n",
       " 'problematic': 713,\n",
       " 'procedural': 714,\n",
       " 'processing': 715,\n",
       " 'proficiency': 716,\n",
       " 'proficient': 717,\n",
       " 'pronunciation': 718,\n",
       " 'providing': 719,\n",
       " 'provision': 720,\n",
       " 'quantitative': 721,\n",
       " 'question': 722,\n",
       " 'randomly': 723,\n",
       " 'reached': 724,\n",
       " 'read': 725,\n",
       " 'readiness': 726,\n",
       " 'reading': 727,\n",
       " 'realworld': 728,\n",
       " 'received': 729,\n",
       " 'receiving': 730,\n",
       " 'recorded': 731,\n",
       " 'referred': 732,\n",
       " 'refers': 733,\n",
       " 'regarding': 734,\n",
       " 'register': 735,\n",
       " 'rejected': 736,\n",
       " 'relate': 737,\n",
       " 'relating': 738,\n",
       " 'relation': 739,\n",
       " 'rely': 740,\n",
       " 'remained': 741,\n",
       " 'representation': 742,\n",
       " 'represented': 743,\n",
       " 'researcher': 744,\n",
       " 'revealed': 745,\n",
       " 'richards': 746,\n",
       " 'role': 747,\n",
       " 'rost': 748,\n",
       " 'schema': 749,\n",
       " 'schematic': 750,\n",
       " 'score': 751,\n",
       " 'seems': 752,\n",
       " 'segment': 753,\n",
       " 'semantic': 754,\n",
       " 'serf': 755,\n",
       " 'session': 756,\n",
       " 'sharp': 757,\n",
       " 'shed': 758,\n",
       " 'significance': 759,\n",
       " 'similarity': 760,\n",
       " 'similarly': 761,\n",
       " 'simultaneously': 762,\n",
       " 'situation': 763,\n",
       " 'skill': 764,\n",
       " 'socalled': 765,\n",
       " 'sociocultural': 766,\n",
       " 'solid': 767,\n",
       " 'somewhat': 768,\n",
       " 'source': 769,\n",
       " 'speaker': 770,\n",
       " 'speaking': 771,\n",
       " 'specialized': 772,\n",
       " 'specification': 773,\n",
       " 'speech': 774,\n",
       " 'spoken': 775,\n",
       " 'stated': 776,\n",
       " 'statistical': 777,\n",
       " 'statistically': 778,\n",
       " 'stimulus': 779,\n",
       " 'store': 780,\n",
       " 'student': 781,\n",
       " 'studied': 782,\n",
       " 'submitted': 783,\n",
       " 'successful': 784,\n",
       " 'suggested': 785,\n",
       " 'suggesting': 786,\n",
       " 'suggests': 787,\n",
       " 'summarize': 788,\n",
       " 'summary': 789,\n",
       " 'supported': 790,\n",
       " 'supporting': 791,\n",
       " 'supportive': 792,\n",
       " 'supposed': 793,\n",
       " 'syllabus': 794,\n",
       " 'syntactical': 795,\n",
       " 'systematic': 796,\n",
       " 'systemic': 797,\n",
       " 'taken': 798,\n",
       " 'taking': 799,\n",
       " 'task': 800,\n",
       " 'taylor': 801,\n",
       " 'teacher': 802,\n",
       " 'teaching': 803,\n",
       " 'tended': 804,\n",
       " 'test': 805,\n",
       " 'tested': 806,\n",
       " 'testing': 807,\n",
       " 'text': 808,\n",
       " 'textual': 809,\n",
       " 'theory': 810,\n",
       " 'thought': 811,\n",
       " 'topdown': 812,\n",
       " 'totalling': 813,\n",
       " 'totally': 814,\n",
       " 'transactional': 815,\n",
       " 'translating': 816,\n",
       " 'twenty': 817,\n",
       " 'utilizes': 818,\n",
       " 'view': 819,\n",
       " 'vocabulary': 820,\n",
       " 'weight': 821,\n",
       " 'whether': 822,\n",
       " 'whose': 823,\n",
       " 'worry': 824,\n",
       " 'writer': 825,\n",
       " 'written': 826,\n",
       " 'able': 827,\n",
       " 'accommodate': 828,\n",
       " 'accordance': 829,\n",
       " 'accordingly': 830,\n",
       " 'accurate': 831,\n",
       " 'achievable': 832,\n",
       " 'additive': 833,\n",
       " 'address': 834,\n",
       " 'admit': 835,\n",
       " 'admits': 836,\n",
       " 'adopt': 837,\n",
       " 'adopted': 838,\n",
       " 'adopting': 839,\n",
       " 'affect': 840,\n",
       " 'algebra': 841,\n",
       " 'alleviated': 842,\n",
       " 'allowing': 843,\n",
       " 'always': 844,\n",
       " 'amount': 845,\n",
       " 'analytic': 846,\n",
       " 'analytical': 847,\n",
       " 'analytically': 848,\n",
       " 'analyze': 849,\n",
       " 'andor': 850,\n",
       " 'andq': 851,\n",
       " 'andw': 852,\n",
       " 'antenna': 853,\n",
       " 'apart': 854,\n",
       " 'apparent': 855,\n",
       " 'appear': 856,\n",
       " 'appears': 857,\n",
       " 'appendix': 858,\n",
       " 'applicable': 859,\n",
       " 'appropriately': 860,\n",
       " 'approximate': 861,\n",
       " 'approximated': 862,\n",
       " 'approximating': 863,\n",
       " 'approximation': 864,\n",
       " 'arbitrary': 865,\n",
       " 'arising': 866,\n",
       " 'arithmetic': 867,\n",
       " 'assemble': 868,\n",
       " 'assuming': 869,\n",
       " 'availability': 870,\n",
       " 'averaged': 871,\n",
       " 'away': 872,\n",
       " 'ball': 873,\n",
       " 'barely': 874,\n",
       " 'base': 875,\n",
       " 'baseband': 876,\n",
       " 'basically': 877,\n",
       " 'becomes': 878,\n",
       " 'begin': 879,\n",
       " 'behavior': 880,\n",
       " 'benchmark': 881,\n",
       " 'beyond': 882,\n",
       " 'bit': 883,\n",
       " 'bivariate': 884,\n",
       " 'blocklevel': 885,\n",
       " 'borrowed': 886,\n",
       " 'boundary': 887,\n",
       " 'bounding': 888,\n",
       " 'briefly': 889,\n",
       " 'broadcast': 890,\n",
       " 'calculated': 891,\n",
       " 'capture': 892,\n",
       " 'carefully': 893,\n",
       " 'central': 894,\n",
       " 'centroid': 895,\n",
       " 'certain': 896,\n",
       " 'chain': 897,\n",
       " 'chanceconstrained': 898,\n",
       " 'channel': 899,\n",
       " 'chisquare': 900,\n",
       " 'choice': 901,\n",
       " 'choose': 902,\n",
       " 'circularly': 903,\n",
       " 'closedform': 904,\n",
       " 'cloud': 905,\n",
       " 'collect': 906,\n",
       " 'combination': 907,\n",
       " 'come': 908,\n",
       " 'commonly': 909,\n",
       " 'complement': 910,\n",
       " 'complementary': 911,\n",
       " 'complexity': 912,\n",
       " 'complexvalued': 913,\n",
       " 'compromise': 914,\n",
       " 'computable': 915,\n",
       " 'computation': 916,\n",
       " 'confine': 917,\n",
       " 'conservatism': 918,\n",
       " 'considerable': 919,\n",
       " 'consideration': 920,\n",
       " 'constellation': 921,\n",
       " 'constrained': 922,\n",
       " 'constructive': 923,\n",
       " 'consume': 924,\n",
       " 'consumed': 925,\n",
       " 'consuming': 926,\n",
       " 'containing': 927,\n",
       " 'contrary': 928,\n",
       " 'controlling': 929,\n",
       " 'convenient': 930,\n",
       " 'conveyed': 931,\n",
       " 'correlated': 932,\n",
       " 'correlation': 933,\n",
       " 'corresponds': 934,\n",
       " 'counterpart': 935,\n",
       " 'course': 936,\n",
       " 'covariance': 937,\n",
       " 'criterion': 938,\n",
       " 'csi': 939,\n",
       " 'cumulative': 940,\n",
       " 'dbw': 941,\n",
       " 'deal': 942,\n",
       " 'decompose': 943,\n",
       " 'decomposed': 944,\n",
       " 'decrease': 945,\n",
       " 'decreasing': 946,\n",
       " 'defining': 947,\n",
       " 'definite': 948,\n",
       " 'degradation': 949,\n",
       " 'degraded': 950,\n",
       " 'delayed': 951,\n",
       " 'demanding': 952,\n",
       " 'denoted': 953,\n",
       " 'denoting': 954,\n",
       " 'depicted': 955,\n",
       " 'derivation': 956,\n",
       " 'derived': 957,\n",
       " 'describes': 958,\n",
       " 'designing': 959,\n",
       " 'desired': 960,\n",
       " 'detect': 961,\n",
       " 'detector': 962,\n",
       " 'determines': 963,\n",
       " 'diagonal': 964,\n",
       " 'diagw': 965,\n",
       " 'difficult': 966,\n",
       " 'dimension': 967,\n",
       " 'direction': 968,\n",
       " 'distancepreserving': 969,\n",
       " 'distorted': 970,\n",
       " 'distortion': 971,\n",
       " 'distributed': 972,\n",
       " 'dominated': 973,\n",
       " 'downlink': 974,\n",
       " 'drawn': 975,\n",
       " 'drop': 976,\n",
       " 'duplex': 977,\n",
       " 'earlier': 978,\n",
       " 'efficiency': 979,\n",
       " 'efficient': 980,\n",
       " 'effort': 981,\n",
       " 'elementwise': 982,\n",
       " 'eliminate': 983,\n",
       " 'employing': 984,\n",
       " 'empty': 985,\n",
       " 'encompasses': 986,\n",
       " 'energy': 987,\n",
       " 'ensure': 988,\n",
       " 'ensuring': 989,\n",
       " 'entry': 990,\n",
       " 'entrywise': 991,\n",
       " 'equality': 992,\n",
       " 'equally': 993,\n",
       " 'equation': 994,\n",
       " 'equipped': 995,\n",
       " 'equiprobable': 996,\n",
       " 'equivalent': 997,\n",
       " 'equivalently': 998,\n",
       " 'erfc': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_doc.token2id\n",
    "#corpus_doc[paper_ids_doc.index(paper_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_words = [sections_cleaned['corpus'][0][x][0] for x in range(len(sections_cleaned['corpus'][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonzero_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = sections_df['paper_id']\n",
    "paper_id = paper_ids.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sections_cleaned['corpus']\n",
    "inds = np.where(paper_ids==paper_id)\n",
    "corpus_select = [ corpus[index] for index in inds[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_select = [ corpus[index] for index in inds[0] ]\n",
    "len(corpus_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
