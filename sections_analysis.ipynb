{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "import preprocessing # import Jupyter notebook\n",
    "#from preprocessing import clean_pdf\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avx2\n"
     ]
    }
   ],
   "source": [
    "import tomotopy as tp\n",
    "print(tp.isa) # prints 'avx2', 'avx', 'sse2' or 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "with open('./Dataset/merged/textdata_all.pkl', 'rb') as f:\n",
    "    text_df = pickle.load(f)\n",
    "text_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>key_words</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[Distributional robustness,  Markov decision p...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>Throughout the technical note, we use capital ...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Distributionally robust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56031008</td>\n",
       "      <td>Abstract-The present study attempted to find o...</td>\n",
       "      <td>[listening comprehension,  pre-task activities...</td>\n",
       "      <td>[{'section': 'A. Listening Materials and Activ...</td>\n",
       "      <td>Morley (1991) has explained that in developing...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Listening', 'authors': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88484504</td>\n",
       "      <td>In this paper, we address robust design of sym...</td>\n",
       "      <td>[Downlink MU-MISO,  imperfect CSI,  symbolleve...</td>\n",
       "      <td>[{'section': 'II. SYSTEM AND UNCERTAINTY MODEL...</td>\n",
       "      <td>We consider an MU-MISO wireless broadcast chan...</td>\n",
       "      <td>{'BIBREF0': {'title': 'Convex optimization-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88485902</td>\n",
       "      <td>ABSTRACT A kinematic equation of profiling flo...</td>\n",
       "      <td>[Profiling float,  depth control,  low power c...</td>\n",
       "      <td>[{'section': 'I. INTRODUCTION', 'text': 'With ...</td>\n",
       "      <td>With the increase in the cognition of marine a...</td>\n",
       "      <td>{'BIBREF0': {'title': 'AUV buoyancy regulating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204197524</td>\n",
       "      <td>We characterize practical optical signal recei...</td>\n",
       "      <td>[Optical wireless communications,  multi-stage...</td>\n",
       "      <td>[{'section': 'A. PMT Principle Review', 'text'...</td>\n",
       "      <td>The typical structure of a PMT is shown in Fig...</td>\n",
       "      <td>{'BIBREF0': {'title': 'A statistical non-linea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id                                           abstract  \\\n",
       "0   18980380  This technical note studies Markov decision pr...   \n",
       "1   56031008  Abstract-The present study attempted to find o...   \n",
       "2   88484504  In this paper, we address robust design of sym...   \n",
       "3   88485902  ABSTRACT A kinematic equation of profiling flo...   \n",
       "4  204197524  We characterize practical optical signal recei...   \n",
       "\n",
       "                                           key_words  \\\n",
       "0  [Distributional robustness,  Markov decision p...   \n",
       "1  [listening comprehension,  pre-task activities...   \n",
       "2  [Downlink MU-MISO,  imperfect CSI,  symbolleve...   \n",
       "3  [Profiling float,  depth control,  low power c...   \n",
       "4  [Optical wireless communications,  multi-stage...   \n",
       "\n",
       "                                           body_text  \\\n",
       "0  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "1  [{'section': 'A. Listening Materials and Activ...   \n",
       "2  [{'section': 'II. SYSTEM AND UNCERTAINTY MODEL...   \n",
       "3  [{'section': 'I. INTRODUCTION', 'text': 'With ...   \n",
       "4  [{'section': 'A. PMT Principle Review', 'text'...   \n",
       "\n",
       "                                          whole_text  \\\n",
       "0  Throughout the technical note, we use capital ...   \n",
       "1  Morley (1991) has explained that in developing...   \n",
       "2  We consider an MU-MISO wireless broadcast chan...   \n",
       "3  With the increase in the cognition of marine a...   \n",
       "4  The typical structure of a PMT is shown in Fig...   \n",
       "\n",
       "                                           citations  \n",
       "0  {'BIBREF0': {'title': 'Distributionally robust...  \n",
       "1  {'BIBREF0': {'title': 'Listening', 'authors': ...  \n",
       "2  {'BIBREF0': {'title': 'Convex optimization-bas...  \n",
       "3  {'BIBREF0': {'title': 'AUV buoyancy regulating...  \n",
       "4  {'BIBREF0': {'title': 'A statistical non-linea...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing index to paper_id\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "0.1245725154876709\n",
      "Tokenizing\n",
      "53.112943172454834\n",
      "53.112943172454834\n",
      "53.112943172454834\n",
      "Lemmatizing\n",
      "53.112943172454834\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  158730\n",
      "length of dct after filter_extreme:  25185\n",
      "159.25587630271912\n"
     ]
    }
   ],
   "source": [
    "docs_cleaned = clean_pdf(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4443 4443\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_cleaned['ids']), len(docs_cleaned['corpus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_df = process_sections(text_df)\n",
    "sections_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing index to paper_id\n",
      "0.004000663757324219\n",
      "0.004000663757324219\n",
      "0.004000663757324219\n",
      "0.004000663757324219\n",
      "0.004000663757324219\n",
      "0.004000663757324219\n",
      "Tokenizing\n",
      "5.905099868774414\n",
      "5.905099868774414\n",
      "5.905099868774414\n",
      "Lemmatizing\n",
      "5.906134366989136\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  31656\n",
      "length of dct after filter_extreme:  7942\n",
      "14.717201471328735\n"
     ]
    }
   ],
   "source": [
    "sections_cleaned = clean_section(sections_df, file_name='section_level_kw', output_dir='./Dataset/cleaned/cs-med/',section_lvl = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sections_cleaned['corpus']\n",
    "dct = sections_cleaned['dct']\n",
    "paper_ids = sections_cleaned['ids']\n",
    "docs = sections_cleaned['docs']\n",
    "\n",
    "corpus_doc = docs_cleaned['corpus']\n",
    "dct_doc = docs_cleaned['dct']\n",
    "paper_ids_doc = docs_cleaned['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights\n",
    "weights = np.zeros((len(corpus), len(dct.cfs)))\n",
    "for d_idx,d in enumerate(corpus):\n",
    "\n",
    "    #print(d_idx)\n",
    "    for w_idx, c in enumerate(d):\n",
    "        \n",
    "        # section length\n",
    "        section_length = sum([x[1] for x in d])\n",
    "        \n",
    "        # Calculate section-level weight\n",
    "        weight_section = (c[1] + 1) / (dct.cfs[w_idx] + section_length)\n",
    "        \n",
    "        # Calculate document-level weight\n",
    "        paper_id = paper_ids[d_idx]\n",
    "        ind = paper_ids_doc.index(paper_id)\n",
    "        \n",
    "        # document length\n",
    "        document_length = sum([x[1] for x in corpus_doc[ind]])\n",
    "        \n",
    "        w_idx_doc = dct_doc.token2id[dct[w_idx]]\n",
    "        \n",
    "        count_doc = 0\n",
    "        if w_idx_doc in dict(corpus_doc[ind]).keys():\n",
    "            count_doc = dict(corpus_doc[ind])[w_idx_doc]\n",
    "        \n",
    "        \n",
    "        weight_document = (count_doc + 1) / (dct_doc.cfs[w_idx_doc] + document_length)\n",
    "        \n",
    "        # Combined weight\n",
    "        weight_combined = weight_section*weight_document\n",
    "    \n",
    "        weights[d_idx][w_idx] = weight_combined\n",
    "weights = (weights-np.min(weights)) / (np.max(weights)-np.min(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update gensim corpus with weighted values\n",
    "for d_idx,d in enumerate(corpus):\n",
    "\n",
    "    for w_idx, c in enumerate(d):\n",
    "    \n",
    "        corpus[d_idx][w_idx] = (c[0], float(c[1])*weights[d_idx][w_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model on Document level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tp.LDAModel(k=20)\n",
    "ndocs = len(docs_cleaned['docs'])\n",
    "for i in range(ndocs):\n",
    "    mdl.add_doc(docs_cleaned['docs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tLog-likelihood: -9.47663281550987\n",
      "Iteration: 10\tLog-likelihood: -8.86721221355413\n",
      "Iteration: 20\tLog-likelihood: -8.74557154302517\n",
      "Iteration: 30\tLog-likelihood: -8.687673267927476\n",
      "Iteration: 40\tLog-likelihood: -8.653538452790892\n",
      "Iteration: 50\tLog-likelihood: -8.627985088054904\n",
      "Iteration: 60\tLog-likelihood: -8.610567729187778\n",
      "Iteration: 70\tLog-likelihood: -8.598197550015616\n",
      "Iteration: 80\tLog-likelihood: -8.587164934505635\n",
      "Iteration: 90\tLog-likelihood: -8.577987917970056\n",
      "Top 10 words of topic #0\n",
      "[('network', 0.022928457707166672), ('model', 0.019273199141025543), ('training', 0.015577062033116817), ('layer', 0.014868954196572304), ('learning', 0.01240178570151329), ('image', 0.010084941983222961), ('input', 0.0096141891553998), ('feature', 0.008896850980818272), ('neural', 0.007194491568952799), ('method', 0.006826592143625021)]\n",
      "Top 10 words of topic #1\n",
      "[('frequency', 0.009286560118198395), ('cell', 0.007737402804195881), ('signal', 0.0074073923751711845), ('fig', 0.0071698687970638275), ('response', 0.006631762254983187), ('neuron', 0.0064530945383012295), ('figure', 0.006272324360907078), ('used', 0.005458858795464039), ('field', 0.0048597948625683784), ('using', 0.004658004734665155)]\n",
      "Top 10 words of topic #2\n",
      "[('channel', 0.019562119618058205), ('antenna', 0.0189664289355278), ('system', 0.013218922540545464), ('signal', 0.012841652147471905), ('performance', 0.01175857987254858), ('proposed', 0.00997872930020094), ('number', 0.009626731276512146), ('array', 0.009170034900307655), ('matrix', 0.008624888025224209), ('mimo', 0.007749404292553663)]\n",
      "Top 10 words of topic #3\n",
      "[('object', 0.021154901012778282), ('target', 0.011826188303530216), ('word', 0.011774059385061264), ('model', 0.010413967072963715), ('tracking', 0.009238696657121181), ('sequence', 0.008399894461035728), ('sentence', 0.007288599852472544), ('event', 0.007008999120444059), ('set', 0.00683839526027441), ('query', 0.006317105609923601)]\n",
      "Top 10 words of topic #4\n",
      "[('fuzzy', 0.013083025813102722), ('method', 0.011775380000472069), ('set', 0.00875145010650158), ('operator', 0.008529149927198887), ('value', 0.007695526350289583), ('proposed', 0.007656296715140343), ('based', 0.007179006468504667), ('decision', 0.006096929777413607), ('force', 0.005685021169483662), ('function', 0.005570602137595415)]\n",
      "Top 10 words of topic #5\n",
      "[('data', 0.02457386627793312), ('attack', 0.015202892944216728), ('key', 0.011925443075597286), ('scheme', 0.010302191600203514), ('system', 0.009852070361375809), ('security', 0.009458213113248348), ('file', 0.009401948191225529), ('user', 0.00883929617702961), ('tag', 0.0081950593739748), ('server', 0.007154152262955904)]\n",
      "Top 10 words of topic #6\n",
      "[('channel', 0.03332589939236641), ('rate', 0.01262237224727869), ('user', 0.012264473363757133), ('receiver', 0.010209618136286736), ('capacity', 0.009280864149332047), ('interference', 0.008807010017335415), ('power', 0.008268488571047783), ('scheme', 0.00826402846723795), ('case', 0.008149188943207264), ('probability', 0.007787944283336401)]\n",
      "Top 10 words of topic #7\n",
      "[('study', 0.008149003610014915), ('subject', 0.007809363771229982), ('human', 0.006997078191488981), ('patient', 0.006828445941209793), ('student', 0.006011410150676966), ('activity', 0.005089870188385248), ('game', 0.0045412215404212475), ('group', 0.004260959103703499), ('time', 0.004082826431840658), ('test', 0.003918944392353296)]\n",
      "Top 10 words of topic #8\n",
      "[('system', 0.015544606372714043), ('user', 0.009752622805535793), ('information', 0.007491687778383493), ('data', 0.007379970978945494), ('model', 0.007302833255380392), ('process', 0.007159197237342596), ('research', 0.006971672642976046), ('also', 0.005560582969337702), ('software', 0.005387688521295786), ('application', 0.005218783393502235)]\n",
      "Top 10 words of topic #9\n",
      "[('antenna', 0.015507601201534271), ('power', 0.013707134872674942), ('signal', 0.011148576624691486), ('device', 0.011046132072806358), ('frequency', 0.009135537780821323), ('cell', 0.008710391819477081), ('system', 0.008577213622629642), ('communication', 0.008277562446892262), ('distance', 0.008103406056761742), ('network', 0.007821683771908283)]\n",
      "Top 10 words of topic #10\n",
      "[('problem', 0.0258785467594862), ('power', 0.02165168523788452), ('constraint', 0.017935143783688545), ('user', 0.01637250743806362), ('optimal', 0.016235249117016792), ('energy', 0.013310584239661694), ('optimization', 0.012344494462013245), ('algorithm', 0.01206117868423462), ('solution', 0.011886965483427048), ('proposed', 0.009565887041389942)]\n",
      "Top 10 words of topic #11\n",
      "[('image', 0.06024172157049179), ('pixel', 0.012821798212826252), ('method', 0.011040237732231617), ('fig', 0.00914952252060175), ('frame', 0.008827906101942062), ('video', 0.00772271491587162), ('noise', 0.007399149239063263), ('quality', 0.007030752021819353), ('filter', 0.006954733747988939), ('using', 0.006527860648930073)]\n",
      "Top 10 words of topic #12\n",
      "[('function', 0.017262697219848633), ('model', 0.01390159409493208), ('distribution', 0.01028114277869463), ('state', 0.008634192869067192), ('given', 0.007876028306782246), ('case', 0.007694295607507229), ('point', 0.007625199388712645), ('parameter', 0.007156670559197664), ('value', 0.006254633888602257), ('error', 0.0056923991069197655)]\n",
      "Top 10 words of topic #13\n",
      "[('power', 0.021420901641249657), ('system', 0.019439158961176872), ('control', 0.01582716777920723), ('voltage', 0.01347384974360466), ('current', 0.012191743589937687), ('fig', 0.009612467139959335), ('load', 0.008892746642231941), ('energy', 0.006283342372626066), ('controller', 0.006191285327076912), ('frequency', 0.005620530340820551)]\n",
      "Top 10 words of topic #14\n",
      "[('code', 0.027795681729912758), ('bit', 0.015589387156069279), ('vehicle', 0.012172245420515537), ('error', 0.010189497843384743), ('decoding', 0.010158517397940159), ('block', 0.009944751858711243), ('decoder', 0.00958537869155407), ('memory', 0.00822843611240387), ('number', 0.00651521747931838), ('one', 0.006224001292139292)]\n",
      "Top 10 words of topic #15\n",
      "[('feature', 0.03429762274026871), ('data', 0.020492859184741974), ('method', 0.015134649351239204), ('set', 0.012932883575558662), ('classification', 0.010691061615943909), ('used', 0.010026125237345695), ('class', 0.009242355823516846), ('performance', 0.00894593819975853), ('classifier', 0.00880440603941679), ('result', 0.008199554868042469)]\n",
      "Top 10 words of topic #16\n",
      "[('matrix', 0.020951170474290848), ('algorithm', 0.015096302144229412), ('problem', 0.01492997631430626), ('vector', 0.012816947884857655), ('set', 0.012546299025416374), ('theorem', 0.008107660338282585), ('let', 0.007871458306908607), ('one', 0.006750480271875858), ('solution', 0.006484752520918846), ('following', 0.0062131197191774845)]\n",
      "Top 10 words of topic #17\n",
      "[('data', 0.01869019865989685), ('method', 0.01639966294169426), ('model', 0.016339655965566635), ('time', 0.015135112218558788), ('error', 0.011050201952457428), ('point', 0.010060807690024376), ('measurement', 0.009659781120717525), ('value', 0.009252900257706642), ('proposed', 0.009071413427591324), ('signal', 0.008740639314055443)]\n",
      "Top 10 words of topic #18\n",
      "[('network', 0.03191421553492546), ('node', 0.029134539887309074), ('packet', 0.012759078294038773), ('data', 0.011532786302268505), ('time', 0.010449827648699284), ('protocol', 0.00929336529225111), ('traffic', 0.009212510660290718), ('routing', 0.007798784412443638), ('delay', 0.007098046597093344), ('path', 0.006693774368613958)]\n",
      "Top 10 words of topic #19\n",
      "[('algorithm', 0.025274036452174187), ('node', 0.013044103048741817), ('graph', 0.012041959911584854), ('problem', 0.010708474554121494), ('set', 0.010317624546587467), ('number', 0.01024459395557642), ('solution', 0.010055255144834518), ('time', 0.009319539181888103), ('one', 0.007242221850901842), ('value', 0.007148904725909233)]\n",
      "<Basic Info>\n",
      "| LDAModel (current version: 0.9.1)\n",
      "| 4443 docs, 12362014 words\n",
      "| Total Vocabs: 158730, Used Vocabs: 158730\n",
      "| Entropy of words: -8.20558\n",
      "| Removed Vocabs: <NA>\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 100, Burn-in steps: 0\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.57799\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 0 (the number of top words to be removed)\n",
      "| k: 20 (the number of topics between 1 ~ 32767)\n",
      "| alpha: 0.1 (hyperparameter of Dirichlet distribution for document-topic)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 2822474373 (random seed)\n",
      "| trained in version 0.9.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.08820908 0.07676827 0.07079116 0.08577935 0.07284912 0.05678603\n",
      "|   0.10332404 0.0966609  0.19684212 0.07051063 0.09303188 0.09250981\n",
      "|   0.28963625 0.08802454 0.07394114 0.12481623 0.2080615  0.158369\n",
      "|   0.10770679 0.13484135]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (756772) : network model training layer learning\n",
      "| #1 (474155) : frequency cell signal fig response\n",
      "| #2 (552392) : channel antenna system signal performance\n",
      "| #3 (420443) : object target word model tracking\n",
      "| #4 (304306) : fuzzy method set operator value\n",
      "| #5 (353872) : data attack key scheme system\n",
      "| #6 (895313) : channel rate user receiver capacity\n",
      "| #7 (419447) : study subject human patient student\n",
      "| #8 (750314) : system user information data model\n",
      "| #9 (388867) : antenna power signal device frequency\n",
      "| #10 (566683) : problem power constraint user optimal\n",
      "| #11 (511446) : image pixel method fig frame\n",
      "| #12 (1054911) : function model distribution state given\n",
      "| #13 (595867) : power system control voltage current\n",
      "| #14 (321197) : code bit vehicle error decoding\n",
      "| #15 (747357) : feature data method set classification\n",
      "| #16 (1014490) : matrix algorithm problem vector set\n",
      "| #17 (681659) : data method model time error\n",
      "| #18 (814695) : network node packet data time\n",
      "| #19 (737828) : algorithm node graph problem set\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    mdl.train(10)\n",
    "    print('Iteration: {}\\tLog-likelihood: {}'.format(i, mdl.ll_per_word))\n",
    "\n",
    "for k in range(mdl.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl.get_topic_words(k, top_n=10))\n",
    "\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model on Section level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_section = tp.LDAModel(k=20)\n",
    "ndocs = len(sections_cleaned['docs'])\n",
    "for i in range(ndocs):\n",
    "    mdl_section.add_doc(sections_cleaned['docs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tLog-likelihood: -9.079915884555385\n",
      "Iteration: 10\tLog-likelihood: -8.701078695364467\n",
      "Iteration: 20\tLog-likelihood: -8.564733159888059\n",
      "Iteration: 30\tLog-likelihood: -8.485860552421332\n",
      "Iteration: 40\tLog-likelihood: -8.437313880667375\n",
      "Iteration: 50\tLog-likelihood: -8.396943245529172\n",
      "Iteration: 60\tLog-likelihood: -8.368769717149952\n",
      "Iteration: 70\tLog-likelihood: -8.346425243730684\n",
      "Iteration: 80\tLog-likelihood: -8.323723462836833\n",
      "Iteration: 90\tLog-likelihood: -8.30783522650672\n",
      "Top 10 words of topic #0\n",
      "[('control', 0.04231368750333786), ('system', 0.03068280778825283), ('method', 0.018112976104021072), ('controller', 0.013630240224301815), ('tracking', 0.01278215553611517), ('state', 0.012388401664793491), ('model', 0.01217638049274683), ('target', 0.011812916025519371), ('wind', 0.011722049675881863), ('speed', 0.01126771792769432)]\n",
      "Top 10 words of topic #1\n",
      "[('student', 0.023132802918553352), ('test', 0.012613781727850437), ('learning', 0.011423846706748009), ('teacher', 0.009377159178256989), ('thinking', 0.007806445937603712), ('human', 0.007663653697818518), ('robot', 0.006806900724768639), ('patient', 0.006759303621947765), ('education', 0.006664108484983444), ('emotion', 0.00656891381368041)]\n",
      "Top 10 words of topic #2\n",
      "[('performance', 0.02455917000770569), ('result', 0.023761717602610588), ('fig', 0.02146904170513153), ('method', 0.01877763867378235), ('number', 0.017880504950881004), ('algorithm', 0.017568999901413918), ('proposed', 0.01623575948178768), ('show', 0.013943083584308624), ('table', 0.013768640346825123), ('value', 0.012746904976665974)]\n",
      "Top 10 words of topic #3\n",
      "[('channel', 0.04323789104819298), ('signal', 0.03788627311587334), ('system', 0.016416089609265327), ('receiver', 0.016394853591918945), ('power', 0.013655334711074829), ('transmitter', 0.01306071039289236), ('noise', 0.012487322092056274), ('received', 0.011637859046459198), ('transmission', 0.011531676165759563), ('communication', 0.01104323472827673)]\n",
      "Top 10 words of topic #4\n",
      "[('image', 0.05960092693567276), ('feature', 0.021424809470772743), ('method', 0.016205310821533203), ('pixel', 0.01303535420447588), ('frame', 0.010630560107529163), ('layer', 0.009838070720434189), ('using', 0.009318853728473186), ('video', 0.00855369120836258), ('used', 0.00855369120836258), ('face', 0.008526364341378212)]\n",
      "Top 10 words of topic #5\n",
      "[('power', 0.036858245730400085), ('node', 0.03177640214562416), ('cost', 0.014574077911674976), ('energy', 0.01331822108477354), ('bus', 0.01255886536091566), ('time', 0.01235442329198122), ('uav', 0.012237600050866604), ('vehicle', 0.011770304292440414), ('grid', 0.010777300223708153), ('unit', 0.010017944499850273)]\n",
      "Top 10 words of topic #6\n",
      "[('model', 0.04115471988916397), ('data', 0.02908959425985813), ('feature', 0.021883804351091385), ('method', 0.02086867019534111), ('sample', 0.014877711422741413), ('learning', 0.01273095142096281), ('training', 0.01026800274848938), ('based', 0.009818680584430695), ('set', 0.009785397909581661), ('information', 0.009752114303410053)]\n",
      "Top 10 words of topic #7\n",
      "[('network', 0.03280726820230484), ('time', 0.02321387641131878), ('packet', 0.022005820646882057), ('node', 0.020703013986349106), ('delay', 0.014804854989051819), ('traffic', 0.013502048328518867), ('protocol', 0.011464932933449745), ('data', 0.011109622195363045), ('path', 0.01092012319713831), ('transmission', 0.010754311457276344)]\n",
      "Top 10 words of topic #8\n",
      "[('data', 0.0459626279771328), ('task', 0.024697907269001007), ('tag', 0.013668224215507507), ('time', 0.01071214210242033), ('file', 0.010521427728235722), ('query', 0.010457855649292469), ('cloud', 0.010330712422728539), ('scheme', 0.00979035347700119), ('user', 0.009377137757837772), ('server', 0.007883203215897083)]\n",
      "Top 10 words of topic #9\n",
      "[('matrix', 0.016416391357779503), ('function', 0.01560570951551199), ('given', 0.01363691221922636), ('vector', 0.013443893752992153), ('set', 0.011552304029464722), ('following', 0.010471395216882229), ('value', 0.008898288011550903), ('distribution', 0.007769125048071146), ('case', 0.007691917009651661), ('probability', 0.0073541332967579365)]\n",
      "Top 10 words of topic #10\n",
      "[('user', 0.04879375174641609), ('power', 0.02778218872845173), ('rate', 0.017112983390688896), ('channel', 0.016505982726812363), ('interference', 0.015478751622140408), ('constraint', 0.01333090290427208), ('optimal', 0.009992399252951145), ('number', 0.009945706464350224), ('transmit', 0.008638320490717888), ('scheme', 0.007961281575262547)]\n",
      "Top 10 words of topic #11\n",
      "[('code', 0.04004264622926712), ('bit', 0.02425675466656685), ('sequence', 0.02163860574364662), ('tree', 0.015555262565612793), ('decoder', 0.013899669982492924), ('state', 0.013899669982492924), ('coding', 0.013129626400768757), ('length', 0.010896500200033188), ('node', 0.010126456618309021), ('vertex', 0.009625927545130253)]\n",
      "Top 10 words of topic #12\n",
      "[('tab', 0.01087685115635395), ('surface', 0.01003661472350359), ('material', 0.009663176722824574), ('electrode', 0.00956981722265482), ('area', 0.007702627219259739), ('measurement', 0.007702627219259739), ('soil', 0.007655947469174862), ('study', 0.007469228468835354), ('size', 0.006535633001476526), ('displacement', 0.006535633001476526)]\n",
      "Top 10 words of topic #13\n",
      "[('process', 0.011676382273435593), ('information', 0.0110849067568779), ('group', 0.00904760230332613), ('study', 0.008916163817048073), ('knowledge', 0.007908464409410954), ('level', 0.007557960692793131), ('social', 0.006331196986138821), ('different', 0.005871160421520472), ('result', 0.005674001760780811), ('also', 0.0054330299608409405)]\n",
      "Top 10 words of topic #14\n",
      "[('current', 0.03549019247293472), ('voltage', 0.03330198675394058), ('power', 0.021745523437857628), ('fig', 0.01641177199780941), ('output', 0.011100813746452332), ('switching', 0.00882143247872591), ('fault', 0.008639082312583923), ('device', 0.00850231945514679), ('load', 0.008479525335133076), ('system', 0.008411143906414509)]\n",
      "Top 10 words of topic #15\n",
      "[('layer', 0.027258576825261116), ('field', 0.02336456999182701), ('health', 0.014945094473659992), ('profile', 0.009682921692728996), ('reflectarray', 0.009314569644629955), ('velocity', 0.00826213601976633), ('time', 0.007630675099790096), ('model', 0.006736105773597956), ('state', 0.006736105773597956), ('implant', 0.006052023731172085)]\n",
      "Top 10 words of topic #16\n",
      "[('fig', 0.03103817068040371), ('value', 0.017308082431554794), ('data', 0.012894839979708195), ('filter', 0.011968604288995266), ('point', 0.00958944857120514), ('used', 0.00924438051879406), ('depth', 0.008917474187910557), ('show', 0.00866321288049221), ('result', 0.008227337151765823), ('area', 0.008118368685245514)]\n",
      "Top 10 words of topic #17\n",
      "[('system', 0.02606501244008541), ('section', 0.0140500757843256), ('application', 0.011973927728831768), ('work', 0.01191225927323103), ('paper', 0.011460029520094395), ('based', 0.010154728777706623), ('approach', 0.009774443693459034), ('design', 0.008993319235742092), ('proposed', 0.008541088551282883), ('however', 0.007955244742333889)]\n",
      "Top 10 words of topic #18\n",
      "[('frequency', 0.03343904763460159), ('antenna', 0.02415621094405651), ('phase', 0.014522689394652843), ('signal', 0.010479498654603958), ('gain', 0.009633728303015232), ('fig', 0.008519788272678852), ('harmonic', 0.008065960370004177), ('pulse', 0.007529618684202433), ('mode', 0.007508990354835987), ('used', 0.007364590652287006)]\n",
      "Top 10 words of topic #19\n",
      "[('algorithm', 0.05547569692134857), ('problem', 0.040017981082201004), ('solution', 0.026822369545698166), ('optimization', 0.02073623053729534), ('method', 0.015323336236178875), ('optimal', 0.014623161405324936), ('search', 0.013896056450903416), ('function', 0.013384389691054821), ('objective', 0.010852986946702003), ('number', 0.008994828909635544)]\n",
      "<Basic Info>\n",
      "| LDAModel (current version: 0.9.1)\n",
      "| 2649 docs, 919975 words\n",
      "| Total Vocabs: 31656, Used Vocabs: 31656\n",
      "| Entropy of words: -8.08522\n",
      "| Removed Vocabs: <NA>\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 100, Burn-in steps: 0\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.30784\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 0 (the number of top words to be removed)\n",
      "| k: 20 (the number of topics between 1 ~ 32767)\n",
      "| alpha: 0.1 (hyperparameter of Dirichlet distribution for document-topic)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 2071933282 (random seed)\n",
      "| trained in version 0.9.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.11147358 0.04898655 0.39091882 0.11149627 0.08805504 0.10512307\n",
      "|   0.18919916 0.10280555 0.08995555 0.44135484 0.13120124 0.08908444\n",
      "|   0.05546063 0.19409354 0.10053241 0.0581724  0.2636364  0.4154281\n",
      "|   0.12932767 0.13353641]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (32699) : control system method controller tracking\n",
      "| #1 (20693) : student test learning teacher thinking\n",
      "| #2 (79939) : performance result fig method number\n",
      "| #3 (46772) : channel signal system receiver power\n",
      "| #4 (36277) : image feature method pixel frame\n",
      "| #5 (33923) : power node cost energy bus\n",
      "| #6 (59774) : model data feature method sample\n",
      "| #7 (41900) : network time packet node delay\n",
      "| #8 (31144) : data task tag time file\n",
      "| #9 (103300) : matrix function given vector set\n",
      "| #10 (42517) : user power rate channel interference\n",
      "| #11 (25656) : code bit sequence tree decoder\n",
      "| #12 (21106) : tab surface material electrode area\n",
      "| #13 (45332) : process information group study knowledge\n",
      "| #14 (43555) : current voltage power fig output\n",
      "| #15 (18687) : layer field health profile reflectarray\n",
      "| #16 (54745) : fig value data filter point\n",
      "| #17 (96979) : system section application work paper\n",
      "| #18 (48160) : frequency antenna phase signal gain\n",
      "| #19 (36817) : algorithm problem solution optimization method\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    mdl_section.train(10)\n",
    "    print('Iteration: {}\\tLog-likelihood: {}'.format(i, mdl_section.ll_per_word))\n",
    "\n",
    "for k in range(mdl_section.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl_section.get_topic_words(k, top_n=10))\n",
    "\n",
    "mdl_section.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1216, 1094, 1151, ...,    1,    1,    1], dtype=uint64)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Modify corpus: adding in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4055.5241830036794"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_section.perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the LDA model\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "import logging\n",
    "\n",
    "field = 'cs-med-kw-only'\n",
    "num_topics = 5\n",
    "model_dir= f'./models/{field}/k_{num_topics}/'\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "model_file = model_dir + 'model'\n",
    "# The filename is the file that will be created with the log.\n",
    "# If the file already exists, the log will continue rather than being overwritten.\n",
    "log_file = model_dir + 'model_callbacks.log'\n",
    "logging.basicConfig(filename=log_file,\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.NOTSET)\n",
    "\n",
    "perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "coherence_cv_logger = CoherenceMetric(corpus=corpus, logger='shell', coherence = 'c_v', texts = docs) # very compute intensive\n",
    "coherence_umass_logger = CoherenceMetric(corpus=corpus, logger='shell', coherence = 'u_mass')\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dct,\n",
    "                         random_state=2020,\n",
    "                         num_topics=num_topics,\n",
    "                         passes=100,\n",
    "                         chunksize=100,\n",
    "#                          batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta=None,\n",
    "                         eval_every=0,\n",
    "                         iterations=150,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True,\n",
    "                         callbacks=[perplexity_logger,\n",
    "                                    convergence_logger,\n",
    "#                                     coherence_cv_logger,\n",
    "                                    coherence_umass_logger])\n",
    "\n",
    "lda_model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.005*\"model\" + 0.003*\"fig\" + 0.003*\"method\" + 0.003*\"power\" + 0.003*\"data\" '\n",
      "  '+ 0.003*\"system\" + 0.002*\"value\" + 0.002*\"algorithm\" + 0.002*\"time\" + '\n",
      "  '0.002*\"user\"'),\n",
      " (1,\n",
      "  '0.000*\"epns\" + 0.000*\"elcc\" + 0.000*\"insar\" + 0.000*\"gasser\" + 0.000*\"gait\" '\n",
      "  '+ 0.000*\"mtu\" + 0.000*\"career\" + 0.000*\"anns\" + 0.000*\"fibre\" + '\n",
      "  '0.000*\"coregularization\"'),\n",
      " (2,\n",
      "  '0.000*\"ambiguity\" + 0.000*\"mdp\" + 0.000*\"confidence\" + '\n",
      "  '0.000*\"representable\" + 0.000*\"reward\" + 0.000*\"lifting\" + '\n",
      "  '0.000*\"distributionally\" + 0.000*\"setc\" + 0.000*\"rich\" + 0.000*\"belong\"'),\n",
      " (3,\n",
      "  '0.000*\"epns\" + 0.000*\"elcc\" + 0.000*\"insar\" + 0.000*\"gasser\" + 0.000*\"gait\" '\n",
      "  '+ 0.000*\"mtu\" + 0.000*\"anns\" + 0.000*\"fibre\" + 0.000*\"career\" + '\n",
      "  '0.000*\"coregularization\"'),\n",
      " (4,\n",
      "  '0.000*\"epns\" + 0.000*\"elcc\" + 0.000*\"insar\" + 0.000*\"gasser\" + 0.000*\"gait\" '\n",
      "  '+ 0.000*\"mtu\" + 0.000*\"anns\" + 0.000*\"fibre\" + 0.000*\"career\" + '\n",
      "  '0.000*\"coregularization\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_documents(corpus,ids,topic):\n",
    "    num_topics = 5\n",
    "    topic_proportions = np.zeros(shape=(len(corpus),num_topics+1))\n",
    "    topic_proportions[:,0] = ids\n",
    "    response = lda_model.get_document_topics(corpus)\n",
    "    for i,doc in enumerate(response):\n",
    "        for t,prop in doc:\n",
    "            topic_proportions[i][t+1] = prop \n",
    "    ind = topic_proportions[:,topic+1].argsort()[::-1]\n",
    "    return topic_proportions[ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
