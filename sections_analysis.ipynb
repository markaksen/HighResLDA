{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbimporter\n",
    "#import preprocessing # import Jupyter notebook\n",
    "#from preprocessing import clean_pdf\n",
    "import clean_data\n",
    "import gensim.corpora as corpora\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avx2\n"
     ]
    }
   ],
   "source": [
    "import tomotopy as tp\n",
    "print(tp.isa) # prints 'avx2', 'avx', 'sse2' or 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "# full_data = './Dataset/merged/textdata_all.pkl'\n",
    "final_corpus = './Dataset/merged/final_corpus.pkl'\n",
    "with open(final_corpus, 'rb') as f:\n",
    "    fc_df = pickle.load(f)\n",
    "# text_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16258597373962402\n",
      "0.1627640724182129\n",
      "0.16277790069580078\n",
      "0.16279292106628418\n",
      "0.1628119945526123\n",
      "0.16282987594604492\n",
      "Tokenizing\n",
      "44.19356989860535\n",
      "44.19361114501953\n",
      "44.19361901283264\n",
      "Lemmatizing\n",
      "44.19363307952881\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  156733\n",
      "length of dct after filter_extreme:  10735\n",
      "157.63465309143066\n"
     ]
    }
   ],
   "source": [
    "docs_cleaned = clean_data.clean_pdf(fc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_cleaned_dir = './Dataset/cleaned/final/docs/'\n",
    "docs_cleaned_file = docs_cleaned_dir + 'docs_cleaned.pkl'\n",
    "os.makedirs(docs_cleaned_dir,exist_ok=True)\n",
    "with open(docs_cleaned_file, 'wb') as f:\n",
    "    pickle.dump(docs_cleaned,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_text</th>\n",
       "      <th>section_titles</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Throughout the technical note, we use capital ...</td>\n",
       "      <td>II. PRELIMINARIES</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) The confidence set O ns s is bounded and ha...</td>\n",
       "      <td>Assumption 3 (Regularity Conditions forC s ):</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This section focuses on DAMDP with a finite nu...</td>\n",
       "      <td>III. FINITE HORIZON DISTRIBUTIONALLY ROBUST MDPS</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this section, we study two synthetic numeri...</td>\n",
       "      <td>IV. SIMULATION</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We consider a machine replacement problem simi...</td>\n",
       "      <td>A. Reward Uncertainty in the Machine Replaceme...</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We first consider a machine replacement proble...</td>\n",
       "      <td>1) Machine Replacement as a MDP With Gaussian ...</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The second experiment has a similar setup as t...</td>\n",
       "      <td>2) Machine Replacement as a MDP With Mixed Gau...</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We now consider a path planning problem, simil...</td>\n",
       "      <td>B. Transition Uncertainty in the Path Planning...</td>\n",
       "      <td>18980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morley (1991) has explained that in developing...</td>\n",
       "      <td>A. Listening Materials and Activities</td>\n",
       "      <td>56031008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prior knowledge in listener\"s mind entails the...</td>\n",
       "      <td>B. Schema Theory and Background Knowledge</td>\n",
       "      <td>56031008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          whole_text  \\\n",
       "0  Throughout the technical note, we use capital ...   \n",
       "1  1) The confidence set O ns s is bounded and ha...   \n",
       "2  This section focuses on DAMDP with a finite nu...   \n",
       "3  In this section, we study two synthetic numeri...   \n",
       "4  We consider a machine replacement problem simi...   \n",
       "5  We first consider a machine replacement proble...   \n",
       "6  The second experiment has a similar setup as t...   \n",
       "7  We now consider a path planning problem, simil...   \n",
       "0  Morley (1991) has explained that in developing...   \n",
       "1  Prior knowledge in listener\"s mind entails the...   \n",
       "\n",
       "                                      section_titles  paper_id  \n",
       "0                                  II. PRELIMINARIES  18980380  \n",
       "1      Assumption 3 (Regularity Conditions forC s ):  18980380  \n",
       "2   III. FINITE HORIZON DISTRIBUTIONALLY ROBUST MDPS  18980380  \n",
       "3                                     IV. SIMULATION  18980380  \n",
       "4  A. Reward Uncertainty in the Machine Replaceme...  18980380  \n",
       "5  1) Machine Replacement as a MDP With Gaussian ...  18980380  \n",
       "6  2) Machine Replacement as a MDP With Mixed Gau...  18980380  \n",
       "7  B. Transition Uncertainty in the Path Planning...  18980380  \n",
       "0              A. Listening Materials and Activities  56031008  \n",
       "1          B. Schema Theory and Background Knowledge  56031008  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections_df = clean_data.process_sections(fc_df)\n",
    "sections_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing index to paper_id\n",
      "0.8703620433807373\n",
      "0.8704631328582764\n",
      "0.870474100112915\n",
      "0.8704822063446045\n",
      "0.8704900741577148\n",
      "0.8704988956451416\n",
      "Tokenizing\n",
      "41.65893006324768\n",
      "41.658942222595215\n",
      "41.658950090408325\n",
      "Lemmatizing\n",
      "41.65896487236023\n",
      "Bag of Words Representation\n",
      "length of dct before filter_extreme:  144802\n",
      "length of dct after filter_extreme:  13165\n",
      "152.77748107910156\n"
     ]
    }
   ],
   "source": [
    "sections_cleaned = clean_data.clean_section(sections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13165"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sections_cleaned['dct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_cleaned_dir = './Dataset/cleaned/final/sections/'\n",
    "sections_cleaned_file = sections_cleaned_dir + 'sections_cleaned.pkl'\n",
    "os.makedirs(sections_cleaned_dir,exist_ok=True)\n",
    "with open(sections_cleaned_file,'wb') as f:\n",
    "    pickle.dump(sections_cleaned,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sections_cleaned['corpus']\n",
    "dct = sections_cleaned['dct']\n",
    "paper_ids = sections_cleaned['ids']\n",
    "docs = sections_cleaned['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_doc = docs_cleaned['corpus']\n",
    "dct_doc = docs_cleaned['dct']\n",
    "paper_ids_doc = docs_cleaned['ids']\n",
    "docs_doc = docs_cleaned['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-07f54f02a75b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(d_idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate weights\n",
    "weights = np.zeros((len(corpus), len(dct.cfs)))\n",
    "for d_idx,d in enumerate(corpus):\n",
    "\n",
    "    #print(d_idx)\n",
    "    for w_idx, c in enumerate(d):\n",
    "        \n",
    "        # section length\n",
    "        section_length = sum([x[1] for x in d])\n",
    "        \n",
    "        # Calculate section-level weight\n",
    "        weight_section = (c[1] + 1) / (dct.cfs[w_idx] + section_length)\n",
    "        \n",
    "        # Calculate document-level weight\n",
    "        paper_id = paper_ids[d_idx]\n",
    "        ind = paper_ids_doc.index(paper_id)\n",
    "        \n",
    "        # document length\n",
    "        document_length = sum([x[1] for x in corpus_doc[ind]])\n",
    "        \n",
    "        w_idx_doc = dct_doc.token2id[dct[w_idx]]\n",
    "        \n",
    "        count_doc = 0\n",
    "        if w_idx_doc in dict(corpus_doc[ind]).keys():\n",
    "            count_doc = dict(corpus_doc[ind])[w_idx_doc]\n",
    "        \n",
    "        \n",
    "        weight_document = (count_doc + 1) / (dct_doc.cfs[w_idx_doc] + document_length)\n",
    "        \n",
    "        # Combined weight\n",
    "        weight_combined = weight_section*weight_document\n",
    "    \n",
    "        weights[d_idx][w_idx] = weight_combined\n",
    "weights = (weights-np.min(weights)) / (np.max(weights)-np.min(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update gensim corpus with weighted values\n",
    "for d_idx,d in enumerate(corpus):\n",
    "\n",
    "    for w_idx, c in enumerate(d):\n",
    "    \n",
    "        corpus[d_idx][w_idx] = (c[0], float(c[1])*weights[d_idx][w_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model on Document level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = tp.LDAModel(k=20)\n",
    "ndocs = len(docs_cleaned['docs'])\n",
    "for i in range(ndocs):\n",
    "    mdl.add_doc(docs_cleaned['docs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(mdl.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tLog-likelihood: -9.52556707920659\n",
      "Iteration: 10\tLog-likelihood: -8.886778533761598\n",
      "Iteration: 20\tLog-likelihood: -8.749836794938812\n",
      "Iteration: 30\tLog-likelihood: -8.685682991883231\n",
      "Iteration: 40\tLog-likelihood: -8.647496887347124\n",
      "Iteration: 50\tLog-likelihood: -8.621290559515279\n",
      "Iteration: 60\tLog-likelihood: -8.602533973124823\n",
      "Iteration: 70\tLog-likelihood: -8.590162400043251\n",
      "Iteration: 80\tLog-likelihood: -8.578226996558925\n",
      "Iteration: 90\tLog-likelihood: -8.56970758550309\n",
      "Top 10 words of topic #0\n",
      "[('channel', 0.029091021046042442), ('system', 0.01907355710864067), ('signal', 0.01591496169567108), ('performance', 0.013407456688582897), ('antenna', 0.012973396107554436), ('proposed', 0.009926006197929382), ('number', 0.008652524091303349), ('power', 0.007875879295170307), ('mimo', 0.007727006915956736), ('symbol', 0.007357517722994089)]\n",
      "Top 10 words of topic #1\n",
      "[('image', 0.031919896602630615), ('feature', 0.01562705636024475), ('method', 0.01201371755450964), ('layer', 0.0073427241295576096), ('network', 0.006943250074982643), ('object', 0.006792971398681402), ('training', 0.00679202051833272), ('proposed', 0.0067863138392567635), ('result', 0.006555189378559589), ('frame', 0.006262241862714291)]\n",
      "Top 10 words of topic #2\n",
      "[('time', 0.013695592060685158), ('task', 0.012307307682931423), ('neuron', 0.011278728954494), ('memory', 0.009028339758515358), ('input', 0.00900753028690815), ('circuit', 0.00796111486852169), ('processor', 0.0060644857585430145), ('operation', 0.005927738267928362), ('fig', 0.005657216068357229), ('output', 0.005630461033433676)]\n",
      "Top 10 words of topic #3\n",
      "[('study', 0.007313252426683903), ('one', 0.006092757452279329), ('information', 0.005178081803023815), ('research', 0.005072435364127159), ('may', 0.004786077421158552), ('would', 0.004720743745565414), ('also', 0.0046595800668001175), ('use', 0.004139687865972519), ('group', 0.004107716027647257), ('process', 0.00408269464969635)]\n",
      "Top 10 words of topic #4\n",
      "[('matrix', 0.01739809848368168), ('signal', 0.013372327201068401), ('noise', 0.00921611674129963), ('error', 0.008163223043084145), ('function', 0.007905160076916218), ('model', 0.007750323042273521), ('estimate', 0.007145988289266825), ('distribution', 0.006755610462278128), ('estimation', 0.006583881564438343), ('measurement', 0.006496609654277563)]\n",
      "Top 10 words of topic #5\n",
      "[('system', 0.03229200467467308), ('control', 0.016104692593216896), ('power', 0.012101703323423862), ('energy', 0.010811717249453068), ('fault', 0.00913876574486494), ('sensor', 0.00872556772083044), ('state', 0.007788312155753374), ('cost', 0.007766140624880791), ('network', 0.007687531877309084), ('data', 0.0067905886098742485)]\n",
      "Top 10 words of topic #6\n",
      "[('data', 0.026552217081189156), ('feature', 0.0227117370814085), ('method', 0.014000769704580307), ('set', 0.012499834410846233), ('model', 0.011954612098634243), ('used', 0.009505517780780792), ('result', 0.00942870881408453), ('number', 0.009160504676401615), ('algorithm', 0.009069844149053097), ('classification', 0.008797862567007542)]\n",
      "Top 10 words of topic #7\n",
      "[('set', 0.01079859770834446), ('state', 0.009867796674370766), ('point', 0.008756875060498714), ('one', 0.008367513306438923), ('function', 0.007688018027693033), ('case', 0.006775552406907082), ('graph', 0.006773395463824272), ('given', 0.006599746644496918), ('space', 0.0060313427820801735), ('time', 0.005692673847079277)]\n",
      "Top 10 words of topic #8\n",
      "[('channel', 0.026707960292696953), ('power', 0.015988901257514954), ('rate', 0.012178925797343254), ('user', 0.011567849665880203), ('receiver', 0.009465523064136505), ('capacity', 0.008991238661110401), ('case', 0.00883874949067831), ('interference', 0.008348767645657063), ('given', 0.007741055451333523), ('optimal', 0.0073777735233306885)]\n",
      "Top 10 words of topic #9\n",
      "[('model', 0.04041804000735283), ('network', 0.024223852902650833), ('input', 0.013620122335851192), ('learning', 0.0129235265776515), ('training', 0.012399421073496342), ('word', 0.011196412146091461), ('neural', 0.01016810443252325), ('output', 0.008878850378096104), ('layer', 0.0076139215379953384), ('sentence', 0.006758104078471661)]\n",
      "Top 10 words of topic #10\n",
      "[('user', 0.019718144088983536), ('network', 0.017979100346565247), ('cell', 0.010155334137380123), ('uav', 0.009928335435688496), ('power', 0.009922564029693604), ('interference', 0.007894963957369328), ('communication', 0.007869956083595753), ('resource', 0.007113934028893709), ('scheme', 0.006883087567985058), ('uavs', 0.0064406320452690125)]\n",
      "Top 10 words of topic #11\n",
      "[('set', 0.016269445419311523), ('fuzzy', 0.015610642731189728), ('method', 0.013827331364154816), ('value', 0.012138674966990948), ('operator', 0.011665397323668003), ('proposed', 0.010226631537079811), ('decision', 0.00995402317494154), ('rule', 0.009901016019284725), ('function', 0.009098337031900883), ('information', 0.008621272630989552)]\n",
      "Top 10 words of topic #12\n",
      "[('code', 0.022846674546599388), ('bit', 0.01531678531318903), ('scheme', 0.013820359483361244), ('coding', 0.010668312199413776), ('block', 0.009635823778808117), ('decoder', 0.009472081437706947), ('decoding', 0.008616981096565723), ('error', 0.0075640249997377396), ('vector', 0.00742757273837924), ('set', 0.00693861860781908)]\n",
      "Top 10 words of topic #13\n",
      "[('antenna', 0.02220609411597252), ('tag', 0.013097163289785385), ('frequency', 0.012273511849343777), ('device', 0.012081146240234375), ('signal', 0.00827717874199152), ('fig', 0.007128402590751648), ('power', 0.006968548987060785), ('backscatter', 0.00619637593626976), ('measurement', 0.006180119700729847), ('ghz', 0.006096129305660725)]\n",
      "Top 10 words of topic #14\n",
      "[('point', 0.012091930024325848), ('image', 0.009126449003815651), ('fig', 0.00756007619202137), ('cell', 0.006601783912628889), ('method', 0.0063108112663030624), ('data', 0.006180135067552328), ('using', 0.006110440939664841), ('surface', 0.006026808172464371), ('figure', 0.005997187923640013), ('used', 0.0054675135761499405)]\n",
      "Top 10 words of topic #15\n",
      "[('power', 0.012774285860359669), ('voltage', 0.012642964720726013), ('current', 0.011789376847445965), ('fig', 0.009827766567468643), ('system', 0.008419346995651722), ('control', 0.008248629048466682), ('model', 0.007933458313345909), ('method', 0.0064363968558609486), ('load', 0.006411774083971977), ('shown', 0.006267320830374956)]\n",
      "Top 10 words of topic #16\n",
      "[('subject', 0.011939333751797676), ('face', 0.011024074628949165), ('patient', 0.010559003800153732), ('study', 0.006931451614946127), ('facial', 0.006432896014302969), ('activity', 0.005566003732383251), ('time', 0.005320446565747261), ('recognition', 0.005201388616114855), ('movement', 0.005190226715058088), ('eeg', 0.004914904944598675)]\n",
      "Top 10 words of topic #17\n",
      "[('data', 0.0302360188215971), ('user', 0.018693897873163223), ('system', 0.01314627192914486), ('attack', 0.010054496116936207), ('service', 0.009311629459261894), ('application', 0.008857125416398048), ('server', 0.007394309155642986), ('file', 0.006941714324057102), ('query', 0.006716371513903141), ('cloud', 0.006565507035702467)]\n",
      "Top 10 words of topic #18\n",
      "[('node', 0.04724924638867378), ('network', 0.029141448438167572), ('packet', 0.01661069504916668), ('time', 0.012368072755634785), ('protocol', 0.011241712607443333), ('path', 0.010293693281710148), ('routing', 0.009979250840842724), ('data', 0.009326901286840439), ('traffic', 0.008485259488224983), ('number', 0.008228699676692486)]\n",
      "Top 10 words of topic #19\n",
      "[('algorithm', 0.04235255718231201), ('problem', 0.035040367394685745), ('solution', 0.020991800352931023), ('optimization', 0.01309486199170351), ('method', 0.012437436729669571), ('set', 0.011708454228937626), ('constraint', 0.011181842535734177), ('optimal', 0.01049534697085619), ('function', 0.010260551236569881), ('number', 0.009372803382575512)]\n",
      "<Basic Info>\n",
      "| LDAModel (current version: 0.9.1)\n",
      "| 4443 docs, 12362014 words\n",
      "| Total Vocabs: 158730, Used Vocabs: 158730\n",
      "| Entropy of words: -8.20558\n",
      "| Removed Vocabs: <NA>\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 100, Burn-in steps: 0\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.56971\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 0 (the number of top words to be removed)\n",
      "| k: 20 (the number of topics between 1 ~ 32767)\n",
      "| alpha: 0.1 (hyperparameter of Dirichlet distribution for document-topic)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 405888423 (random seed)\n",
      "| trained in version 0.9.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.08256951 0.10977578 0.06634394 0.18908414 0.22528175 0.13510013\n",
      "|   0.14418863 0.2178729  0.09817056 0.07656943 0.06477635 0.06462894\n",
      "|   0.07498678 0.05804654 0.11041101 0.09681123 0.04361023 0.0974049\n",
      "|   0.08896925 0.2011863 ]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (555939) : channel system signal performance antenna\n",
      "| #1 (1049795) : image feature method layer network\n",
      "| #2 (334799) : time task neuron memory input\n",
      "| #3 (717793) : study one information research may\n",
      "| #4 (1064047) : matrix signal noise error function\n",
      "| #5 (494542) : system control power energy fault\n",
      "| #6 (792584) : data feature method set model\n",
      "| #7 (925571) : set state point one function\n",
      "| #8 (890282) : channel power rate user receiver\n",
      "| #9 (450612) : model network input learning training\n",
      "| #10 (518239) : user network cell uav power\n",
      "| #11 (262528) : set fuzzy method value operator\n",
      "| #12 (438127) : code bit scheme coding block\n",
      "| #13 (367501) : antenna tag frequency device signal\n",
      "| #14 (572350) : point image fig cell method\n",
      "| #15 (607606) : power voltage current fig system\n",
      "| #16 (267189) : subject face patient study facial\n",
      "| #17 (522060) : data user system attack service\n",
      "| #18 (637640) : node network packet time protocol\n",
      "| #19 (892810) : algorithm problem solution optimization method\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    mdl.train(10)\n",
    "    print('Iteration: {}\\tLog-likelihood: {}'.format(i, mdl.ll_per_word))\n",
    "\n",
    "for k in range(mdl.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl.get_topic_words(k, top_n=10))\n",
    "\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tomotopy.LDAModel' object has no attribute 'coherence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9f99c62f1465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoherence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tomotopy.LDAModel' object has no attribute 'coherence'"
     ]
    }
   ],
   "source": [
    "mdl.perplexity, mdl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model on Section level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_section = tp.LDAModel(k=20)\n",
    "ndocs = len(sections_cleaned['docs'])\n",
    "for i in range(ndocs):\n",
    "    mdl_section.add_doc(sections_cleaned['docs'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\tLog-likelihood: -9.079915884555385\n",
      "Iteration: 10\tLog-likelihood: -8.701078695364467\n",
      "Iteration: 20\tLog-likelihood: -8.564733159888059\n",
      "Iteration: 30\tLog-likelihood: -8.485860552421332\n",
      "Iteration: 40\tLog-likelihood: -8.437313880667375\n",
      "Iteration: 50\tLog-likelihood: -8.396943245529172\n",
      "Iteration: 60\tLog-likelihood: -8.368769717149952\n",
      "Iteration: 70\tLog-likelihood: -8.346425243730684\n",
      "Iteration: 80\tLog-likelihood: -8.323723462836833\n",
      "Iteration: 90\tLog-likelihood: -8.30783522650672\n",
      "Top 10 words of topic #0\n",
      "[('control', 0.04231368750333786), ('system', 0.03068280778825283), ('method', 0.018112976104021072), ('controller', 0.013630240224301815), ('tracking', 0.01278215553611517), ('state', 0.012388401664793491), ('model', 0.01217638049274683), ('target', 0.011812916025519371), ('wind', 0.011722049675881863), ('speed', 0.01126771792769432)]\n",
      "Top 10 words of topic #1\n",
      "[('student', 0.023132802918553352), ('test', 0.012613781727850437), ('learning', 0.011423846706748009), ('teacher', 0.009377159178256989), ('thinking', 0.007806445937603712), ('human', 0.007663653697818518), ('robot', 0.006806900724768639), ('patient', 0.006759303621947765), ('education', 0.006664108484983444), ('emotion', 0.00656891381368041)]\n",
      "Top 10 words of topic #2\n",
      "[('performance', 0.02455917000770569), ('result', 0.023761717602610588), ('fig', 0.02146904170513153), ('method', 0.01877763867378235), ('number', 0.017880504950881004), ('algorithm', 0.017568999901413918), ('proposed', 0.01623575948178768), ('show', 0.013943083584308624), ('table', 0.013768640346825123), ('value', 0.012746904976665974)]\n",
      "Top 10 words of topic #3\n",
      "[('channel', 0.04323789104819298), ('signal', 0.03788627311587334), ('system', 0.016416089609265327), ('receiver', 0.016394853591918945), ('power', 0.013655334711074829), ('transmitter', 0.01306071039289236), ('noise', 0.012487322092056274), ('received', 0.011637859046459198), ('transmission', 0.011531676165759563), ('communication', 0.01104323472827673)]\n",
      "Top 10 words of topic #4\n",
      "[('image', 0.05960092693567276), ('feature', 0.021424809470772743), ('method', 0.016205310821533203), ('pixel', 0.01303535420447588), ('frame', 0.010630560107529163), ('layer', 0.009838070720434189), ('using', 0.009318853728473186), ('video', 0.00855369120836258), ('used', 0.00855369120836258), ('face', 0.008526364341378212)]\n",
      "Top 10 words of topic #5\n",
      "[('power', 0.036858245730400085), ('node', 0.03177640214562416), ('cost', 0.014574077911674976), ('energy', 0.01331822108477354), ('bus', 0.01255886536091566), ('time', 0.01235442329198122), ('uav', 0.012237600050866604), ('vehicle', 0.011770304292440414), ('grid', 0.010777300223708153), ('unit', 0.010017944499850273)]\n",
      "Top 10 words of topic #6\n",
      "[('model', 0.04115471988916397), ('data', 0.02908959425985813), ('feature', 0.021883804351091385), ('method', 0.02086867019534111), ('sample', 0.014877711422741413), ('learning', 0.01273095142096281), ('training', 0.01026800274848938), ('based', 0.009818680584430695), ('set', 0.009785397909581661), ('information', 0.009752114303410053)]\n",
      "Top 10 words of topic #7\n",
      "[('network', 0.03280726820230484), ('time', 0.02321387641131878), ('packet', 0.022005820646882057), ('node', 0.020703013986349106), ('delay', 0.014804854989051819), ('traffic', 0.013502048328518867), ('protocol', 0.011464932933449745), ('data', 0.011109622195363045), ('path', 0.01092012319713831), ('transmission', 0.010754311457276344)]\n",
      "Top 10 words of topic #8\n",
      "[('data', 0.0459626279771328), ('task', 0.024697907269001007), ('tag', 0.013668224215507507), ('time', 0.01071214210242033), ('file', 0.010521427728235722), ('query', 0.010457855649292469), ('cloud', 0.010330712422728539), ('scheme', 0.00979035347700119), ('user', 0.009377137757837772), ('server', 0.007883203215897083)]\n",
      "Top 10 words of topic #9\n",
      "[('matrix', 0.016416391357779503), ('function', 0.01560570951551199), ('given', 0.01363691221922636), ('vector', 0.013443893752992153), ('set', 0.011552304029464722), ('following', 0.010471395216882229), ('value', 0.008898288011550903), ('distribution', 0.007769125048071146), ('case', 0.007691917009651661), ('probability', 0.0073541332967579365)]\n",
      "Top 10 words of topic #10\n",
      "[('user', 0.04879375174641609), ('power', 0.02778218872845173), ('rate', 0.017112983390688896), ('channel', 0.016505982726812363), ('interference', 0.015478751622140408), ('constraint', 0.01333090290427208), ('optimal', 0.009992399252951145), ('number', 0.009945706464350224), ('transmit', 0.008638320490717888), ('scheme', 0.007961281575262547)]\n",
      "Top 10 words of topic #11\n",
      "[('code', 0.04004264622926712), ('bit', 0.02425675466656685), ('sequence', 0.02163860574364662), ('tree', 0.015555262565612793), ('decoder', 0.013899669982492924), ('state', 0.013899669982492924), ('coding', 0.013129626400768757), ('length', 0.010896500200033188), ('node', 0.010126456618309021), ('vertex', 0.009625927545130253)]\n",
      "Top 10 words of topic #12\n",
      "[('tab', 0.01087685115635395), ('surface', 0.01003661472350359), ('material', 0.009663176722824574), ('electrode', 0.00956981722265482), ('area', 0.007702627219259739), ('measurement', 0.007702627219259739), ('soil', 0.007655947469174862), ('study', 0.007469228468835354), ('size', 0.006535633001476526), ('displacement', 0.006535633001476526)]\n",
      "Top 10 words of topic #13\n",
      "[('process', 0.011676382273435593), ('information', 0.0110849067568779), ('group', 0.00904760230332613), ('study', 0.008916163817048073), ('knowledge', 0.007908464409410954), ('level', 0.007557960692793131), ('social', 0.006331196986138821), ('different', 0.005871160421520472), ('result', 0.005674001760780811), ('also', 0.0054330299608409405)]\n",
      "Top 10 words of topic #14\n",
      "[('current', 0.03549019247293472), ('voltage', 0.03330198675394058), ('power', 0.021745523437857628), ('fig', 0.01641177199780941), ('output', 0.011100813746452332), ('switching', 0.00882143247872591), ('fault', 0.008639082312583923), ('device', 0.00850231945514679), ('load', 0.008479525335133076), ('system', 0.008411143906414509)]\n",
      "Top 10 words of topic #15\n",
      "[('layer', 0.027258576825261116), ('field', 0.02336456999182701), ('health', 0.014945094473659992), ('profile', 0.009682921692728996), ('reflectarray', 0.009314569644629955), ('velocity', 0.00826213601976633), ('time', 0.007630675099790096), ('model', 0.006736105773597956), ('state', 0.006736105773597956), ('implant', 0.006052023731172085)]\n",
      "Top 10 words of topic #16\n",
      "[('fig', 0.03103817068040371), ('value', 0.017308082431554794), ('data', 0.012894839979708195), ('filter', 0.011968604288995266), ('point', 0.00958944857120514), ('used', 0.00924438051879406), ('depth', 0.008917474187910557), ('show', 0.00866321288049221), ('result', 0.008227337151765823), ('area', 0.008118368685245514)]\n",
      "Top 10 words of topic #17\n",
      "[('system', 0.02606501244008541), ('section', 0.0140500757843256), ('application', 0.011973927728831768), ('work', 0.01191225927323103), ('paper', 0.011460029520094395), ('based', 0.010154728777706623), ('approach', 0.009774443693459034), ('design', 0.008993319235742092), ('proposed', 0.008541088551282883), ('however', 0.007955244742333889)]\n",
      "Top 10 words of topic #18\n",
      "[('frequency', 0.03343904763460159), ('antenna', 0.02415621094405651), ('phase', 0.014522689394652843), ('signal', 0.010479498654603958), ('gain', 0.009633728303015232), ('fig', 0.008519788272678852), ('harmonic', 0.008065960370004177), ('pulse', 0.007529618684202433), ('mode', 0.007508990354835987), ('used', 0.007364590652287006)]\n",
      "Top 10 words of topic #19\n",
      "[('algorithm', 0.05547569692134857), ('problem', 0.040017981082201004), ('solution', 0.026822369545698166), ('optimization', 0.02073623053729534), ('method', 0.015323336236178875), ('optimal', 0.014623161405324936), ('search', 0.013896056450903416), ('function', 0.013384389691054821), ('objective', 0.010852986946702003), ('number', 0.008994828909635544)]\n",
      "<Basic Info>\n",
      "| LDAModel (current version: 0.9.1)\n",
      "| 2649 docs, 919975 words\n",
      "| Total Vocabs: 31656, Used Vocabs: 31656\n",
      "| Entropy of words: -8.08522\n",
      "| Removed Vocabs: <NA>\n",
      "|\n",
      "<Training Info>\n",
      "| Iterations: 100, Burn-in steps: 0\n",
      "| Optimization Interval: 10\n",
      "| Log-likelihood per word: -8.30784\n",
      "|\n",
      "<Initial Parameters>\n",
      "| tw: TermWeight.ONE\n",
      "| min_cf: 0 (minimum collection frequency of words)\n",
      "| min_df: 0 (minimum document frequency of words)\n",
      "| rm_top: 0 (the number of top words to be removed)\n",
      "| k: 20 (the number of topics between 1 ~ 32767)\n",
      "| alpha: 0.1 (hyperparameter of Dirichlet distribution for document-topic)\n",
      "| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)\n",
      "| seed: 2071933282 (random seed)\n",
      "| trained in version 0.9.1\n",
      "|\n",
      "<Parameters>\n",
      "| alpha (Dirichlet prior on the per-document topic distributions)\n",
      "|  [0.11147358 0.04898655 0.39091882 0.11149627 0.08805504 0.10512307\n",
      "|   0.18919916 0.10280555 0.08995555 0.44135484 0.13120124 0.08908444\n",
      "|   0.05546063 0.19409354 0.10053241 0.0581724  0.2636364  0.4154281\n",
      "|   0.12932767 0.13353641]\n",
      "| eta (Dirichlet prior on the per-topic word distribution)\n",
      "|  0.01\n",
      "|\n",
      "<Topics>\n",
      "| #0 (32699) : control system method controller tracking\n",
      "| #1 (20693) : student test learning teacher thinking\n",
      "| #2 (79939) : performance result fig method number\n",
      "| #3 (46772) : channel signal system receiver power\n",
      "| #4 (36277) : image feature method pixel frame\n",
      "| #5 (33923) : power node cost energy bus\n",
      "| #6 (59774) : model data feature method sample\n",
      "| #7 (41900) : network time packet node delay\n",
      "| #8 (31144) : data task tag time file\n",
      "| #9 (103300) : matrix function given vector set\n",
      "| #10 (42517) : user power rate channel interference\n",
      "| #11 (25656) : code bit sequence tree decoder\n",
      "| #12 (21106) : tab surface material electrode area\n",
      "| #13 (45332) : process information group study knowledge\n",
      "| #14 (43555) : current voltage power fig output\n",
      "| #15 (18687) : layer field health profile reflectarray\n",
      "| #16 (54745) : fig value data filter point\n",
      "| #17 (96979) : system section application work paper\n",
      "| #18 (48160) : frequency antenna phase signal gain\n",
      "| #19 (36817) : algorithm problem solution optimization method\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    mdl_section.train(10)\n",
    "    print('Iteration: {}\\tLog-likelihood: {}'.format(i, mdl_section.ll_per_word))\n",
    "\n",
    "for k in range(mdl_section.k):\n",
    "    print('Top 10 words of topic #{}'.format(k))\n",
    "    print(mdl_section.get_topic_words(k, top_n=10))\n",
    "\n",
    "mdl_section.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1216, 1094, 1151, ...,    1,    1,    1], dtype=uint64)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Modify corpus: adding in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl_section.perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the LDA model\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "import logging\n",
    "\n",
    "field = 'cs-med-kw-only'\n",
    "num_topics = 20\n",
    "model_dir= f'./models/{field}/k_{num_topics}/'\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "model_file = model_dir + 'model'\n",
    "# The filename is the file that will be created with the log.\n",
    "# If the file already exists, the log will continue rather than being overwritten.\n",
    "log_file = model_dir + 'model_callbacks.log'\n",
    "# log_file = 'model_callbacks_test.log'\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(filename=log_file,\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "perplexity_logger = PerplexityMetric(corpus=corpus_doc, logger='shell')\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "coherence_cv_logger = CoherenceMetric(corpus=corpus_doc, logger='shell', coherence = 'c_v', texts = docs_doc) # very compute intensive\n",
    "coherence_umass_logger = CoherenceMetric(corpus=corpus_doc, logger='shell', coherence = 'u_mass')\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus_doc,\n",
    "                         id2word=dct_doc,\n",
    "                         random_state=2020,\n",
    "                         num_topics=num_topics,\n",
    "                         passes=1,\n",
    "                         chunksize=1000,\n",
    "#                          batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta='auto',\n",
    "                         eval_every=0,\n",
    "                         iterations=100,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True,\n",
    "                         callbacks=[perplexity_logger,\n",
    "                                    convergence_logger])\n",
    "#                                     coherence_cv_logger,\n",
    "                                    #coherence_umass_logger])\n",
    "\n",
    "lda_model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.011*\"image\" + 0.010*\"feature\" + 0.007*\"method\" + 0.007*\"model\" + '\n",
      "  '0.006*\"used\" + 0.005*\"set\" + 0.005*\"using\" + 0.005*\"data\" + 0.005*\"result\" '\n",
      "  '+ 0.005*\"training\"'),\n",
      " (1,\n",
      "  '0.007*\"channel\" + 0.007*\"algorithm\" + 0.007*\"problem\" + 0.005*\"power\" + '\n",
      "  '0.005*\"set\" + 0.005*\"number\" + 0.005*\"system\" + 0.005*\"function\" + '\n",
      "  '0.004*\"case\" + 0.004*\"one\"'),\n",
      " (2,\n",
      "  '0.002*\"data\" + 0.002*\"time\" + 0.001*\"system\" + 0.001*\"power\" + '\n",
      "  '0.001*\"method\" + 0.001*\"value\" + 0.001*\"result\" + 0.001*\"network\" + '\n",
      "  '0.001*\"algorithm\" + 0.001*\"based\"'),\n",
      " (3,\n",
      "  '0.002*\"user\" + 0.002*\"power\" + 0.002*\"channel\" + 0.002*\"algorithm\" + '\n",
      "  '0.002*\"system\" + 0.002*\"data\" + 0.001*\"number\" + 0.001*\"time\" + 0.001*\"two\" '\n",
      "  '+ 0.001*\"proposed\"'),\n",
      " (4,\n",
      "  '0.001*\"method\" + 0.001*\"system\" + 0.001*\"data\" + 0.001*\"time\" + '\n",
      "  '0.001*\"value\" + 0.001*\"number\" + 0.001*\"result\" + 0.001*\"two\" + 0.001*\"set\" '\n",
      "  '+ 0.001*\"different\"'),\n",
      " (5,\n",
      "  '0.003*\"method\" + 0.003*\"network\" + 0.003*\"model\" + 0.003*\"feature\" + '\n",
      "  '0.003*\"system\" + 0.002*\"set\" + 0.002*\"image\" + 0.002*\"time\" + 0.002*\"data\" '\n",
      "  '+ 0.002*\"algorithm\"'),\n",
      " (6,\n",
      "  '0.003*\"system\" + 0.002*\"fig\" + 0.002*\"power\" + 0.002*\"two\" + 0.002*\"user\" + '\n",
      "  '0.001*\"also\" + 0.001*\"current\" + 0.001*\"algorithm\" + 0.001*\"proposed\" + '\n",
      "  '0.001*\"number\"'),\n",
      " (7,\n",
      "  '0.003*\"model\" + 0.003*\"method\" + 0.002*\"result\" + 0.002*\"image\" + '\n",
      "  '0.002*\"set\" + 0.002*\"proposed\" + 0.002*\"data\" + 0.001*\"number\" + '\n",
      "  '0.001*\"node\" + 0.001*\"function\"'),\n",
      " (8,\n",
      "  '0.001*\"data\" + 0.001*\"model\" + 0.001*\"system\" + 0.001*\"result\" + '\n",
      "  '0.001*\"method\" + 0.001*\"used\" + 0.001*\"signal\" + 0.001*\"one\" + 0.001*\"set\" '\n",
      "  '+ 0.001*\"two\"'),\n",
      " (9,\n",
      "  '0.002*\"method\" + 0.001*\"result\" + 0.001*\"data\" + 0.001*\"node\" + '\n",
      "  '0.001*\"time\" + 0.001*\"using\" + 0.001*\"fig\" + 0.001*\"power\" + 0.001*\"one\" + '\n",
      "  '0.001*\"value\"'),\n",
      " (10,\n",
      "  '0.009*\"data\" + 0.006*\"system\" + 0.005*\"network\" + 0.005*\"time\" + '\n",
      "  '0.004*\"model\" + 0.004*\"used\" + 0.004*\"result\" + 0.004*\"different\" + '\n",
      "  '0.003*\"also\" + 0.003*\"method\"'),\n",
      " (11,\n",
      "  '0.001*\"data\" + 0.001*\"system\" + 0.001*\"model\" + 0.001*\"number\" + '\n",
      "  '0.001*\"result\" + 0.001*\"also\" + 0.001*\"set\" + 0.001*\"algorithm\" + '\n",
      "  '0.001*\"network\" + 0.001*\"function\"'),\n",
      " (12,\n",
      "  '0.001*\"power\" + 0.001*\"time\" + 0.001*\"problem\" + 0.001*\"user\" + '\n",
      "  '0.001*\"value\" + 0.001*\"model\" + 0.001*\"channel\" + 0.001*\"algorithm\" + '\n",
      "  '0.001*\"function\" + 0.001*\"set\"'),\n",
      " (13,\n",
      "  '0.002*\"power\" + 0.001*\"system\" + 0.001*\"result\" + 0.000*\"network\" + '\n",
      "  '0.000*\"number\" + 0.000*\"fig\" + 0.000*\"proposed\" + 0.000*\"problem\" + '\n",
      "  '0.000*\"control\" + 0.000*\"model\"'),\n",
      " (14,\n",
      "  '0.001*\"data\" + 0.001*\"network\" + 0.001*\"result\" + 0.001*\"system\" + '\n",
      "  '0.001*\"signal\" + 0.001*\"time\" + 0.001*\"number\" + 0.001*\"user\" + '\n",
      "  '0.001*\"performance\" + 0.001*\"set\"'),\n",
      " (15,\n",
      "  '0.010*\"model\" + 0.005*\"system\" + 0.003*\"user\" + 0.003*\"network\" + '\n",
      "  '0.003*\"word\" + 0.003*\"sentence\" + 0.003*\"used\" + 0.003*\"set\" + '\n",
      "  '0.002*\"using\" + 0.002*\"one\"'),\n",
      " (16,\n",
      "  '0.003*\"model\" + 0.003*\"student\" + 0.002*\"time\" + 0.002*\"data\" + '\n",
      "  '0.001*\"antenna\" + 0.001*\"fig\" + 0.001*\"result\" + 0.001*\"one\" + 0.001*\"used\" '\n",
      "  '+ 0.001*\"value\"'),\n",
      " (17,\n",
      "  '0.006*\"voltage\" + 0.005*\"power\" + 0.004*\"converter\" + 0.004*\"antenna\" + '\n",
      "  '0.004*\"current\" + 0.003*\"fig\" + 0.003*\"system\" + 0.003*\"control\" + '\n",
      "  '0.002*\"frequency\" + 0.002*\"data\"'),\n",
      " (18,\n",
      "  '0.002*\"channel\" + 0.001*\"signal\" + 0.001*\"using\" + 0.001*\"number\" + '\n",
      "  '0.001*\"data\" + 0.001*\"result\" + 0.001*\"two\" + 0.001*\"fig\" + 0.001*\"used\" + '\n",
      "  '0.001*\"system\"'),\n",
      " (19,\n",
      "  '0.002*\"algorithm\" + 0.002*\"problem\" + 0.002*\"value\" + 0.002*\"method\" + '\n",
      "  '0.002*\"model\" + 0.001*\"used\" + 0.001*\"proposed\" + 0.001*\"function\" + '\n",
      "  '0.001*\"feature\" + 0.001*\"number\"')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ef0c7f59459e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus_doc, texts = docs_doc, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_documents(corpus,ids,topic):\n",
    "    num_topics = 5\n",
    "    topic_proportions = np.zeros(shape=(len(corpus),num_topics+1))\n",
    "    topic_proportions[:,0] = ids\n",
    "    response = lda_model.get_document_topics(corpus)\n",
    "    for i,doc in enumerate(response):\n",
    "        for t,prop in doc:\n",
    "            topic_proportions[i][t+1] = prop \n",
    "    ind = topic_proportions[:,topic+1].argsort()[::-1]\n",
    "    return topic_proportions[ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
