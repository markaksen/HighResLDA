{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/virenbajaj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/virenbajaj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/virenbajaj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import io \n",
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from functools import partial \n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pickle\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import itertools as it\n",
    "import re\n",
    "import time\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_pdf(file_name, start_line, end_line, ids):\n",
    "#     papers_ids_text = []; abstract = []; body_text = []; whole_text = []\n",
    "\n",
    "#     with open(file_name) as f:\n",
    "#         for _ in range(start_line):\n",
    "#             next(f)\n",
    "#         index = 0\n",
    "#         for line in f:\n",
    "#             paper = json.loads(line)\n",
    "# #             if index > end_line - start_line:\n",
    "# #                 break\n",
    "# #             index += 1\n",
    "#             if paper['paper_id'] in ids:\n",
    "#                 print('in')\n",
    "#                 papers_ids_text.append(paper['paper_id'])\n",
    "#                 if paper['abstract']:\n",
    "#                     print(paper['abstract'])\n",
    "#                     abstract.append(paper['abstract'][0]['text'])\n",
    "#                 else: \n",
    "#                     abstract.append('')\n",
    "#                 text = []\n",
    "#                 full_text = ''\n",
    "#                 if paper['body_text']:\n",
    "#                     for entry in paper['body_text']:\n",
    "#                         if entry['section'] and entry['text']:\n",
    "#                             section = {key: entry[key] for key in ['section', 'text']}\n",
    "#                             text.append(section)\n",
    "#                             if full_text:\n",
    "#                                 full_text = full_text + '\\n' + entry['text']\n",
    "#                             else:\n",
    "#                                 full_text = entry['text']\n",
    "#                     body_text.append(text)\n",
    "#                     whole_text.append(full_text)\n",
    "#                 else:\n",
    "#                     body_text.append([])\n",
    "#                     whole_text.append('')\n",
    "                \n",
    "#         textdata = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract, 'body_text': body_text, 'whole_text': whole_text})\n",
    "\n",
    "#         return textdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Uncompressing papers from fields we want, saving the metadata and pdf_parses as pickled dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(metadata_file,pdf_file, fields=None, output_dir = './processed/'):\n",
    "    # Go through metadata files to get relevant paper ids and titles\n",
    "    ids = []; title = []; \n",
    "    # if file is compressed\n",
    "    if metadata_file[-3:] == '.gz':\n",
    "        output_file = metadata_file[:-3]\n",
    "        gz = gzip.open(metadata_file, 'rb')\n",
    "        f = io.BufferedReader(gz)\n",
    "        f_out = open(output_file,'wb')\n",
    "    else:\n",
    "        f = open(metadata_file)\n",
    "        f_out = None\n",
    "\n",
    "    for line in tqdm(f.readlines()):\n",
    "        paper = json.loads(line)\n",
    "        if not fields:\n",
    "            ids.append(paper['paper_id'])\n",
    "            title.append(paper['title'])\n",
    "            if f_out:\n",
    "                f_out.write(line)\n",
    "        elif paper['mag_field_of_study']:\n",
    "            field_in = any([x in fields for x in paper['mag_field_of_study']])\n",
    "            if field_in:\n",
    "                ids.append(paper['paper_id'])\n",
    "                title.append(paper['title'])\n",
    "                if f_out:\n",
    "                    f_out.write(line)\n",
    "    f.close()\n",
    "    if f_out:\n",
    "        f_out.close()\n",
    "    # create and save dataframe in output_dir/meta_df\n",
    "    meta_df = pd.DataFrame({'ids':ids, 'titles':title})\n",
    "    meta_df_dir = output_dir + 'meta_df/'\n",
    "    os.makedirs(meta_df_dir, exist_ok=True)\n",
    "    file_name_without_path_or_ext = metadata_file.split('/')[-1].split('.')[0]\n",
    "    meta_df_file = meta_df_dir + file_name_without_path_or_ext + '.pkl'\n",
    "    with open(meta_df_file, 'wb') as f:\n",
    "        pickle.dump(meta_df, f)\n",
    "\n",
    "    # get the pdfs         \n",
    "    papers_ids_text = []; abstract = []; body_text = []; whole_text = []; key_words = [];            \n",
    "    # if file is compressed\n",
    "    if pdf_file[-3:] == '.gz':\n",
    "        output_file = pdf_file[:-3]\n",
    "        gz = gzip.open(pdf_file, 'rb')\n",
    "        f = io.BufferedReader(gz)\n",
    "        f_out = open(output_file,'wb')\n",
    "    else:\n",
    "        f = open(pdf_file)\n",
    "        f_out = None\n",
    "        \n",
    "    for line in tqdm(f.readlines()):\n",
    "        paper = json.loads(line)\n",
    "        if paper['paper_id'] in ids:\n",
    "            if f_out:\n",
    "                f_out.write(line)\n",
    "            papers_ids_text.append(paper['paper_id'])\n",
    "            abstract_text = ''\n",
    "            terms = []\n",
    "            if paper['abstract']:\n",
    "                abstract_text = paper['abstract'][0]['text']\n",
    "                if len(paper['abstract'])>1:   \n",
    "                    if paper['abstract'][1]['text'][:11].lower() == 'index terms':\n",
    "                        terms = paper['abstract'][1]['text'][12:].split(',') #remove \"Index Terms-\" or \"INDEX TERMS \" from string    \n",
    "            abstract.append(abstract_text) \n",
    "            key_words.append(terms)\n",
    "            text = []\n",
    "            full_text = ''\n",
    "            if paper['body_text']:\n",
    "                for entry in paper['body_text']:\n",
    "                    if entry['section'] and entry['text']:\n",
    "                        section = {key: entry[key] for key in ['section', 'text']}\n",
    "                        text.append(section)\n",
    "                        if full_text:\n",
    "                            full_text = full_text + '\\n' + entry['text']\n",
    "                        else:\n",
    "                            full_text = entry['text']\n",
    "            body_text.append(text)\n",
    "            whole_text.append(full_text)\n",
    "    f.close()\n",
    "    if f_out:\n",
    "        f_out.close()\n",
    "    # create and save dataframe in output_dir/text_df\n",
    "    text_df = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract,'key_words': key_words,'body_text': body_text, 'whole_text': whole_text})\n",
    "    text_df_dir = output_dir + 'text_df/'\n",
    "    os.makedirs(text_df_dir, exist_ok=True)\n",
    "    file_name_without_path_or_ext = pdf_file.split('/')[-1].split('.')[0]\n",
    "    text_df_file = text_df_dir + file_name_without_path_or_ext + '.pkl'\n",
    "    with open(text_df_file, 'wb') as f:\n",
    "        pickle.dump(text_df, f)                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"v\"\n",
    "if user == \"v\":\n",
    "    sample_data_dir = \"/Users/virenbajaj/Desktop/Columbia Fall 20/Graphical Models/project/20200705v1/sample/\"\n",
    "    full_data_dir = \"/Volumes/Extreme SSD/Library/SemanticScholar Data/20200705v1/full/\"\n",
    "else:\n",
    "    full_data_dir = '20200705v1/full/'\n",
    "    \n",
    "metadata_dir = full_data_dir + 'metadata/'\n",
    "pdf_parses_dir = full_data_dir + 'pdf_parses/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/Extreme SSD/Library/SemanticScholar Data/20200705v1/full/metadata/metadata_0.jsonl'] ['/Volumes/Extreme SSD/Library/SemanticScholar Data/20200705v1/full/pdf_parses/pdf_parses_0.jsonl']\n"
     ]
    }
   ],
   "source": [
    "files = range(1)\n",
    "metadata = [metadata_dir + f'metadata_{i}.jsonl' for i in files]\n",
    "pdfs = [pdf_parses_dir + f'pdf_parses_{i}.jsonl' for i in files]\n",
    "fields = ['Computer Science']\n",
    "print(metadata, pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121562/121562 [00:01<00:00, 75905.37it/s]\n",
      "100%|██████████| 51058/51058 [01:00<00:00, 841.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop done\n",
      "making text df\n"
     ]
    }
   ],
   "source": [
    "for batch in zip(metadata,pdfs):\n",
    "    process_batch(batch[0], batch[1], fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed/meta_df/metadata_0.pkl', 'rb') as f:\n",
    "    meta_df = pickle.load(f)\n",
    "with open('./processed/text_df/pdf_parses_0.pkl','rb') as f:\n",
    "    text_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Finer cleaning of data:\n",
    "- remove stop words, high-frequency words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_word_postag(word):\n",
    "    #if pos_tag([word])[0][1].startswith('J'):\n",
    "    #    return wordnet.ADJ\n",
    "    #if pos_tag([word])[0][1].startswith('V'):\n",
    "    #    return wordnet.VERB\n",
    "    if pos_tag([word])[0][1].startswith('N'):\n",
    "        #return wordnet.NOUN\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        #return wordnet.ADJ\n",
    "        #return wordnet.NOUN\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Preprocessing: tokenize words\n",
    "def tokenize(text):\n",
    "    return(word_tokenize(text))\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        return(gensim.utils.simple_preprocess(str(sentence), min_len=3,deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Preprocessing: remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords]) \n",
    "    #return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "# Preprocessing: lemmatizing\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Preprocessing: remove short text\n",
    "def find_longer_text(texts,k=200):\n",
    "    return list(map(lambda x: len(x.split())>k,texts))\n",
    "    \n",
    "#     lengths = list(map(lambda x: len(x.split()), texts))\n",
    "#     return [val >= k for val in lengths]\n",
    "    #return [idx for idx, val in enumerate(lengths) if val >= k] \n",
    "\n",
    "# Preprocessing: alpha num\n",
    "def keep_alphanum(words):\n",
    "    #def isalphanum(word):\n",
    "    #return word.isalnum()\n",
    "    return filter(lambda word: word.isalnum(), words)\n",
    "    #return [word for word in words if word.isalnum()]\n",
    "\n",
    "# Preprocessing: keep nouns\n",
    "def keep_nouns(words):\n",
    "    return filter(get_word_postag, words)\n",
    "    #return [word for word in words if get_word_postag(word) =='n']\n",
    "\n",
    "# Preprocessing: keep words >= 3 in length\n",
    "def keep_longer_words(words):\n",
    "    return filter(lambda x: (len(x) >= 3), words)\n",
    "    #return [word for word in words if len(word) >= 3]\n",
    "\n",
    "# Preprocessing: lemmatize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()\n",
    "def lemmatize(words):\n",
    "    return (map(lm.lemmatize, words)) # removing list\n",
    "\n",
    "# Preprocessing: stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "def stemming(words):\n",
    "    #return [ps.stem(word) for word in words]\n",
    "    return map(ps.stem, words)\n",
    "\n",
    "def remove_digits(words):\n",
    "    return filter(lambda x: x.isalpha(), words)\n",
    "#     return [word for word in words if word.isalpha()]\n",
    "\n",
    "def merged(words):\n",
    "    return ' '.join(word for word in words)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "Codes =['C', 'C++', 'Java', 'Python'] \n",
    "Codes = map(len,Codes)\n",
    "selectors = [False, False, False, True] \n",
    "  \n",
    "Best_Programming = itertools.compress(Codes, selectors) \n",
    "# x = list(map(len,Best_Programming) )\n",
    "# print(x)\n",
    "for each in Best_Programming: \n",
    "    print(each) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pdf(text_df, file_name, output_dir='./cleaned/'):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Convert to list\n",
    "    ids = text_df['paper_id'].values.tolist()\n",
    "    contents = text_df['whole_text'].values.tolist()\n",
    "    abstracts = text_df['abstract'].values.tolist()\n",
    "    \n",
    "    # Add abstract to text\n",
    "    contents = [i + j for i, j in zip(contents, abstracts)]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Remove new line characters\n",
    "    contents = (map(lambda x: re.sub('\\s+', ' ', x), contents))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Preprocessing: lower case text\n",
    "    contents = (map(lambda x: x.lower(),contents))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Preprocessing: keep alphanumeric\n",
    "    contents = (map(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', x), contents)) \n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Preprocessing: remove stand along numbers\n",
    "    contents = (map(lambda x: re.sub(\" \\d+ \", \" \", x), contents))\n",
    "\n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Preprocessing: remove stop words\n",
    "    contents = (map(remove_stopwords, contents))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Preprocessing: remove short text\n",
    "    inds = find_longer_text(contents)\n",
    "    contents = (itertools.compress(contents, inds))\n",
    "    ids = (itertools.compress(ids, inds))\n",
    "    \n",
    "    print('Tokenizing')\n",
    "    \n",
    "    # Tokenize words + remove punctuation\n",
    "    word_list = (map(tokenize,contents))\n",
    "#     word_list = [tokenize(article) for article in contents]\n",
    "\n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Remove numbers\n",
    "    word_list = (map(remove_digits, word_list))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    # Keep longer words\n",
    "#     word_list = [keep_longer_words(words) for words in  word_list]\n",
    "    word_list = map(keep_longer_words,  word_list)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Lemmatizing')\n",
    "    \n",
    "    # Preprocessing: lemmatize\n",
    "    word_list = (map(lemmatize, word_list))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Bag of Words Representation')\n",
    "    # Preprocessing: \n",
    "    dct = corpora.Dictionary()\n",
    "    doc2bow = partial(dct.doc2bow,allow_update=True)\n",
    "    corpus = map(doc2bow, word_list)\n",
    "#     corpus = [dct.doc2bow(doc, allow_update=True) for doc in word_list]\n",
    "\n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    #dct.save(file_name+'.dict')\n",
    "    word_list = list(word_list)\n",
    "    word_list =  [item for sublist in word_list for item in sublist]\n",
    "    counter=collections.Counter(word_list)\n",
    "    print(type(corpus))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file_name = output_dir + file_name + '_clean.pkl'\n",
    "    with open(output_file_name, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump({'dct': dct, 'corpus': list(corpus), 'counter': counter,'ids': ids}, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38265180587768555\n",
      "0.3828279972076416\n",
      "0.38283801078796387\n",
      "0.3828458786010742\n",
      "0.38285374641418457\n",
      "0.3828620910644531\n",
      "Tokenizing\n",
      "116.64940595626831\n",
      "116.64941883087158\n",
      "116.64942693710327\n",
      "Lemmatizing\n",
      "116.64944195747375\n",
      "Bag of Words Representation\n",
      "116.64946389198303\n",
      "<class 'map'>\n"
     ]
    }
   ],
   "source": [
    "file_name = 'pdf_parses_0'\n",
    "clean_pdf(text_df,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file= './cleaned/pdf_parses_0_clean.pkl'\n",
    "with open(cleaned_file, 'rb') as f:\n",
    "    cleaned_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x7f9693389c50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "b = map(lambda x: x+1,a)\n",
    "(filter(lambda x: x<3, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18980380',\n",
       " '18981111',\n",
       " '18982496',\n",
       " '18983391',\n",
       " '199668887',\n",
       " '199668943',\n",
       " '2872653',\n",
       " '2873021',\n",
       " '2874113',\n",
       " '2875387',\n",
       " '2877021',\n",
       " '2877038',\n",
       " '2877521',\n",
       " '213466066',\n",
       " '118869358',\n",
       " '17780357',\n",
       " '17783411',\n",
       " '17786002',\n",
       " '17786441',\n",
       " '17787527',\n",
       " '42955338',\n",
       " '8333443',\n",
       " '8339153',\n",
       " '45911968',\n",
       " '10701360',\n",
       " '10701804',\n",
       " '10702430',\n",
       " '10705817',\n",
       " '10706360',\n",
       " '10707812',\n",
       " '10708489',\n",
       " '17433432',\n",
       " '17437275',\n",
       " '17437758',\n",
       " '17437949',\n",
       " '35656585',\n",
       " '126494268',\n",
       " '204950394',\n",
       " '204950407',\n",
       " '204954248',\n",
       " '40220581',\n",
       " '40221698',\n",
       " '40228247',\n",
       " '64903177',\n",
       " '13461521',\n",
       " '8394589',\n",
       " '8395288',\n",
       " '56031008',\n",
       " '56031338',\n",
       " '56033157',\n",
       " '56035733',\n",
       " '56037507',\n",
       " '56038508',\n",
       " '56038548',\n",
       " '62652265',\n",
       " '62653399',\n",
       " '62655103',\n",
       " '5400734',\n",
       " '5401568',\n",
       " '5402095',\n",
       " '5407972',\n",
       " '55923581',\n",
       " '55923959',\n",
       " '55924989',\n",
       " '55925659',\n",
       " '88482089',\n",
       " '88482265',\n",
       " '88484504',\n",
       " '88485785',\n",
       " '88485902',\n",
       " '88487211',\n",
       " '88488423',\n",
       " '88488465',\n",
       " '88489565',\n",
       " '23511267',\n",
       " '201600643',\n",
       " '55547716',\n",
       " '204197085',\n",
       " '204197524',\n",
       " '43966534',\n",
       " '43967752',\n",
       " '43968000',\n",
       " '18411536',\n",
       " '18412846',\n",
       " '18413119',\n",
       " '18418392',\n",
       " '54784325',\n",
       " '54787642',\n",
       " '54789745',\n",
       " '7223410',\n",
       " '7225848',\n",
       " '7227196',\n",
       " '214802001',\n",
       " '214802415',\n",
       " '214802619',\n",
       " '214802660',\n",
       " '214802675',\n",
       " '67238238',\n",
       " '44434458',\n",
       " '201900600',\n",
       " '201904938',\n",
       " '201906352',\n",
       " '201906803',\n",
       " '125063770',\n",
       " '32263165',\n",
       " '17471662',\n",
       " '17478013',\n",
       " '17478275',\n",
       " '17478335',\n",
       " '205539833',\n",
       " '6271137',\n",
       " '6271257',\n",
       " '6276047',\n",
       " '6278012',\n",
       " '208991971',\n",
       " '159007072',\n",
       " '55321840',\n",
       " '55322632',\n",
       " '55324454',\n",
       " '55324541',\n",
       " '28809978',\n",
       " '27417425',\n",
       " '2921458',\n",
       " '2923727',\n",
       " '2924377',\n",
       " '2927300',\n",
       " '2928088',\n",
       " '39713190',\n",
       " '39715157',\n",
       " '39716371',\n",
       " '19010061',\n",
       " '19011461',\n",
       " '19016620',\n",
       " '19019727',\n",
       " '291143',\n",
       " '291742',\n",
       " '295231',\n",
       " '295349',\n",
       " '297068',\n",
       " '297464',\n",
       " '18602084',\n",
       " '18603810',\n",
       " '18605353',\n",
       " '850237',\n",
       " '851881',\n",
       " '852442',\n",
       " '852996',\n",
       " '854201',\n",
       " '854921',\n",
       " '858074',\n",
       " '858388',\n",
       " '858869',\n",
       " '858938',\n",
       " '859195',\n",
       " '859921',\n",
       " '2410620',\n",
       " '2411921',\n",
       " '2413407',\n",
       " '2414783',\n",
       " '36645954',\n",
       " '59152113',\n",
       " '59154823',\n",
       " '59155690',\n",
       " '59159673',\n",
       " '42351863',\n",
       " '42358455',\n",
       " '62758691',\n",
       " '475504',\n",
       " '476190',\n",
       " '478500',\n",
       " '478526',\n",
       " '478851',\n",
       " '21730536',\n",
       " '21733548',\n",
       " '16341355',\n",
       " '16343255',\n",
       " '16348051',\n",
       " '16348313',\n",
       " '16348583',\n",
       " '16349522',\n",
       " '4940547',\n",
       " '4940686',\n",
       " '4940765',\n",
       " '4941349',\n",
       " '4943921',\n",
       " '4946747',\n",
       " '4948107',\n",
       " '4948856',\n",
       " '18833971',\n",
       " '18835050',\n",
       " '18835550',\n",
       " '18836292',\n",
       " '18836977',\n",
       " '18837566',\n",
       " '54191149',\n",
       " '54192955',\n",
       " '54194571',\n",
       " '54198236',\n",
       " '11820304',\n",
       " '11824449',\n",
       " '11827258',\n",
       " '11827381',\n",
       " '11829380',\n",
       " '25043074',\n",
       " '25045654',\n",
       " '122282',\n",
       " '122292',\n",
       " '123040',\n",
       " '124448',\n",
       " '125245',\n",
       " '125356',\n",
       " '125394',\n",
       " '126031',\n",
       " '126129',\n",
       " '128024',\n",
       " '128085',\n",
       " '129124',\n",
       " '129712',\n",
       " '24156429',\n",
       " '206341736',\n",
       " '206342033',\n",
       " '1343626',\n",
       " '1345080',\n",
       " '1345235',\n",
       " '1347207',\n",
       " '1349870',\n",
       " '195747334',\n",
       " '195748751',\n",
       " '3150198',\n",
       " '3153809',\n",
       " '3155983',\n",
       " '2551230',\n",
       " '2551698',\n",
       " '2554264',\n",
       " '2558839',\n",
       " '2559268',\n",
       " '1530286',\n",
       " '1532834',\n",
       " '1533658',\n",
       " '1534758',\n",
       " '1538349',\n",
       " '1539332',\n",
       " '18552590',\n",
       " '18555534',\n",
       " '18558128',\n",
       " '55855939',\n",
       " '55857359',\n",
       " '55859562',\n",
       " '27245419',\n",
       " '2621179',\n",
       " '2622106',\n",
       " '2624639',\n",
       " '2627903',\n",
       " '4631701',\n",
       " '4633451',\n",
       " '146120525',\n",
       " '12946840',\n",
       " '60482425',\n",
       " '60483817',\n",
       " '59273692',\n",
       " '34010500',\n",
       " '25517643',\n",
       " '124487547',\n",
       " '69267156',\n",
       " '195790004',\n",
       " '195791457',\n",
       " '195791501',\n",
       " '195791798',\n",
       " '195795480',\n",
       " '195798786',\n",
       " '195799050',\n",
       " '52040261',\n",
       " '52041827',\n",
       " '52047358',\n",
       " '52047968',\n",
       " '52048871',\n",
       " '42490916',\n",
       " '42497289',\n",
       " '41620800',\n",
       " '17960081',\n",
       " '17960779',\n",
       " '17961118',\n",
       " '17962548',\n",
       " '17964443',\n",
       " '17966917',\n",
       " '17969301',\n",
       " '16101355',\n",
       " '16101950',\n",
       " '16102232',\n",
       " '16102392',\n",
       " '1990144',\n",
       " '1995031',\n",
       " '1997742',\n",
       " '1998675',\n",
       " '1999718',\n",
       " '54434517',\n",
       " '54435756',\n",
       " '54436915',\n",
       " '54437398',\n",
       " '54439672',\n",
       " '57064991',\n",
       " '57066189',\n",
       " '7204683',\n",
       " '7205083',\n",
       " '7207393',\n",
       " '7209921',\n",
       " '1360597',\n",
       " '1362002',\n",
       " '1362939',\n",
       " '1364461',\n",
       " '1368250',\n",
       " '1369074',\n",
       " '1369649',\n",
       " '1369658',\n",
       " '9443380',\n",
       " '9445483',\n",
       " '9446703',\n",
       " '9446888',\n",
       " '9448547',\n",
       " '9449558',\n",
       " '9130160',\n",
       " '9134261',\n",
       " '9135705',\n",
       " '9138193',\n",
       " '9139503',\n",
       " '124468095',\n",
       " '206643830',\n",
       " '204893869',\n",
       " '204898674',\n",
       " '204899422',\n",
       " '204899999',\n",
       " '30681906',\n",
       " '7170202',\n",
       " '7171265',\n",
       " '7173250',\n",
       " '7175972',\n",
       " '32994559',\n",
       " '209168247',\n",
       " '55972220',\n",
       " '55974762',\n",
       " '55976072',\n",
       " '55978626',\n",
       " '55978669',\n",
       " '20391839',\n",
       " '20395831',\n",
       " '20399859',\n",
       " '4802258',\n",
       " '4805588',\n",
       " '4805856',\n",
       " '4808050',\n",
       " '4808479',\n",
       " '4808664',\n",
       " '182920527',\n",
       " '64106151',\n",
       " '6732350',\n",
       " '6733857',\n",
       " '6736110',\n",
       " '6737447',\n",
       " '120214662',\n",
       " '2971325',\n",
       " '2972444',\n",
       " '67095931',\n",
       " '12081003',\n",
       " '12084714',\n",
       " '12086220',\n",
       " '12088540',\n",
       " '199290448',\n",
       " '153312704',\n",
       " '153314412',\n",
       " '153314513',\n",
       " '1231017',\n",
       " '1234653',\n",
       " '15264746',\n",
       " '15265452',\n",
       " '15265741',\n",
       " '15268094',\n",
       " '15269942',\n",
       " '34002261',\n",
       " '11220961',\n",
       " '11227510',\n",
       " '36765907',\n",
       " '36766430',\n",
       " '14051061',\n",
       " '14054127',\n",
       " '14054150',\n",
       " '14054835',\n",
       " '14055357',\n",
       " '14056326',\n",
       " '14056501',\n",
       " '14058242',\n",
       " '14059146',\n",
       " '14059503',\n",
       " '14059690',\n",
       " '20950328',\n",
       " '20952747',\n",
       " '12522511',\n",
       " '12522599',\n",
       " '12524593',\n",
       " '12524755',\n",
       " '168336215',\n",
       " '63819844',\n",
       " '30274891',\n",
       " '22570290',\n",
       " '119673301',\n",
       " '119677335',\n",
       " '21397581',\n",
       " '28400149',\n",
       " '28404950',\n",
       " '213274317',\n",
       " '10162476',\n",
       " '10162880',\n",
       " '10164018',\n",
       " '10165852',\n",
       " '10167293',\n",
       " '10168292',\n",
       " '10169638',\n",
       " '1290215',\n",
       " '1290397',\n",
       " '1290535',\n",
       " '1292253',\n",
       " '1294851',\n",
       " '1299000',\n",
       " '206461383',\n",
       " '206463443',\n",
       " '57317112',\n",
       " '34063019',\n",
       " '34064526',\n",
       " '34066072',\n",
       " '64626285',\n",
       " '52081264',\n",
       " '52086083',\n",
       " '52088518',\n",
       " '39173868',\n",
       " '32247557',\n",
       " '65777757',\n",
       " '24615845',\n",
       " '32353744',\n",
       " '54583985',\n",
       " '54588831',\n",
       " '26462466',\n",
       " '26468498',\n",
       " '17971602',\n",
       " '17971860',\n",
       " '17971980',\n",
       " '17974011',\n",
       " '17974218',\n",
       " '17976349',\n",
       " '10131503',\n",
       " '10135233',\n",
       " '22790222',\n",
       " '54025299',\n",
       " '54029468',\n",
       " '54029868',\n",
       " '1610154',\n",
       " '1613052',\n",
       " '1613915',\n",
       " '1615646',\n",
       " '10680062',\n",
       " '10682115',\n",
       " '10687387',\n",
       " '10689255',\n",
       " '59620517',\n",
       " '59620570',\n",
       " '6961896',\n",
       " '202911215',\n",
       " '54000800',\n",
       " '54002172',\n",
       " '54003480',\n",
       " '54004133',\n",
       " '8651943',\n",
       " '8652040',\n",
       " '8652212',\n",
       " '67122820',\n",
       " '67129193',\n",
       " '19339740',\n",
       " '9461757',\n",
       " '9462502',\n",
       " '9463029',\n",
       " '9467610',\n",
       " '9468255',\n",
       " '9469160',\n",
       " '19863110',\n",
       " '19869239',\n",
       " '17779733',\n",
       " '204700972',\n",
       " '59553549',\n",
       " '59553801',\n",
       " '59553834',\n",
       " '59554484',\n",
       " '59554549',\n",
       " '59555262',\n",
       " '201103644',\n",
       " '201103753',\n",
       " '201103845',\n",
       " '201103910',\n",
       " '201107128',\n",
       " '26833857',\n",
       " '6830642',\n",
       " '6831433',\n",
       " '6834548',\n",
       " '6834721',\n",
       " '6837121',\n",
       " '6839232',\n",
       " '6839287',\n",
       " '6839388',\n",
       " '21548392',\n",
       " '21834115',\n",
       " '32372358',\n",
       " '25649612',\n",
       " '59493457',\n",
       " '59499131',\n",
       " '53541358',\n",
       " '53547062',\n",
       " '62333112',\n",
       " '64197204',\n",
       " '55468511',\n",
       " '8310315',\n",
       " '8313353',\n",
       " '8314206',\n",
       " '8314389',\n",
       " '8315718',\n",
       " '8315761',\n",
       " '8317429',\n",
       " '8317448',\n",
       " '8317479',\n",
       " '8318082',\n",
       " '8318298',\n",
       " '140223918',\n",
       " '209515373',\n",
       " '209515583',\n",
       " '209515638',\n",
       " '209515808',\n",
       " '209515914',\n",
       " '209516407',\n",
       " '45355533',\n",
       " '21149141',\n",
       " '18930050',\n",
       " '18930228',\n",
       " '18932382',\n",
       " '18933295',\n",
       " '18934046',\n",
       " '18939492',\n",
       " '67788165',\n",
       " '67788211',\n",
       " '67788402',\n",
       " '49742407',\n",
       " '49743698',\n",
       " '49743824',\n",
       " '49745006',\n",
       " '205209254',\n",
       " '52218855',\n",
       " '52219118',\n",
       " '7974470',\n",
       " '7976495',\n",
       " '7979564',\n",
       " '54922616',\n",
       " '209464920',\n",
       " '22263548',\n",
       " '34929123',\n",
       " '206670218',\n",
       " '86782543',\n",
       " '86787580',\n",
       " '42370574',\n",
       " '86648117',\n",
       " '17403109',\n",
       " '17405188',\n",
       " '17406587',\n",
       " '17408312',\n",
       " '17920073',\n",
       " '17921282',\n",
       " '17922688',\n",
       " '17923207',\n",
       " '17927373',\n",
       " '121288690',\n",
       " '43136871',\n",
       " '8091076',\n",
       " '8095358',\n",
       " '8098928',\n",
       " '8099619',\n",
       " '49184595',\n",
       " '63987076',\n",
       " '207847542',\n",
       " '207847926',\n",
       " '38001059',\n",
       " '38003203',\n",
       " '7102910',\n",
       " '7103899',\n",
       " '7104902',\n",
       " '7106188',\n",
       " '3968001',\n",
       " '24902948',\n",
       " '24905394',\n",
       " '3824849',\n",
       " '3827395',\n",
       " '7393056',\n",
       " '7395433',\n",
       " '7397303',\n",
       " '7399296',\n",
       " '56380688',\n",
       " '7561107',\n",
       " '7562791',\n",
       " '7563000',\n",
       " '7563195',\n",
       " '7564897',\n",
       " '31182280',\n",
       " '40675165',\n",
       " '13261162',\n",
       " '13261324',\n",
       " '13263157',\n",
       " '13267400',\n",
       " '13267738',\n",
       " '13268839',\n",
       " '13269431',\n",
       " '23370283',\n",
       " '8062034',\n",
       " '8063073',\n",
       " '8064332',\n",
       " '8064754',\n",
       " '8065148',\n",
       " '8065470',\n",
       " '8068740',\n",
       " '28698273',\n",
       " '28699619',\n",
       " '11131121',\n",
       " '11131633',\n",
       " '11134338',\n",
       " '11135305',\n",
       " '11135343',\n",
       " '11136632',\n",
       " '30536442',\n",
       " '31403862',\n",
       " '31406915',\n",
       " '35742161',\n",
       " '28411001',\n",
       " '28419705',\n",
       " '205728436',\n",
       " '58765521',\n",
       " '211060143',\n",
       " '211066414',\n",
       " '211069348',\n",
       " '17212613',\n",
       " '17215935',\n",
       " '17217625',\n",
       " '17218691',\n",
       " '17219136',\n",
       " '17219188',\n",
       " '58930635',\n",
       " '58931902',\n",
       " '58933226',\n",
       " '58935783',\n",
       " '58936784',\n",
       " '58937210',\n",
       " '58937551',\n",
       " '1030348',\n",
       " '1030471',\n",
       " '1033512',\n",
       " '1033620',\n",
       " '1034793',\n",
       " '1037154',\n",
       " '1037946',\n",
       " '61893833',\n",
       " '11011017',\n",
       " '11013405',\n",
       " '15690112',\n",
       " '15698804',\n",
       " '6990522',\n",
       " '6990534',\n",
       " '6990754',\n",
       " '6992876',\n",
       " '6994401',\n",
       " '6999928',\n",
       " '67691754',\n",
       " '67699953',\n",
       " '119285256',\n",
       " '17352526',\n",
       " '17353176',\n",
       " '17355020',\n",
       " '17355235',\n",
       " '60808120',\n",
       " '60809857',\n",
       " '73429802',\n",
       " '86840471',\n",
       " '86843720',\n",
       " '30383904',\n",
       " '31644268',\n",
       " '210154081',\n",
       " '210157074',\n",
       " '210157149',\n",
       " '210157292',\n",
       " '210157745',\n",
       " '27067293',\n",
       " '27068260',\n",
       " '72249216',\n",
       " '7991362',\n",
       " '7993372',\n",
       " '7994658',\n",
       " '7996650',\n",
       " '59933293',\n",
       " '861493',\n",
       " '863566',\n",
       " '865945',\n",
       " '49480889',\n",
       " '49484030',\n",
       " '49486379',\n",
       " '52990764',\n",
       " '60412813',\n",
       " '53127449',\n",
       " '203736515',\n",
       " '203736648',\n",
       " '7851966',\n",
       " '7852269',\n",
       " '7854576',\n",
       " '7858319',\n",
       " '119236016',\n",
       " '119236028',\n",
       " '55159381',\n",
       " '9051062',\n",
       " '9052030',\n",
       " '9052255',\n",
       " '9058909',\n",
       " '86833162',\n",
       " '86835820',\n",
       " '86838539',\n",
       " '41050098',\n",
       " '41052891',\n",
       " '41057937',\n",
       " '196192426',\n",
       " '196192616',\n",
       " '196193922',\n",
       " '196196094',\n",
       " '196196215',\n",
       " '44752838',\n",
       " '207000970',\n",
       " '207002654',\n",
       " '601685',\n",
       " '603190',\n",
       " '607968',\n",
       " '27941462',\n",
       " '27949252',\n",
       " '12461081',\n",
       " '12461260',\n",
       " '12464302',\n",
       " '12468128',\n",
       " '12469107',\n",
       " '12469192',\n",
       " '126127652',\n",
       " '1261503',\n",
       " '1267896',\n",
       " '1268851',\n",
       " '9390975',\n",
       " '9391560',\n",
       " '9391732',\n",
       " '9395456',\n",
       " '9396743',\n",
       " '9397184',\n",
       " '26260379',\n",
       " '26260678',\n",
       " '186425499',\n",
       " '53503783',\n",
       " '53505438',\n",
       " '5940327',\n",
       " '5941489',\n",
       " '5941579',\n",
       " '5941582',\n",
       " '5945410',\n",
       " '5947935',\n",
       " '26701595',\n",
       " '181890568',\n",
       " '181891251',\n",
       " '15320337',\n",
       " '15322612',\n",
       " '15325170',\n",
       " '15326236',\n",
       " '15327998',\n",
       " '15328193',\n",
       " '15328536',\n",
       " '15329160',\n",
       " '12423516',\n",
       " '12425598',\n",
       " '116769763',\n",
       " '208821488',\n",
       " '208821729',\n",
       " '208822039',\n",
       " '39823524',\n",
       " '39827212',\n",
       " '14260484',\n",
       " '14265101',\n",
       " '14267193',\n",
       " '14267961',\n",
       " '14268398',\n",
       " '7552715',\n",
       " '7553576',\n",
       " '7556729',\n",
       " '7559418',\n",
       " '10113401',\n",
       " '10113685',\n",
       " '10115788',\n",
       " '10118280',\n",
       " '10119997',\n",
       " '49646433',\n",
       " '209532054',\n",
       " '9835570',\n",
       " '9835782',\n",
       " '9840000',\n",
       " '35136567',\n",
       " '61772921',\n",
       " '18220809',\n",
       " '18222504',\n",
       " '18222918',\n",
       " '18222947',\n",
       " '18223484',\n",
       " '18223757',\n",
       " '18227293',\n",
       " '18228350',\n",
       " '18229897',\n",
       " '52868732',\n",
       " '20614925',\n",
       " '18901034',\n",
       " '18902415',\n",
       " '18904777',\n",
       " '18909150',\n",
       " '18909556',\n",
       " '61386302',\n",
       " '16082865',\n",
       " '16084553',\n",
       " '16085684',\n",
       " '16085702',\n",
       " '54862517',\n",
       " '54865218',\n",
       " '54867815',\n",
       " '54868012',\n",
       " '37832010',\n",
       " '37832572',\n",
       " '12370569',\n",
       " '12372546',\n",
       " '12372782',\n",
       " '12378495',\n",
       " '202728518',\n",
       " '202728624',\n",
       " '202728734',\n",
       " '202729775',\n",
       " '202729848',\n",
       " '2061001',\n",
       " '2064645',\n",
       " '2065057',\n",
       " '2065400',\n",
       " '2069424',\n",
       " '64219037',\n",
       " '131763462',\n",
       " '55687531',\n",
       " '22604482',\n",
       " '7532885',\n",
       " '7535293',\n",
       " '116052224',\n",
       " '13970847',\n",
       " '13971486',\n",
       " '13974252',\n",
       " '13975279',\n",
       " '13979241',\n",
       " '39152076',\n",
       " '182949066',\n",
       " '49552729',\n",
       " '49556479',\n",
       " '49557232',\n",
       " '1784638',\n",
       " '1788317',\n",
       " '1788586',\n",
       " '4933208',\n",
       " '4933593',\n",
       " '4938534',\n",
       " '4939967',\n",
       " '196471176',\n",
       " '41320439',\n",
       " '2341372',\n",
       " '2343166',\n",
       " '2346063',\n",
       " '2347187',\n",
       " '18941040',\n",
       " '18945816',\n",
       " '18946658',\n",
       " '7960852',\n",
       " '7966572',\n",
       " '7967380',\n",
       " '32164761',\n",
       " '4967734',\n",
       " '4969300',\n",
       " '33599910',\n",
       " '32892329',\n",
       " '63683049',\n",
       " '63685348',\n",
       " '199085470',\n",
       " '63564394',\n",
       " '63564747',\n",
       " '63569187',\n",
       " '53872395',\n",
       " '53873286',\n",
       " '53877079',\n",
       " '29790076',\n",
       " '29795356',\n",
       " '29798801',\n",
       " '58981433',\n",
       " '58981439',\n",
       " '58981569',\n",
       " '58981918',\n",
       " '58981936',\n",
       " '58981955',\n",
       " '58982022',\n",
       " '39197511',\n",
       " '185609592',\n",
       " '70334709',\n",
       " '14721296',\n",
       " '14724733',\n",
       " '14724777',\n",
       " '14724885',\n",
       " '14725073',\n",
       " '14726452',\n",
       " '14727625',\n",
       " '14727794',\n",
       " '22715960',\n",
       " '58011648',\n",
       " '58012994',\n",
       " '58013029',\n",
       " '58013574',\n",
       " '58013858',\n",
       " '58014223',\n",
       " '58019925',\n",
       " '55953629',\n",
       " '55955410',\n",
       " '55958889',\n",
       " '14490447',\n",
       " '14490799',\n",
       " '14492975',\n",
       " '14495292',\n",
       " '14495917',\n",
       " '14496173',\n",
       " '14497879',\n",
       " '2980325',\n",
       " '2980580',\n",
       " '2982460',\n",
       " '2982741',\n",
       " '2986916',\n",
       " '2987146',\n",
       " '2989660',\n",
       " '63751096',\n",
       " '63758733',\n",
       " '41307870',\n",
       " '33444937',\n",
       " '8571801',\n",
       " '8573773',\n",
       " '8576285',\n",
       " '8578055',\n",
       " '88500230',\n",
       " '88500518',\n",
       " '88500944',\n",
       " '88500963',\n",
       " '24698940',\n",
       " '25242936',\n",
       " '25781700',\n",
       " '206548350',\n",
       " '10342474',\n",
       " '10348441',\n",
       " '10348675',\n",
       " '19974542',\n",
       " '19976153',\n",
       " '19979031',\n",
       " '19110825',\n",
       " '17464778',\n",
       " '17464934',\n",
       " '17466512',\n",
       " '17466802',\n",
       " '17466844',\n",
       " '17468170',\n",
       " '201718834',\n",
       " '18972100',\n",
       " '18972934',\n",
       " '18975823',\n",
       " '18976600',\n",
       " '18979281',\n",
       " '550139',\n",
       " '550393',\n",
       " '551912',\n",
       " '552892',\n",
       " '553292',\n",
       " '554423',\n",
       " '555235',\n",
       " '555630',\n",
       " '555949',\n",
       " '556060',\n",
       " '556244',\n",
       " '556964',\n",
       " '558902',\n",
       " '559888',\n",
       " '18430884',\n",
       " '18434738',\n",
       " '18438551',\n",
       " '18439440',\n",
       " '17660790',\n",
       " '17663739',\n",
       " '17663789',\n",
       " '17668071',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cleaned_data['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sections(textdf, file_name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>Throughout the technical note, we use capital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18981111</td>\n",
       "      <td></td>\n",
       "      <td>[{'section': 'Exploration of Unknown Spaces by...</td>\n",
       "      <td>ORLY LAHAV DAVID MIODUSER Tel Aviv University,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18981625</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18982496</td>\n",
       "      <td>In this paper I discuss some constraints and i...</td>\n",
       "      <td>[{'section': 'Lack of Cooperation from Fellow ...</td>\n",
       "      <td>We normally take precautionary measures agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18983082</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  18980380  This technical note studies Markov decision pr...   \n",
       "1  18981111                                                      \n",
       "2  18981625                                                      \n",
       "3  18982496  In this paper I discuss some constraints and i...   \n",
       "4  18983082                                                      \n",
       "\n",
       "                                           body_text  \\\n",
       "0  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "1  [{'section': 'Exploration of Unknown Spaces by...   \n",
       "2                                                 []   \n",
       "3  [{'section': 'Lack of Cooperation from Fellow ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                          whole_text  \n",
       "0  Throughout the technical note, we use capital ...  \n",
       "1  ORLY LAHAV DAVID MIODUSER Tel Aviv University,...  \n",
       "2                                                     \n",
       "3  We normally take precautionary measures agains...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ids = selected_data['ids'].values\n",
    "# pdf_file = pdf_parses_dir + 'pdf_parses_0.jsonl'\n",
    "# textdf = read_pdf(pdf_file,0,100000, ids)\n",
    "# textdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = textdf['body_text'][0]\n",
    "# section_titles = [x['section'] for x in sections]\n",
    "# section_titles\n",
    "# sections[0]\n",
    "# sections[1]['section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing\n",
      "Lemmatizing\n",
      "Bag of Words Representation\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# cwd = os.getcwd()\n",
    "# file_path = cwd + '\\\\Preprocessed\\\\0'\n",
    "# output = clean_pdf(textdf, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = output[0]\n",
    "corpus = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = cleaned_data[2]\n",
    "word_list =  [item for sublist in word_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bf50460a09c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#wordcloud.generate(long_string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#wordcloud.generate(word_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mwordcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Visualize the word cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'counter' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join the different processed titles together.\n",
    "#long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "long_string = ' '.join(word_list)\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# Generate a word cloud\n",
    "#wordcloud.generate(long_string)\n",
    "#wordcloud.generate(word_list)\n",
    "wordcloud.generate_from_frequencies(counter)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = cwd + '\\\\Preprocessed\\\\'\n",
    "# def process_pdf(file_name, batch_num, start_ind, end_ind, ids):\n",
    "#     textdf = read_pdf(file_name, start_ind, end_ind, ids)\n",
    "#     save_path = file_path + str(batchnum)\n",
    "#     output = clean_pdf(textdf, save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_batch(batch_ind, batch_size=50000, field='Computer Science'):\n",
    "#     file_name_meta = '20200705v1/full/metadata/metadata_' + str(batch_ind) + '.jsonl'\n",
    "#     file_name_pdf = '20200705v1/full/pdf_parses/pdf_parses_' + str(batch_ind) + '.jsonl'\n",
    "    \n",
    "#     import os\n",
    "#     cwd = os.getcwd()\n",
    "#     file_path = cwd + '\\\\Preprocessed\\\\' \n",
    "\n",
    "#     start = time.time()\n",
    "    \n",
    "#     nlines = sum(1 for line in open(file_name_pdf))\n",
    "#     batch_num = int(np.ceil(nlines / batch_size))\n",
    "    \n",
    "#     print('Processing metadata file', batch_ind)\n",
    "#     selected_data = process_metadata(file_name_meta, field)\n",
    "#     selected_ids = selected_data['ids'].values\n",
    "    \n",
    "#     with open(file_path+'metadata.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#         pickle.dump(selected_data, f)\n",
    "    \n",
    "#     t = time.time()\n",
    "#     print(t-start)\n",
    "    \n",
    "#     for i in range(batch_num):\n",
    "#         print('Processing pdfs batch Number: ', i)\n",
    "#         line_nums = [batch_size*i, batch_size*(i+1)]\n",
    "#         textdf = read_pdf(file_name_pdf,line_nums[0],line_nums[1], ids)  \n",
    "        \n",
    "#         t = time.time()\n",
    "#         print(t-start)\n",
    "        \n",
    "#         print('Processing pdfs batch Number: ', i)\n",
    "\n",
    "#         output = clean_pdf(textdf, file_path+str(i))\n",
    "        \n",
    "#         t = time.time()\n",
    "#         print(t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metadata file 0\n",
      "35.497846364974976\n",
      "Processing pdfs batch Number:  0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-39af9d441e12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocess_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Computer Science'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-287ae6b34805>\u001b[0m in \u001b[0;36mprocess_batch\u001b[1;34m(batch_ind, batch_size, field)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Processing pdfs batch Number: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mline_nums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mtextdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'20200705v1/full/pdf_parses/pdf_parses'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jsonl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline_nums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline_nums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# process_batch(batch_ind=0, field='Computer Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "980",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-0e0278214d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtop_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-0e0278214d90>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mword_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtop_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2token\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 980"
     ]
    }
   ],
   "source": [
    "word_counts = sorted(dct.dfs.items(), key = lambda x: x[1], reverse=True)\n",
    "top_ids = [x[0] for x in word_counts[0:100]]\n",
    "top_words = [dct.id2token[x] for x in top_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.filter_tokens(bad_ids=top_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get_texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-8a66c0ec1b57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocuments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_texts'"
     ]
    }
   ],
   "source": [
    "documents = corpus.get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the LDA model\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.test.utils import common_corpus\n",
    "\n",
    "#perplexity_logger = PerplexityMetric(corpus=common_corpus, logger='shell')\n",
    "#convergence_logger = ConvergenceMetric(logger='shell')\n",
    "#coherence_cv_logger = CoherenceMetric(corpus=corpus, logger='shell', coherence = 'c_v', texts = documents)\n",
    "\n",
    "lda_model = LdaMulticore(corpus=corpus,\n",
    "                         id2word=dct,\n",
    "                         random_state=2020,\n",
    "                         num_topics=10,\n",
    "                         passes=1,\n",
    "                         chunksize=1000,\n",
    "                         batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta=None,\n",
    "                         eval_every=0,\n",
    "                         iterations=100,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True)\n",
    "\n",
    "# save the model\n",
    "lda_model.save('lda_model.model')\n",
    "\n",
    "# See the topics\n",
    "lda_model.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -0.6558824017161562\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -0.6559.\n",
      "[([(0.005903978, 'model'),\n",
      "   (0.0056817126, 'data'),\n",
      "   (0.0050683604, 'system'),\n",
      "   (0.004683143, 'one'),\n",
      "   (0.004589382, 'set'),\n",
      "   (0.004308348, 'result'),\n",
      "   (0.004308256, 'time'),\n",
      "   (0.0041383095, 'used'),\n",
      "   (0.0041151457, 'using'),\n",
      "   (0.004082712, 'algorithm'),\n",
      "   (0.003972761, 'two'),\n",
      "   (0.0039018418, 'method'),\n",
      "   (0.0038599866, 'also'),\n",
      "   (0.0038234273, 'number'),\n",
      "   (0.0033649916, 'value'),\n",
      "   (0.0032020246, 'problem'),\n",
      "   (0.0031827844, 'case'),\n",
      "   (0.003104415, 'function'),\n",
      "   (0.0029815945, 'use'),\n",
      "   (0.0029531042, 'different')],\n",
      "  -0.15817686393398864),\n",
      " ([(0.00148182, 'method'),\n",
      "   (0.0013913988, 'ship'),\n",
      "   (0.001329745, 'model'),\n",
      "   (0.0010342445, 'set'),\n",
      "   (0.001012543, 'user'),\n",
      "   (0.0009968651, 'data'),\n",
      "   (0.0008815918, 'one'),\n",
      "   (0.00087165734, 'system'),\n",
      "   (0.0008399095, 'using'),\n",
      "   (0.00083453057, 'used'),\n",
      "   (0.000791407, 'function'),\n",
      "   (0.0007810815, 'algorithm'),\n",
      "   (0.00077615393, 'value'),\n",
      "   (0.0007526579, 'problem'),\n",
      "   (0.0007092378, 'number'),\n",
      "   (0.00070608774, 'time'),\n",
      "   (0.0006937634, 'different'),\n",
      "   (0.00069175614, 'case'),\n",
      "   (0.00068830495, 'result'),\n",
      "   (0.00065999624, 'use')],\n",
      "  -0.19138922816613405),\n",
      " ([(0.0027968646, 'data'),\n",
      "   (0.0021357208, 'set'),\n",
      "   (0.0016082124, 'using'),\n",
      "   (0.0015638896, 'two'),\n",
      "   (0.0014477217, 'used'),\n",
      "   (0.0013985019, 'use'),\n",
      "   (0.0013956556, 'one'),\n",
      "   (0.0013592504, 'system'),\n",
      "   (0.001345978, 'number'),\n",
      "   (0.0012952733, 'image'),\n",
      "   (0.0012944619, 'time'),\n",
      "   (0.0012798801, 'value'),\n",
      "   (0.0011609592, 'model'),\n",
      "   (0.001151968, 'case'),\n",
      "   (0.0010108142, 'also'),\n",
      "   (0.0009908113, 'method'),\n",
      "   (0.0009773144, 'based'),\n",
      "   (0.000935779, 'result'),\n",
      "   (0.00089157757, 'figure'),\n",
      "   (0.0008909335, 'function')],\n",
      "  -0.22409184986313432),\n",
      " ([(0.0021165882, 'needle'),\n",
      "   (0.0019584747, 'algorithm'),\n",
      "   (0.0016796219, 'data'),\n",
      "   (0.0016376894, 'system'),\n",
      "   (0.0016126306, 'used'),\n",
      "   (0.0014627527, 'number'),\n",
      "   (0.0014033306, 'using'),\n",
      "   (0.0013259042, 'time'),\n",
      "   (0.0013150312, 'method'),\n",
      "   (0.0012832065, 'node'),\n",
      "   (0.001239575, 'model'),\n",
      "   (0.0011901379, 'case'),\n",
      "   (0.0011605163, 'set'),\n",
      "   (0.0011476235, 'also'),\n",
      "   (0.0010834641, 'one'),\n",
      "   (0.0010529901, 'result'),\n",
      "   (0.0009916686, 'different'),\n",
      "   (0.0009762293, 'value'),\n",
      "   (0.00095746265, 'matrix'),\n",
      "   (0.00091953826, 'two')],\n",
      "  -0.25134008979311917),\n",
      " ([(0.023662955, 'image'),\n",
      "   (0.0055000572, 'method'),\n",
      "   (0.0045116665, 'data'),\n",
      "   (0.003928035, 'used'),\n",
      "   (0.0037993668, 'feature'),\n",
      "   (0.0032171821, 'model'),\n",
      "   (0.0031706023, 'segmentation'),\n",
      "   (0.0031630958, 'result'),\n",
      "   (0.002553997, 'pixel'),\n",
      "   (0.0024299114, 'network'),\n",
      "   (0.0024149008, 'proposed'),\n",
      "   (0.0023470058, 'using'),\n",
      "   (0.0021702317, 'different'),\n",
      "   (0.002168456, 'training'),\n",
      "   (0.0021552993, 'based'),\n",
      "   (0.0020933722, 'structure'),\n",
      "   (0.0019312912, 'color'),\n",
      "   (0.0019009954, 'two'),\n",
      "   (0.0018529977, 'information'),\n",
      "   (0.0017923183, 'figure')],\n",
      "  -0.5579335765643996),\n",
      " ([(0.0023184768, 'model'),\n",
      "   (0.002227875, 'node'),\n",
      "   (0.0020038085, 'cluster'),\n",
      "   (0.001924908, 'two'),\n",
      "   (0.0018726464, 'time'),\n",
      "   (0.0018558607, 'also'),\n",
      "   (0.001767826, 'used'),\n",
      "   (0.0015980387, 'using'),\n",
      "   (0.0014667639, 'figure'),\n",
      "   (0.0014604741, 'method'),\n",
      "   (0.0014415247, 'result'),\n",
      "   (0.0013196376, 'one'),\n",
      "   (0.0012870783, 'network'),\n",
      "   (0.0012687208, 'set'),\n",
      "   (0.0012555473, 'system'),\n",
      "   (0.0012008026, 'first'),\n",
      "   (0.0011834344, 'process'),\n",
      "   (0.0011362268, 'section'),\n",
      "   (0.0011007574, 'cell'),\n",
      "   (0.0010918492, 'mass')],\n",
      "  -0.5746132102299181),\n",
      " ([(0.026017405, 'node'),\n",
      "   (0.012148737, 'network'),\n",
      "   (0.0073822034, 'packet'),\n",
      "   (0.0060198638, 'protocol'),\n",
      "   (0.0055011758, 'number'),\n",
      "   (0.004493956, 'routing'),\n",
      "   (0.0044550938, 'time'),\n",
      "   (0.004316476, 'data'),\n",
      "   (0.004093516, 'sensor'),\n",
      "   (0.003979899, 'message'),\n",
      "   (0.0037014952, 'algorithm'),\n",
      "   (0.0036520546, 'energy'),\n",
      "   (0.003384935, 'one'),\n",
      "   (0.00335106, 'transmission'),\n",
      "   (0.003304123, 'scheme'),\n",
      "   (0.0032496708, 'path'),\n",
      "   (0.00309392, 'link'),\n",
      "   (0.0029847038, 'using'),\n",
      "   (0.002871374, 'cluster'),\n",
      "   (0.0028386982, 'based')],\n",
      "  -0.8143271300692008),\n",
      " ([(0.0031040343, 'data'),\n",
      "   (0.0015278966, 'model'),\n",
      "   (0.001497044, 'verb'),\n",
      "   (0.001434914, 'system'),\n",
      "   (0.0013891332, 'information'),\n",
      "   (0.0013804802, 'method'),\n",
      "   (0.0013726277, 'one'),\n",
      "   (0.0013565171, 'used'),\n",
      "   (0.0013548307, 'set'),\n",
      "   (0.0013339281, 'result'),\n",
      "   (0.0013248938, 'monad'),\n",
      "   (0.0013196635, 'two'),\n",
      "   (0.0012487762, 'number'),\n",
      "   (0.0012140084, 'time'),\n",
      "   (0.0011246407, 'function'),\n",
      "   (0.0010442164, 'problem'),\n",
      "   (0.0010013905, 'kleisli'),\n",
      "   (0.0009597435, 'analysis'),\n",
      "   (0.0009456633, 'show'),\n",
      "   (0.0009326994, 'case')],\n",
      "  -1.1506353201954824),\n",
      " ([(0.003437029, 'model'),\n",
      "   (0.002060297, 'set'),\n",
      "   (0.0019958434, 'used'),\n",
      "   (0.001933589, 'seller'),\n",
      "   (0.0017931446, 'using'),\n",
      "   (0.0017459083, 'buyer'),\n",
      "   (0.0017265596, 'redescription'),\n",
      "   (0.0017150694, 'two'),\n",
      "   (0.0017139321, 'group'),\n",
      "   (0.0016999695, 'graph'),\n",
      "   (0.0016761238, 'also'),\n",
      "   (0.0016577935, 'locus'),\n",
      "   (0.0016530857, 'time'),\n",
      "   (0.0016020335, 'data'),\n",
      "   (0.001595676, 'one'),\n",
      "   (0.0015612551, 'algorithm'),\n",
      "   (0.0015298325, 'use'),\n",
      "   (0.0014662513, 'number'),\n",
      "   (0.001444491, 'function'),\n",
      "   (0.0013954344, 'value')],\n",
      "  -1.21794680310391),\n",
      " ([(0.00347038, 'retailer'),\n",
      "   (0.001924207, 'rubber'),\n",
      "   (0.0018543763, 'one'),\n",
      "   (0.0017085216, 'result'),\n",
      "   (0.0016629796, 'manufacturer'),\n",
      "   (0.0016348023, 'plantation'),\n",
      "   (0.0015873768, 'time'),\n",
      "   (0.0015790883, 'used'),\n",
      "   (0.0015734532, 'data'),\n",
      "   (0.0015045947, 'figure'),\n",
      "   (0.0014655072, 'image'),\n",
      "   (0.0013718479, 'two'),\n",
      "   (0.0013211813, 'system'),\n",
      "   (0.0012562802, 'also'),\n",
      "   (0.0012319752, 'process'),\n",
      "   (0.0012304898, 'function'),\n",
      "   (0.001217165, 'study'),\n",
      "   (0.0012150613, 'using'),\n",
      "   (0.0011828527, 'bird'),\n",
      "   (0.0011572706, 'type')],\n",
      "  -1.4183699452422742)]\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "\n",
    "top_topics = lda_model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
