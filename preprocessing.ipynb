{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "def process_articles(file_name, start_line, end_line):\n",
    "    paper_ids = []; title = []; index = 0; area = []\n",
    "    papers_ids_text = []; abstract = []; body_text = []; index = 0; whole_text = []\n",
    "    #metadata = def process_metadata(file_name_meta, start_line, end_line)\n",
    "    x = []\n",
    "    with open(file_name) as f:\n",
    "        for _ in range(start_line):\n",
    "            next(f)\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            paper = json.loads(line)\n",
    "            if index > end_line - start_line:\n",
    "                break\n",
    "            x.append(paper['paper_id'])   \n",
    "            index += 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_name, start_line, end_line):\n",
    "    papers_ids_text = []; abstract = []; body_text = []; index = 0; whole_text = []\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        for _ in range(start_line):\n",
    "            next(f)\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            paper = json.loads(line)\n",
    "            if index > end_line - start_line:\n",
    "                break\n",
    "            index += 1\n",
    "            papers_ids_text.append(paper['paper_id'])\n",
    "            if paper['abstract']:\n",
    "                abstract.append(paper['abstract'][0]['text'])\n",
    "            else: \n",
    "                abstract.append('')\n",
    "            text = []\n",
    "            full_text = ''\n",
    "            if paper['body_text']:\n",
    "                for entry in paper['body_text']:\n",
    "                    if entry['section'] and entry['text']:\n",
    "                        section = {key: entry[key] for key in ['section', 'text']}\n",
    "                        text.append(section)\n",
    "                        if full_text:\n",
    "                            full_text = full_text + '\\n' + entry['text']\n",
    "                        else:\n",
    "                            full_text = entry['text']\n",
    "                body_text.append(text)\n",
    "                whole_text.append(full_text)\n",
    "            else:\n",
    "                body_text.append([])\n",
    "                whole_text.append('')\n",
    "                \n",
    "        textdata = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract, 'body_text': body_text, 'whole_text': whole_text})\n",
    "\n",
    "        return textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_name, start_line, end_line):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_word_postag(word):\n",
    "    if pos_tag([word])[0][1].startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    if pos_tag([word])[0][1].startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    if pos_tag([word])[0][1].startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return wordnet.ADJ\n",
    "        #return wordnet.NOUN\n",
    "\n",
    "# Preprocessing: alpha num\n",
    "def keep_alphanum(words):\n",
    "    return [word for word in words if word.isalnum()]\n",
    "\n",
    "# Preprocessing: keep nouns\n",
    "def keep_nouns(words):\n",
    "    return [word for word in words if get_word_postag(word) =='n']\n",
    "\n",
    "# Preprocessing: keep words >= 3 in length\n",
    "def keep_longer_words(words):\n",
    "    return [word for word in words if len(word) >= 3]\n",
    "\n",
    "# Preprocessing: stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "def stemming(words):\n",
    "    return [ps.stem(word) for word in words]\n",
    "\n",
    "def merged(words):\n",
    "    return ' '.join(word for word in words)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def clean_pdf(textdf):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    print('Lower case')\n",
    "    # Preprocessing: lower case text\n",
    "    textdf['whole_text'] = textdf['whole_text'].str.lower()\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Remove short text')\n",
    "    # Select rows where whole text has >= 200 words\n",
    "    k = 200\n",
    "    #textdata['split_text'] = [x.split() for x in textdata['whole_text']]\n",
    "    textdf['split_text'] = [nltk.word_tokenize(x) for x in textdf['whole_text']]\n",
    "    text_length = [len(x)>= k for x in textdf['split_text']]\n",
    "    textdf = textdf[text_length]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Keep Alpha numeric')\n",
    "    textdf['nouns'] = [keep_alphanum(x) for x in textdf['split_text']]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Keep nouns')\n",
    "    textdf['nouns'] = [keep_nouns(x) for x in textdf['nouns']]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Keep longer words')\n",
    "    textdf['nouns'] = [keep_longer_words(x) for x in textdf['nouns']]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Stem words')\n",
    "    textdf['nouns'] = [stemming(x) for x in textdf['nouns']]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Merge text')\n",
    "    textdata['merged'] = [merged(x) for x in textdata['nouns']]  \n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Bag of Words Representation')\n",
    "    cv = CountVectorizer(max_features=1000, stop_words = 'english')\n",
    "    X = cv.fit_transform(textdata['merged']).toarray()\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    corpus = cv.get_feature_names()\n",
    "    \n",
    "    return (X, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata = read_pdf('20200705v1/full/pdf_parses/pdf_parses_0.jsonl',1,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94553452</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  94550656                                                      \n",
       "1  94551239                                                      \n",
       "2  94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "3  94552339                                                      \n",
       "4  94553452                                                      \n",
       "\n",
       "                                           body_text  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                          whole_text  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  Gene therapy holds potential for treating many...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case\n",
      "0.31731247901916504\n",
      "Remove short text\n",
      "42.80977416038513\n",
      "Keep Alpha numeric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-88-94075515e180>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['nouns'] = [keep_alphanum(x) for x in textdf['split_text']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.64421892166138\n",
      "Keep nouns\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-52c0246e5456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-88-94075515e180>\u001b[0m in \u001b[0;36mclean_pdf\u001b[1;34m(textdf)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Keep nouns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mtextdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nouns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeep_nouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtextdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nouns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-94075515e180>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Keep nouns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mtextdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nouns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeep_nouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtextdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nouns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-41b5116e97dd>\u001b[0m in \u001b[0;36mkeep_nouns\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Preprocessing: keep nouns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkeep_nouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mget_word_postag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Preprocessing: keep words >= 3 in length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-41b5116e97dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Preprocessing: keep nouns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkeep_nouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mget_word_postag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Preprocessing: keep words >= 3 in length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-41b5116e97dd>\u001b[0m in \u001b[0;36mget_word_postag\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_word_postag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'J'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADJ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'V'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             )\n\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = clean_pdf(textdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paper_ids and title from metadata\n",
    "paper_ids = []; title = []; index = 0; area = []\n",
    "with open('20200705v1/full/metadata/metadata_0.jsonl') as f:\n",
    "    for line in f:\n",
    "        index += 1\n",
    "        paper = json.loads(line)\n",
    "        #print(paper)\n",
    "        paper_ids.append(paper['paper_id'])\n",
    "        if paper['mag_field_of_study']:\n",
    "            area.append(paper['mag_field_of_study'][0])\n",
    "        else: \n",
    "            area.append('')\n",
    "        title.append(paper['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text for each paper\n",
    "papers_ids_text = []; abstract = []; body_text = []; index = 0; whole_text = []\n",
    "with open('20200705v1/full/pdf_parses/pdf_parses_0.jsonl') as f:\n",
    "    for line in f:\n",
    "        index += 1\n",
    "        paper = json.loads(line)\n",
    "        papers_ids_text.append(paper['paper_id'])\n",
    "        if paper['abstract']:\n",
    "            abstract.append(paper['abstract'][0]['text'])\n",
    "        else: \n",
    "            abstract.append('')\n",
    "        text = []\n",
    "        full_text = ''\n",
    "        if paper['body_text']:\n",
    "            for entry in paper['body_text']:\n",
    "                if entry['section'] and entry['text']:\n",
    "                    section = {key: entry[key] for key in ['section', 'text']}\n",
    "                    text.append(section)\n",
    "                    if full_text:\n",
    "                        full_text = full_text + '\\n' + entry['text']\n",
    "                    else:\n",
    "                        full_text = entry['text']\n",
    "            body_text.append(text)\n",
    "            whole_text.append(full_text)\n",
    "        else:\n",
    "            body_text.append([])\n",
    "            whole_text.append('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77499681</td>\n",
       "      <td>The purpose of this study is to evaluate the e...</td>\n",
       "      <td>[{'section': 'CONFLICTS OF INTEREST', 'text': ...</td>\n",
       "      <td>The authors have nothing to disclose.</td>\n",
       "      <td>Effects of Teriparatide Administration on Frac...</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>The Approximate Analysis of Nonlinear Behavior...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Scanning probe memories – Technology and appli...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Analytical Procedure for the Determination of ...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  77499681  The purpose of this study is to evaluate the e...   \n",
       "1  94550656                                                      \n",
       "2  94551239                                                      \n",
       "3  94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "4  94552339                                                      \n",
       "\n",
       "                                           body_text  \\\n",
       "0  [{'section': 'CONFLICTS OF INTEREST', 'text': ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "4                                                 []   \n",
       "\n",
       "                                          whole_text  \\\n",
       "0             The authors have nothing to disclose.    \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Gene therapy holds potential for treating many...   \n",
       "4                                                      \n",
       "\n",
       "                                               title               area  \n",
       "0  Effects of Teriparatide Administration on Frac...           Medicine  \n",
       "1  The Approximate Analysis of Nonlinear Behavior...          Chemistry  \n",
       "2  Scanning probe memories – Technology and appli...          Chemistry  \n",
       "3  Gd(III) ion-chelated supramolecular assemblies...  Materials Science  \n",
       "4  Analytical Procedure for the Determination of ...          Chemistry  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing: merging data to dataframe\n",
    "\n",
    "metadata = pd.DataFrame({'paper_id': paper_ids, 'title': title, 'area': area})\n",
    "textdata = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract, 'body_text': body_text, 'whole_text': whole_text})\n",
    "textdata = textdata.merge(metadata, how='left', on='paper_id')\n",
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata.to_csv('articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata.drop(labels=['abstract', 'body_text', 'title'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77499681</td>\n",
       "      <td>The authors have nothing to disclose.</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                         whole_text  \\\n",
       "0  77499681             The authors have nothing to disclose.    \n",
       "1  94550656                                                      \n",
       "2  94551239                                                      \n",
       "3  94551546  Gene therapy holds potential for treating many...   \n",
       "4  94552339                                                      \n",
       "\n",
       "                area  \n",
       "0           Medicine  \n",
       "1          Chemistry  \n",
       "2          Chemistry  \n",
       "3  Materials Science  \n",
       "4          Chemistry  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: lower case text\n",
    "textdata['whole_text'] = textdata['whole_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where whole text has >= 100 words\n",
    "#textdata['split_text'] = [x.split() for x in textdata['whole_text']]\n",
    "textdata['split_text'] = [nltk.word_tokenize(x) for x in textdata['whole_text']]\n",
    "text_length = [len(x)>= 200 for x in textdata['split_text']]\n",
    "textdata = textdata[text_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "      <td>[gene, therapy, holds, potential, for, treatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>159355456</td>\n",
       "      <td>The Government of India has presented an expan...</td>\n",
       "      <td>[{'section': 'OUR MISSION', 'text': 'Our missi...</td>\n",
       "      <td>our mission is achieving and maintaining excel...</td>\n",
       "      <td>An update on model Ayush wellness clinic at pr...</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>[our, mission, is, achieving, and, maintaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>throughout the technical note, we use capital ...</td>\n",
       "      <td>Distributionally Robust Counterpart in Markov ...</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>[throughout, the, technical, note, ,, we, use,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18980463</td>\n",
       "      <td>Although development of the adult Drosophila c...</td>\n",
       "      <td>[{'section': 'Embryonic development of the lar...</td>\n",
       "      <td>we followed bo pr development from specificati...</td>\n",
       "      <td>Adult and larval photoreceptors use different ...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>[we, followed, bo, pr, development, from, spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18981111</td>\n",
       "      <td></td>\n",
       "      <td>[{'section': 'Exploration of Unknown Spaces by...</td>\n",
       "      <td>orly lahav david mioduser tel aviv university,...</td>\n",
       "      <td>Exploration of Unknown Spaces by People Who Ar...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>[orly, lahav, david, mioduser, tel, aviv, univ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                           abstract  \\\n",
       "3    94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "11  159355456  The Government of India has presented an expan...   \n",
       "16   18980380  This technical note studies Markov decision pr...   \n",
       "17   18980463  Although development of the adult Drosophila c...   \n",
       "19   18981111                                                      \n",
       "\n",
       "                                            body_text  \\\n",
       "3   [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "11  [{'section': 'OUR MISSION', 'text': 'Our missi...   \n",
       "16  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "17  [{'section': 'Embryonic development of the lar...   \n",
       "19  [{'section': 'Exploration of Unknown Spaces by...   \n",
       "\n",
       "                                           whole_text  \\\n",
       "3   gene therapy holds potential for treating many...   \n",
       "11  our mission is achieving and maintaining excel...   \n",
       "16  throughout the technical note, we use capital ...   \n",
       "17  we followed bo pr development from specificati...   \n",
       "19  orly lahav david mioduser tel aviv university,...   \n",
       "\n",
       "                                                title               area  \\\n",
       "3   Gd(III) ion-chelated supramolecular assemblies...  Materials Science   \n",
       "11  An update on model Ayush wellness clinic at pr...  Political Science   \n",
       "16  Distributionally Robust Counterpart in Markov ...        Mathematics   \n",
       "17  Adult and larval photoreceptors use different ...            Biology   \n",
       "19  Exploration of Unknown Spaces by People Who Ar...   Computer Science   \n",
       "\n",
       "                                           split_text  \n",
       "3   [gene, therapy, holds, potential, for, treatin...  \n",
       "11  [our, mission, is, achieving, and, maintaining...  \n",
       "16  [throughout, the, technical, note, ,, we, use,...  \n",
       "17  [we, followed, bo, pr, development, from, spec...  \n",
       "19  [orly, lahav, david, mioduser, tel, aviv, univ...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_word_postag(word):\n",
    "    if pos_tag([word])[0][1].startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    if pos_tag([word])[0][1].startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    if pos_tag([word])[0][1].startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return wordnet.ADJ\n",
    "        #return wordnet.NOUN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: alpha num\n",
    "def keep_alphanum(words):\n",
    "    return [word for word in words if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: keep nouns\n",
    "def keep_nouns(words):\n",
    "    return [word for word in words if get_word_postag(word) =='n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: keep words >= 3 in length\n",
    "def keep_longer_words(words):\n",
    "    return [word for word in words if len(word) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "def stemming(words):\n",
    "    return [ps.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['nouns'] = [keep_alphanum(x) for x in textdata['split_text']]\n",
    "textdata['nouns'] = [keep_nouns(x) for x in textdata['nouns']]\n",
    "\n",
    "textdata['nouns'] = [keep_longer_words(x) for x in textdata['nouns']]\n",
    "textdata['nouns'] = [stemming(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['nouns'] = [keep_longer_words(x) for x in textdata['nouns']]\n",
    "textdata['nouns'] = [stemming(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: get corpus of words\n",
    "corpus_all = []\n",
    "for text in textdata['nouns']:\n",
    "    corpus_all.extend(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: removing stop words:\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "corpus = []\n",
    "for word in corpus_all:\n",
    "    if word not in stop_words:\n",
    "        corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "def getUniqueWords(allWords):\n",
    "    uniqueWords = Counter()\n",
    "\n",
    "    for word in allWords:\n",
    "        uniqueWords[word]+=1\n",
    "    return uniqueWords.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8717"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = getUniqueWords(corpus)\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for paper in textdata['nouns']:\n",
    "    for noun in paper:\n",
    "        if noun not in wordfreq.keys():\n",
    "            wordfreq[noun] = 1\n",
    "        else:\n",
    "            wordfreq[noun] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "most_freq = heapq.nlargest(10, wordfreq, key=wordfreq.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'studi',\n",
       " 'data',\n",
       " 'cell',\n",
       " 'time',\n",
       " 'case',\n",
       " 'group',\n",
       " 'model',\n",
       " 'result',\n",
       " 'patient']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged(words):\n",
    "    return ' '.join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['merged'] = [merged(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>split_text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "      <td>[gene, therapy, holds, potential, for, treatin...</td>\n",
       "      <td>[gene, therapi, diseas, cancer, diseas, gene, ...</td>\n",
       "      <td>gene therapi diseas cancer diseas gene therapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>159355456</td>\n",
       "      <td>The Government of India has presented an expan...</td>\n",
       "      <td>[{'section': 'OUR MISSION', 'text': 'Our missi...</td>\n",
       "      <td>our mission is achieving and maintaining excel...</td>\n",
       "      <td>An update on model Ayush wellness clinic at pr...</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>[our, mission, is, achieving, and, maintaining...</td>\n",
       "      <td>[mission, excel, healthcar, servic, system, me...</td>\n",
       "      <td>mission excel healthcar servic system medicin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>throughout the technical note, we use capital ...</td>\n",
       "      <td>Distributionally Robust Counterpart in Markov ...</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>[throughout, the, technical, note, ,, we, use,...</td>\n",
       "      <td>[note, use, capit, letter, denot, matric, bold...</td>\n",
       "      <td>note use capit letter denot matric bold face l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18980463</td>\n",
       "      <td>Although development of the adult Drosophila c...</td>\n",
       "      <td>[{'section': 'Embryonic development of the lar...</td>\n",
       "      <td>we followed bo pr development from specificati...</td>\n",
       "      <td>Adult and larval photoreceptors use different ...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>[we, followed, bo, pr, development, from, spec...</td>\n",
       "      <td>[develop, specif, precursor, end, larval, life...</td>\n",
       "      <td>develop specif precursor end larval life molec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18981111</td>\n",
       "      <td></td>\n",
       "      <td>[{'section': 'Exploration of Unknown Spaces by...</td>\n",
       "      <td>orly lahav david mioduser tel aviv university,...</td>\n",
       "      <td>Exploration of Unknown Spaces by People Who Ar...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>[orly, lahav, david, mioduser, tel, aviv, univ...</td>\n",
       "      <td>[lahav, david, miodus, tel, aviv, univers, sch...</td>\n",
       "      <td>lahav david miodus tel aviv univers school edu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                           abstract  \\\n",
       "3    94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "11  159355456  The Government of India has presented an expan...   \n",
       "16   18980380  This technical note studies Markov decision pr...   \n",
       "17   18980463  Although development of the adult Drosophila c...   \n",
       "19   18981111                                                      \n",
       "\n",
       "                                            body_text  \\\n",
       "3   [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "11  [{'section': 'OUR MISSION', 'text': 'Our missi...   \n",
       "16  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "17  [{'section': 'Embryonic development of the lar...   \n",
       "19  [{'section': 'Exploration of Unknown Spaces by...   \n",
       "\n",
       "                                           whole_text  \\\n",
       "3   gene therapy holds potential for treating many...   \n",
       "11  our mission is achieving and maintaining excel...   \n",
       "16  throughout the technical note, we use capital ...   \n",
       "17  we followed bo pr development from specificati...   \n",
       "19  orly lahav david mioduser tel aviv university,...   \n",
       "\n",
       "                                                title               area  \\\n",
       "3   Gd(III) ion-chelated supramolecular assemblies...  Materials Science   \n",
       "11  An update on model Ayush wellness clinic at pr...  Political Science   \n",
       "16  Distributionally Robust Counterpart in Markov ...        Mathematics   \n",
       "17  Adult and larval photoreceptors use different ...            Biology   \n",
       "19  Exploration of Unknown Spaces by People Who Ar...   Computer Science   \n",
       "\n",
       "                                           split_text  \\\n",
       "3   [gene, therapy, holds, potential, for, treatin...   \n",
       "11  [our, mission, is, achieving, and, maintaining...   \n",
       "16  [throughout, the, technical, note, ,, we, use,...   \n",
       "17  [we, followed, bo, pr, development, from, spec...   \n",
       "19  [orly, lahav, david, mioduser, tel, aviv, univ...   \n",
       "\n",
       "                                                nouns  \\\n",
       "3   [gene, therapi, diseas, cancer, diseas, gene, ...   \n",
       "11  [mission, excel, healthcar, servic, system, me...   \n",
       "16  [note, use, capit, letter, denot, matric, bold...   \n",
       "17  [develop, specif, precursor, end, larval, life...   \n",
       "19  [lahav, david, miodus, tel, aviv, univers, sch...   \n",
       "\n",
       "                                               merged  \n",
       "3   gene therapi diseas cancer diseas gene therapi...  \n",
       "11  mission excel healthcar servic system medicin ...  \n",
       "16  note use capit letter denot matric bold face l...  \n",
       "17  develop specif precursor end larval life molec...  \n",
       "19  lahav david miodus tel aviv univers school edu...  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata_sample = textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df = max_features=1000)\n",
    "\n",
    "X = cv.fit_transform(textdata['merged']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 1000)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
