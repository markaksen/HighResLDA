{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aksen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "def process_metadata(file_name, field=None):\n",
    "    ids = []; title = []; \n",
    "    #metadata = def process_metadata(file_name_meta, start_line, end_line)\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            paper = json.loads(line)\n",
    "            if not field:\n",
    "                ids.append(paper['paper_id'])\n",
    "                title.append(paper['title'])\n",
    "            elif paper['mag_field_of_study'] and field in paper['mag_field_of_study']:\n",
    "                ids.append(paper['paper_id'])\n",
    "                title.append(paper['title'])\n",
    "        return {'ids':ids, 'titles':title}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = process_metadata('20200705v1/full/metadata/metadata_0.jsonl', 'Computer Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121562"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_data['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(file_name, start_line, end_line):\n",
    "    papers_ids_text = []; abstract = []; body_text = []; index = 0; whole_text = []\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        for _ in range(start_line):\n",
    "            next(f)\n",
    "        index = 0\n",
    "        for line in f:\n",
    "            paper = json.loads(line)\n",
    "            if index > end_line - start_line:\n",
    "                break\n",
    "            index += 1\n",
    "            papers_ids_text.append(paper['paper_id'])\n",
    "            if paper['abstract']:\n",
    "                abstract.append(paper['abstract'][0]['text'])\n",
    "            else: \n",
    "                abstract.append('')\n",
    "            text = []\n",
    "            full_text = ''\n",
    "            if paper['body_text']:\n",
    "                for entry in paper['body_text']:\n",
    "                    if entry['section'] and entry['text']:\n",
    "                        section = {key: entry[key] for key in ['section', 'text']}\n",
    "                        text.append(section)\n",
    "                        if full_text:\n",
    "                            full_text = full_text + '\\n' + entry['text']\n",
    "                        else:\n",
    "                            full_text = entry['text']\n",
    "                body_text.append(text)\n",
    "                whole_text.append(full_text)\n",
    "            else:\n",
    "                body_text.append([])\n",
    "                whole_text.append('')\n",
    "                \n",
    "        textdata = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract, 'body_text': body_text, 'whole_text': whole_text})\n",
    "\n",
    "        return textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(file_name, ids):\n",
    "    BATCH_SIZE = 5000\n",
    "    \n",
    "    batch = 0\n",
    "    while True:\n",
    "        w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_word_postag(word):\n",
    "    #if pos_tag([word])[0][1].startswith('J'):\n",
    "    #    return wordnet.ADJ\n",
    "    #if pos_tag([word])[0][1].startswith('V'):\n",
    "    #    return wordnet.VERB\n",
    "    if pos_tag([word])[0][1].startswith('N'):\n",
    "        #return wordnet.NOUN\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        #return wordnet.ADJ\n",
    "        #return wordnet.NOUN\n",
    "\n",
    "# Preprocessing: alpha num\n",
    "def keep_alphanum(words):\n",
    "    def isalphanum(word):\n",
    "        return word.isalnum()\n",
    "    return filter(isalphanum, words)\n",
    "    #return [word for word in words if word.isalnum()]\n",
    "\n",
    "# Preprocessing: keep nouns\n",
    "def keep_nouns(words):\n",
    "    return filter(get_word_postag, words)\n",
    "    #return [word for word in words if get_word_postag(word) =='n']\n",
    "\n",
    "# Preprocessing: keep words >= 3 in length\n",
    "def keep_longer_words(words):\n",
    "    return filter(lambda x: (len(x) >= 3), words)\n",
    "    #return [word for word in words if len(word) >= 3]\n",
    "\n",
    "# Preprocessing: stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "def stemming(words):\n",
    "    #return [ps.stem(word) for word in words]\n",
    "    return map(ps.stem, words)\n",
    "\n",
    "def merged(words):\n",
    "    return ' '.join(word for word in words)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['whole_text'] = textdata['whole_text'].str.lower()\n",
    "textdata['split_text'] = textdata['whole_text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def clean_pdf(textdf):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    print('Lower case')\n",
    "    # Preprocessing: lower case text\n",
    "    textdf['whole_text'] = textdf['whole_text'].str.lower()\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Remove short text')\n",
    "    # Select rows where whole text has >= 200 words\n",
    "    k = 200\n",
    "    #textdata['split_text'] = [x.split() for x in textdata['whole_text']]\n",
    "    textdf['split_text'] = [nltk.word_tokenize(x) for x in textdf['whole_text']]\n",
    "    text_length = [len(x)>= k for x in textdf['split_text']]\n",
    "    textdf = textdf[text_length]\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Keep Alpha numeric')\n",
    "    #textdf['nouns'] = [keep_alphanum(x) for x in textdf['split_text']]\n",
    "    textdf['nouns'] = textdf['split_text'].apply(keep_alphanum)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Keep nouns')\n",
    "    #textdf['nouns'] = [keep_nouns(x) for x in textdf['nouns']]\n",
    "    textdf['nouns'] = textdf['nouns'].apply(keep_nouns)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Keep longer words')\n",
    "    #textdf['nouns'] = [keep_longer_words(x) for x in textdf['nouns']]\n",
    "    textdf['nouns'] = textdf['nouns'].apply(keep_longer_words)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Stem words')\n",
    "    #textdf['nouns'] = [stemming(x) for x in textdf['nouns']]\n",
    "    textdf['nouns'] = textdf['nouns'].apply(stemming)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "\n",
    "    print('Merge text')\n",
    "    #textdf['merged'] = [merged(x) for x in textdf['nouns']]  \n",
    "    textdf['merged'] = textdf['nouns'].apply(merged)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    print('Bag of Words Representation')\n",
    "    cv = CountVectorizer(max_features=1000, stop_words = 'english')\n",
    "    X = cv.fit_transform(textdf['merged']).toarray()\n",
    "    \n",
    "    t = time.time()\n",
    "    print(t-start)\n",
    "    \n",
    "    corpus = cv.get_feature_names()\n",
    "    \n",
    "    return (X, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-41944084dada>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'20200705v1/full/pdf_parses/pdf_parses_0.jsonl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m800000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m800001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-0af2201e6496>\u001b[0m in \u001b[0;36mread_pdf\u001b[1;34m(file_name, start_line, end_line)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = read_pdf('20200705v1/full/pdf_parses/pdf_parses_0.jsonl', 800000, 800001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata = read_pdf('20200705v1/full/pdf_parses/pdf_parses_0.jsonl',1,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94553452</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  94550656                                                      \n",
       "1  94551239                                                      \n",
       "2  94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "3  94552339                                                      \n",
       "4  94553452                                                      \n",
       "\n",
       "                                           body_text  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                          whole_text  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  Gene therapy holds potential for treating many...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower case\n",
      "0.01299738883972168\n",
      "Remove short text\n",
      "1.7004528045654297\n",
      "Keep Alpha numeric\n",
      "1.7014508247375488\n",
      "Keep nouns\n",
      "1.7014508247375488\n",
      "Keep longer words\n",
      "1.7044429779052734\n",
      "Stem words\n",
      "1.7054402828216553\n",
      "Merge text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-104-fbbd97d87b59>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['nouns'] = textdf['split_text'].apply(keep_alphanum)\n",
      "<ipython-input-104-fbbd97d87b59>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['nouns'] = textdf['nouns'].apply(keep_nouns)\n",
      "<ipython-input-104-fbbd97d87b59>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['nouns'] = textdf['nouns'].apply(keep_longer_words)\n",
      "<ipython-input-104-fbbd97d87b59>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['nouns'] = textdf['nouns'].apply(stemming)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.15537571907043\n",
      "Bag of Words Representation\n",
      "123.2881441116333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-104-fbbd97d87b59>:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  textdf['merged'] = textdf['nouns'].apply(merged)\n"
     ]
    }
   ],
   "source": [
    "output = clean_pdf(textdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = output[0].transpose()\n",
    "words = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dict(zip(words, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77499681</td>\n",
       "      <td>The purpose of this study is to evaluate the e...</td>\n",
       "      <td>[{'section': 'CONFLICTS OF INTEREST', 'text': ...</td>\n",
       "      <td>The authors have nothing to disclose.</td>\n",
       "      <td>Effects of Teriparatide Administration on Frac...</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>The Approximate Analysis of Nonlinear Behavior...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Scanning probe memories – Technology and appli...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>Analytical Procedure for the Determination of ...</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  77499681  The purpose of this study is to evaluate the e...   \n",
       "1  94550656                                                      \n",
       "2  94551239                                                      \n",
       "3  94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "4  94552339                                                      \n",
       "\n",
       "                                           body_text  \\\n",
       "0  [{'section': 'CONFLICTS OF INTEREST', 'text': ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "4                                                 []   \n",
       "\n",
       "                                          whole_text  \\\n",
       "0             The authors have nothing to disclose.    \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Gene therapy holds potential for treating many...   \n",
       "4                                                      \n",
       "\n",
       "                                               title               area  \n",
       "0  Effects of Teriparatide Administration on Frac...           Medicine  \n",
       "1  The Approximate Analysis of Nonlinear Behavior...          Chemistry  \n",
       "2  Scanning probe memories – Technology and appli...          Chemistry  \n",
       "3  Gd(III) ion-chelated supramolecular assemblies...  Materials Science  \n",
       "4  Analytical Procedure for the Determination of ...          Chemistry  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing: merging data to dataframe\n",
    "\n",
    "metadata = pd.DataFrame({'paper_id': paper_ids, 'title': title, 'area': area})\n",
    "textdata = pd.DataFrame({'paper_id': papers_ids_text, 'abstract': abstract, 'body_text': body_text, 'whole_text': whole_text})\n",
    "textdata = textdata.merge(metadata, how='left', on='paper_id')\n",
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata.to_csv('articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata.drop(labels=['abstract', 'body_text', 'title'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77499681</td>\n",
       "      <td>The authors have nothing to disclose.</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94550656</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94551239</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Gene therapy holds potential for treating many...</td>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94552339</td>\n",
       "      <td></td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                         whole_text  \\\n",
       "0  77499681             The authors have nothing to disclose.    \n",
       "1  94550656                                                      \n",
       "2  94551239                                                      \n",
       "3  94551546  Gene therapy holds potential for treating many...   \n",
       "4  94552339                                                      \n",
       "\n",
       "                area  \n",
       "0           Medicine  \n",
       "1          Chemistry  \n",
       "2          Chemistry  \n",
       "3  Materials Science  \n",
       "4          Chemistry  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: lower case text\n",
    "textdata['whole_text'] = textdata['whole_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where whole text has >= 100 words\n",
    "#textdata['split_text'] = [x.split() for x in textdata['whole_text']]\n",
    "textdata['split_text'] = [nltk.word_tokenize(x) for x in textdata['whole_text']]\n",
    "text_length = [len(x)>= 200 for x in textdata['split_text']]\n",
    "textdata = textdata[text_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "      <td>[gene, therapy, holds, potential, for, treatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>159355456</td>\n",
       "      <td>The Government of India has presented an expan...</td>\n",
       "      <td>[{'section': 'OUR MISSION', 'text': 'Our missi...</td>\n",
       "      <td>our mission is achieving and maintaining excel...</td>\n",
       "      <td>An update on model Ayush wellness clinic at pr...</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>[our, mission, is, achieving, and, maintaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>throughout the technical note, we use capital ...</td>\n",
       "      <td>Distributionally Robust Counterpart in Markov ...</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>[throughout, the, technical, note, ,, we, use,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18980463</td>\n",
       "      <td>Although development of the adult Drosophila c...</td>\n",
       "      <td>[{'section': 'Embryonic development of the lar...</td>\n",
       "      <td>we followed bo pr development from specificati...</td>\n",
       "      <td>Adult and larval photoreceptors use different ...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>[we, followed, bo, pr, development, from, spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18981111</td>\n",
       "      <td></td>\n",
       "      <td>[{'section': 'Exploration of Unknown Spaces by...</td>\n",
       "      <td>orly lahav david mioduser tel aviv university,...</td>\n",
       "      <td>Exploration of Unknown Spaces by People Who Ar...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>[orly, lahav, david, mioduser, tel, aviv, univ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                           abstract  \\\n",
       "3    94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "11  159355456  The Government of India has presented an expan...   \n",
       "16   18980380  This technical note studies Markov decision pr...   \n",
       "17   18980463  Although development of the adult Drosophila c...   \n",
       "19   18981111                                                      \n",
       "\n",
       "                                            body_text  \\\n",
       "3   [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "11  [{'section': 'OUR MISSION', 'text': 'Our missi...   \n",
       "16  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "17  [{'section': 'Embryonic development of the lar...   \n",
       "19  [{'section': 'Exploration of Unknown Spaces by...   \n",
       "\n",
       "                                           whole_text  \\\n",
       "3   gene therapy holds potential for treating many...   \n",
       "11  our mission is achieving and maintaining excel...   \n",
       "16  throughout the technical note, we use capital ...   \n",
       "17  we followed bo pr development from specificati...   \n",
       "19  orly lahav david mioduser tel aviv university,...   \n",
       "\n",
       "                                                title               area  \\\n",
       "3   Gd(III) ion-chelated supramolecular assemblies...  Materials Science   \n",
       "11  An update on model Ayush wellness clinic at pr...  Political Science   \n",
       "16  Distributionally Robust Counterpart in Markov ...        Mathematics   \n",
       "17  Adult and larval photoreceptors use different ...            Biology   \n",
       "19  Exploration of Unknown Spaces by People Who Ar...   Computer Science   \n",
       "\n",
       "                                           split_text  \n",
       "3   [gene, therapy, holds, potential, for, treatin...  \n",
       "11  [our, mission, is, achieving, and, maintaining...  \n",
       "16  [throughout, the, technical, note, ,, we, use,...  \n",
       "17  [we, followed, bo, pr, development, from, spec...  \n",
       "19  [orly, lahav, david, mioduser, tel, aviv, univ...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_word_postag(word):\n",
    "    if pos_tag([word])[0][1].startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    if pos_tag([word])[0][1].startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    if pos_tag([word])[0][1].startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    else:\n",
    "        return wordnet.ADJ\n",
    "        #return wordnet.NOUN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: alpha num\n",
    "def keep_alphanum(words):\n",
    "    return [word for word in words if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: keep nouns\n",
    "def keep_nouns(words):\n",
    "    return [word for word in words if get_word_postag(word) =='n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: keep words >= 3 in length\n",
    "def keep_longer_words(words):\n",
    "    return [word for word in words if len(word) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: stemming\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "def stemming(words):\n",
    "    return [ps.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['nouns'] = [keep_alphanum(x) for x in textdata['split_text']]\n",
    "textdata['nouns'] = [keep_nouns(x) for x in textdata['nouns']]\n",
    "\n",
    "textdata['nouns'] = [keep_longer_words(x) for x in textdata['nouns']]\n",
    "textdata['nouns'] = [stemming(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['nouns'] = [keep_longer_words(x) for x in textdata['nouns']]\n",
    "textdata['nouns'] = [stemming(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: get corpus of words\n",
    "corpus_all = []\n",
    "for text in textdata['nouns']:\n",
    "    corpus_all.extend(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: removing stop words:\n",
    "stop_words = set(stopwords.words('english'))  \n",
    "corpus = []\n",
    "for word in corpus_all:\n",
    "    if word not in stop_words:\n",
    "        corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "def getUniqueWords(allWords):\n",
    "    uniqueWords = Counter()\n",
    "\n",
    "    for word in allWords:\n",
    "        uniqueWords[word]+=1\n",
    "    return uniqueWords.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8717"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = getUniqueWords(corpus)\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = {}\n",
    "for paper in textdata['nouns']:\n",
    "    for noun in paper:\n",
    "        if noun not in wordfreq.keys():\n",
    "            wordfreq[noun] = 1\n",
    "        else:\n",
    "            wordfreq[noun] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "most_freq = heapq.nlargest(10, wordfreq, key=wordfreq.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system',\n",
       " 'studi',\n",
       " 'data',\n",
       " 'cell',\n",
       " 'time',\n",
       " 'case',\n",
       " 'group',\n",
       " 'model',\n",
       " 'result',\n",
       " 'patient']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged(words):\n",
    "    return ' '.join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata['merged'] = [merged(x) for x in textdata['nouns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "      <th>whole_text</th>\n",
       "      <th>title</th>\n",
       "      <th>area</th>\n",
       "      <th>split_text</th>\n",
       "      <th>nouns</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94551546</td>\n",
       "      <td>Ethanolamine (EA) or ethylenediamine (ED)-func...</td>\n",
       "      <td>[{'section': 'INTRODUCTION', 'text': 'Gene the...</td>\n",
       "      <td>gene therapy holds potential for treating many...</td>\n",
       "      <td>Gd(III) ion-chelated supramolecular assemblies...</td>\n",
       "      <td>Materials Science</td>\n",
       "      <td>[gene, therapy, holds, potential, for, treatin...</td>\n",
       "      <td>[gene, therapi, diseas, cancer, diseas, gene, ...</td>\n",
       "      <td>gene therapi diseas cancer diseas gene therapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>159355456</td>\n",
       "      <td>The Government of India has presented an expan...</td>\n",
       "      <td>[{'section': 'OUR MISSION', 'text': 'Our missi...</td>\n",
       "      <td>our mission is achieving and maintaining excel...</td>\n",
       "      <td>An update on model Ayush wellness clinic at pr...</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>[our, mission, is, achieving, and, maintaining...</td>\n",
       "      <td>[mission, excel, healthcar, servic, system, me...</td>\n",
       "      <td>mission excel healthcar servic system medicin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18980380</td>\n",
       "      <td>This technical note studies Markov decision pr...</td>\n",
       "      <td>[{'section': 'II. PRELIMINARIES', 'text': 'Thr...</td>\n",
       "      <td>throughout the technical note, we use capital ...</td>\n",
       "      <td>Distributionally Robust Counterpart in Markov ...</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>[throughout, the, technical, note, ,, we, use,...</td>\n",
       "      <td>[note, use, capit, letter, denot, matric, bold...</td>\n",
       "      <td>note use capit letter denot matric bold face l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18980463</td>\n",
       "      <td>Although development of the adult Drosophila c...</td>\n",
       "      <td>[{'section': 'Embryonic development of the lar...</td>\n",
       "      <td>we followed bo pr development from specificati...</td>\n",
       "      <td>Adult and larval photoreceptors use different ...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>[we, followed, bo, pr, development, from, spec...</td>\n",
       "      <td>[develop, specif, precursor, end, larval, life...</td>\n",
       "      <td>develop specif precursor end larval life molec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18981111</td>\n",
       "      <td></td>\n",
       "      <td>[{'section': 'Exploration of Unknown Spaces by...</td>\n",
       "      <td>orly lahav david mioduser tel aviv university,...</td>\n",
       "      <td>Exploration of Unknown Spaces by People Who Ar...</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>[orly, lahav, david, mioduser, tel, aviv, univ...</td>\n",
       "      <td>[lahav, david, miodus, tel, aviv, univers, sch...</td>\n",
       "      <td>lahav david miodus tel aviv univers school edu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                           abstract  \\\n",
       "3    94551546  Ethanolamine (EA) or ethylenediamine (ED)-func...   \n",
       "11  159355456  The Government of India has presented an expan...   \n",
       "16   18980380  This technical note studies Markov decision pr...   \n",
       "17   18980463  Although development of the adult Drosophila c...   \n",
       "19   18981111                                                      \n",
       "\n",
       "                                            body_text  \\\n",
       "3   [{'section': 'INTRODUCTION', 'text': 'Gene the...   \n",
       "11  [{'section': 'OUR MISSION', 'text': 'Our missi...   \n",
       "16  [{'section': 'II. PRELIMINARIES', 'text': 'Thr...   \n",
       "17  [{'section': 'Embryonic development of the lar...   \n",
       "19  [{'section': 'Exploration of Unknown Spaces by...   \n",
       "\n",
       "                                           whole_text  \\\n",
       "3   gene therapy holds potential for treating many...   \n",
       "11  our mission is achieving and maintaining excel...   \n",
       "16  throughout the technical note, we use capital ...   \n",
       "17  we followed bo pr development from specificati...   \n",
       "19  orly lahav david mioduser tel aviv university,...   \n",
       "\n",
       "                                                title               area  \\\n",
       "3   Gd(III) ion-chelated supramolecular assemblies...  Materials Science   \n",
       "11  An update on model Ayush wellness clinic at pr...  Political Science   \n",
       "16  Distributionally Robust Counterpart in Markov ...        Mathematics   \n",
       "17  Adult and larval photoreceptors use different ...            Biology   \n",
       "19  Exploration of Unknown Spaces by People Who Ar...   Computer Science   \n",
       "\n",
       "                                           split_text  \\\n",
       "3   [gene, therapy, holds, potential, for, treatin...   \n",
       "11  [our, mission, is, achieving, and, maintaining...   \n",
       "16  [throughout, the, technical, note, ,, we, use,...   \n",
       "17  [we, followed, bo, pr, development, from, spec...   \n",
       "19  [orly, lahav, david, mioduser, tel, aviv, univ...   \n",
       "\n",
       "                                                nouns  \\\n",
       "3   [gene, therapi, diseas, cancer, diseas, gene, ...   \n",
       "11  [mission, excel, healthcar, servic, system, me...   \n",
       "16  [note, use, capit, letter, denot, matric, bold...   \n",
       "17  [develop, specif, precursor, end, larval, life...   \n",
       "19  [lahav, david, miodus, tel, aviv, univers, sch...   \n",
       "\n",
       "                                               merged  \n",
       "3   gene therapi diseas cancer diseas gene therapi...  \n",
       "11  mission excel healthcar servic system medicin ...  \n",
       "16  note use capit letter denot matric bold face l...  \n",
       "17  develop specif precursor end larval life molec...  \n",
       "19  lahav david miodus tel aviv univers school edu...  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata_sample = textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df = max_features=1000)\n",
    "\n",
    "X = cv.fit_transform(textdata['merged']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 1000)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
